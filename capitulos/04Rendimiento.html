<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="es" xml:lang="es"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>4&nbsp; Rendimiento – Aprendizaje Computacional</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../capitulos/05ReduccionDim.html" rel="next">
<link href="../capitulos/03Parametricos.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-78faf54a06e50be45dc6d83ab59297a7.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Sin resultados",
    "search-matching-documents-text": "documentos encontrados",
    "search-copy-link-title": "Copiar el enlace en la búsqueda",
    "search-hide-matches-text": "Ocultar resultados adicionales",
    "search-more-match-text": "resultado adicional en este documento",
    "search-more-matches-text": "resultados adicionales en este documento",
    "search-clear-button-title": "Borrar",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancelar",
    "search-submit-button-title": "Enviar",
    "search-label": "Buscar"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../capitulos/04Rendimiento.html"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Rendimiento</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Buscar" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Aprendizaje Computacional</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/INGEOTEC/AprendizajeComputacional" title="Ejecutar el código" class="quarto-navigation-tool px-1" aria-label="Ejecutar el código"><i class="bi bi-github"></i></a>
    <a href="../Aprendizaje-Computacional.pdf" title="Descargar PDF" class="quarto-navigation-tool px-1" aria-label="Descargar PDF"><i class="bi bi-file-pdf"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Buscar"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Prefacio</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../capitulos/01Introduccion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introducción</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../capitulos/02Teoria_Decision.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Teoría de Decisión Bayesiana</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../capitulos/03Parametricos.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Métodos Paramétricos</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../capitulos/04Rendimiento.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Rendimiento</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../capitulos/05ReduccionDim.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Reducción de Dimensión</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../capitulos/06Agrupamiento.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Agrupamiento</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../capitulos/07NoParametricos.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Métodos No Paramétricos</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../capitulos/08Arboles.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Árboles de Decisión</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../capitulos/09Lineal.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Discriminantes Lineales</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../capitulos/10Optimizacion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Optimización</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../capitulos/11RedesNeuronales.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Redes Neuronales</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../capitulos/12Ensambles.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Ensambles</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../capitulos/13Comparacion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Comparación de Algoritmos</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../capitulos/17Referencias.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Referencias</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Apéndices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Alternar sección">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../capitulos/14Estadistica.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Estadística</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../capitulos/16ConjuntosDatos.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Conjunto de Datos</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Tabla de contenidos</h2>
   
  <ul>
  <li><a href="#paquetes-usados" id="toc-paquetes-usados" class="nav-link active" data-scroll-target="#paquetes-usados">Paquetes usados</a></li>
  <li><a href="#sec-intro-04" id="toc-sec-intro-04" class="nav-link" data-scroll-target="#sec-intro-04"><span class="header-section-number">4.1</span> Introducción</a></li>
  <li><a href="#sec-clasificacion" id="toc-sec-clasificacion" class="nav-link" data-scroll-target="#sec-clasificacion"><span class="header-section-number">4.2</span> Clasificación</a>
  <ul class="collapse">
  <li><a href="#sec-error" id="toc-sec-error" class="nav-link" data-scroll-target="#sec-error"><span class="header-section-number">4.2.1</span> Error</a></li>
  <li><a href="#sec-accuracy" id="toc-sec-accuracy" class="nav-link" data-scroll-target="#sec-accuracy"><span class="header-section-number">4.2.2</span> Exactitud (<em>Accuracy</em>)</a></li>
  <li><a href="#sec-recall" id="toc-sec-recall" class="nav-link" data-scroll-target="#sec-recall"><span class="header-section-number">4.2.3</span> Coberturba (<em>Recall</em>)</a></li>
  <li><a href="#sec-precision" id="toc-sec-precision" class="nav-link" data-scroll-target="#sec-precision"><span class="header-section-number">4.2.4</span> Precisión (<em>Precision</em>)</a></li>
  <li><a href="#sec-f1" id="toc-sec-f1" class="nav-link" data-scroll-target="#sec-f1"><span class="header-section-number">4.2.5</span> <span class="math inline">\(F_\beta\)</span></a></li>
  <li><a href="#sec-macro" id="toc-sec-macro" class="nav-link" data-scroll-target="#sec-macro"><span class="header-section-number">4.2.6</span> Medidas Macro</a></li>
  <li><a href="#sec-entropia-cruzada" id="toc-sec-entropia-cruzada" class="nav-link" data-scroll-target="#sec-entropia-cruzada"><span class="header-section-number">4.2.7</span> Entropía Cruzada</a></li>
  <li><a href="#sec-roc-curve" id="toc-sec-roc-curve" class="nav-link" data-scroll-target="#sec-roc-curve"><span class="header-section-number">4.2.8</span> Área Bajo la Curva <em>ROC</em></a></li>
  <li><a href="#ejemplo" id="toc-ejemplo" class="nav-link" data-scroll-target="#ejemplo"><span class="header-section-number">4.2.9</span> Ejemplo</a></li>
  </ul></li>
  <li><a href="#sec-rendimiento-regresion" id="toc-sec-rendimiento-regresion" class="nav-link" data-scroll-target="#sec-rendimiento-regresion"><span class="header-section-number">4.3</span> Regresión</a>
  <ul class="collapse">
  <li><a href="#ejemplo-1" id="toc-ejemplo-1" class="nav-link" data-scroll-target="#ejemplo-1"><span class="header-section-number">4.3.1</span> Ejemplo</a></li>
  </ul></li>
  <li><a href="#sec-validacion-cruzada" id="toc-sec-validacion-cruzada" class="nav-link" data-scroll-target="#sec-validacion-cruzada"><span class="header-section-number">4.4</span> Conjunto de Validación y Validación Cruzada</a>
  <ul class="collapse">
  <li><a href="#sec-kfold-cross-validation" id="toc-sec-kfold-cross-validation" class="nav-link" data-scroll-target="#sec-kfold-cross-validation"><span class="header-section-number">4.4.1</span> k-Iteraciones de Validación Cruzada</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Rendimiento</span></h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Código</button></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>El <strong>objetivo</strong> es contrastar las características de diferentes medidas de rendimiento en aprendizaje supervisado así como simular un procedimiento de aprendizaje supervisado.</p>
<section id="paquetes-usados" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="paquetes-usados">Paquetes usados</h2>
<div id="db46bebc" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> EvoMSA.model <span class="im">import</span> GaussianBayes</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_breast_cancer,<span class="op">\</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>                             load_diabetes</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> recall_score</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split, KFold</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> metrics</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> pylab <span class="im">as</span> plt</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<hr>
<div class="quarto-video"><iframe data-external="1" src="https://www.youtube.com/embed/NUbGplcMRmw" width="560" height="315" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<hr>
</section>
<section id="sec-intro-04" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="sec-intro-04"><span class="header-section-number">4.1</span> Introducción</h2>
<p>Es importante conocer el rendimiento del algoritmo de aprendizaje computacional desarrollado. En aprendizaje supervisado la medición se hace mediante el conjunto de prueba, <span class="math inline">\(\mathcal G\)</span>, mientras que en aprendizaje no supervisado es posible utilizar el conjunto de entrenamiento <span class="math inline">\(\mathcal T\)</span> o utilizar un conjunto de prueba. Es importante notar que aunque en el proceso de entrenamiento puede usar una función de rendimiento para estimar o encontrar el algoritmo que modela los datos, es importante complementar esta medición con otras funciones de rendimiento. Esta unidad describe algunas de las medidas más utilizadas para medir el rendimiento de algoritmos de clasificación y regresión.</p>
</section>
<section id="sec-clasificacion" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="sec-clasificacion"><span class="header-section-number">4.2</span> Clasificación</h2>
<p>En clasificación existen diferentes medidas de rendimiento, algunas de ellas son exactitud (<em>accuracy</em>), precisión (<em>precision</em>), recall, y <span class="math inline">\(F_1\)</span>, entre otras. <span class="citation" data-cites="10.1145/2808194.2809449">Sebastiani (<a href="17Referencias.html#ref-10.1145/2808194.2809449" role="doc-biblioref">2015</a>)</span> describe de manera axiomática algunas de estas medidas y se dan recomendaciones en general sobre medidas de rendimiento para clasificadores.</p>
<p>Varias de las medidas de rendimiento toman como insume la <strong>Tabla de Confusión</strong> (<a href="#tbl-confusion" class="quarto-xref">Tabla&nbsp;<span>4.1</span></a>), la cual contiene la información del proceso de clasificación. La siguiente tabla muestra la estructura de esta tabla para un problema binario, donde se tiene una clase positiva identificada con <span class="math inline">\(p\)</span> y una clase negativa (<span class="math inline">\(n\)</span>). La variable <span class="math inline">\(\mathcal Y\)</span> indica las clases reales y la variable <span class="math inline">\(\mathcal{\hat Y}\)</span> representa la estimación (predicción) hecha por el clasificador. Adicionalmente, la tabla se puede extender a <span class="math inline">\(K\)</span> clases siguiendo la misma estructura; la diagonal contienen los elementos correctamente identificados y los elementos fuera de la diagonal muestra los errores.</p>
<div id="tbl-confusion" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-confusion-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Tabla&nbsp;4.1: Tabla de Confusión
</figcaption>
<div aria-describedby="tbl-confusion-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<thead>
<tr class="header">
<th></th>
<th><span class="math inline">\(\mathcal{\hat Y}=p\)</span></th>
<th><span class="math inline">\(\mathcal{\hat Y}=n\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(\mathcal Y=p\)</span></td>
<td>Verdaderos Pos.</td>
<td>Falsos Neg.</td>
</tr>
<tr class="even">
<td><span class="math inline">\(\mathcal Y=n\)</span></td>
<td>Falsos Pos.</td>
<td>Verdaderos Neg.</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>La tabla se puede ver como valores nominales, es decir contar el número de ejemplos clasificados como verdaderos positivos o como proporción de tal manera que las cuatro celdas sumen <span class="math inline">\(1\)</span>. En esta descripción se asume que son proporcionen, esto porque se seguirá una interpretación probabilística descrita en <a href="https://link.springer.com/chapter/10.1007/978-3-540-31865-1_25">este artículo</a> para presentar las diferentes medidas de rendimiento.</p>
<p>Viendo la <a href="#tbl-confusion" class="quarto-xref">Tabla&nbsp;<span>4.1</span></a> como una proporción y combinando con la interpretación probabilística la tabla quedaría de la siguiente manera.</p>
<div id="tbl-confusion-prob" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-confusion-prob-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Tabla&nbsp;4.2: Tabla de Confusión como Proporción
</figcaption>
<div aria-describedby="tbl-confusion-prob-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 26%">
<col style="width: 36%">
<col style="width: 36%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th><span class="math inline">\(\mathcal{\hat Y}=p\)</span></th>
<th><span class="math inline">\(\mathcal{\hat Y}=n\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(\mathcal Y=p\)</span></td>
<td><span class="math inline">\(\mathbb P(\mathcal Y=p, \mathcal{\hat Y=p})\)</span></td>
<td><span class="math inline">\(\mathbb P(\mathcal Y=p, \mathcal{\hat Y=n})\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\mathcal Y=n\)</span></td>
<td><span class="math inline">\(\mathbb P(\mathcal Y=n, \mathcal{\hat Y=p})\)</span></td>
<td><span class="math inline">\(\mathbb P(\mathcal Y=n, \mathcal{\hat Y=n})\)</span></td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>Partiendo de la <a href="#tbl-confusion-prob" class="quarto-xref">Tabla&nbsp;<span>4.2</span></a> se puede calcular la probabilidad marginal de cualquier variable y también las probabilidades condicionales, por ejemplo <span class="math inline">\(\mathbb P(\mathcal Y=p) = \sum_k \mathbb P(\mathcal Y=p, \mathcal{\hat Y=k})\)</span> que es la suma de los elementos del primer renglón de la tabla anterior.</p>
<section id="sec-error" class="level3" data-number="4.2.1">
<h3 data-number="4.2.1" class="anchored" data-anchor-id="sec-error"><span class="header-section-number">4.2.1</span> Error</h3>
<p>Se empieza la descripción con el error de clasificación (<a href="02Teoria_Decision.html#sec-error-clasificacion" class="quarto-xref"><span>Sección 2.4</span></a>) el cual es la proporción de errores y se puede definir como</p>
<p><span class="math display">\[
\textsf{error}(\mathcal Y, \mathcal{\hat Y}) = 1 -  \textsf{accuracy}(\mathcal Y, \mathcal{\hat Y}).
\]</span></p>
</section>
<section id="sec-accuracy" class="level3" data-number="4.2.2">
<h3 data-number="4.2.2" class="anchored" data-anchor-id="sec-accuracy"><span class="header-section-number">4.2.2</span> Exactitud (<em>Accuracy</em>)</h3>
<p>El error se define mediante la exactitud. La exactitud es la proporción de ejemplos correctamente clasificados, utilizando la notación de la tabla de confusión quedaría como:</p>
<p><span class="math display">\[
\textsf{accuracy}(\mathcal Y, \mathcal{\hat Y}) = \mathbb P(\mathcal Y=p, \mathcal{\hat Y}=p) + \mathbb P(\mathcal Y=n, \mathcal{\hat Y}=n).
\]</span></p>
<p>Una manera equivalente de ver la exactitud es utilizando la probabilidad condicional, es decir,</p>
<p><span class="math display">\[
\begin{split}
\textsf{accuracy}(\mathcal Y, \mathcal{\hat Y}) &amp;= \mathbb P( \mathcal{\hat Y}=p \mid \mathcal Y=p)\mathbb P(\mathcal Y=p)\\
&amp;+ \mathbb P(\mathcal{\hat Y}=n \mid \mathcal Y=n)\mathbb P(\mathcal Y=n).
\end{split}
\]</span></p>
<p>Esta manera ayuda a entender el caso cuando se tiene una clase con muchos ejemplos, e.g., <span class="math inline">\(\mathbb P(\mathcal Y=p) \gg \mathbb P(\mathcal Y=n),\)</span> en ese caso se ve que la exactitud está dominado por el primer término, i.e., <span class="math inline">\(\mathbb P( \mathcal{\hat Y}=p \mid \mathcal Y=p)\mathbb P(\mathcal Y=p).\)</span> En este caso, la manera trivial de optimizar la exactitud es crear un clasificador que siempre regrese la clase <span class="math inline">\(p.\)</span> Por esta razón la exactitud no es una medida adecuada cuando las clases son desbalanciadas, es buena medida cuando <span class="math inline">\(\mathbb P(\mathcal Y=p) \approx \mathbb P(\mathcal Y=n).\)</span></p>
</section>
<section id="sec-recall" class="level3" data-number="4.2.3">
<h3 data-number="4.2.3" class="anchored" data-anchor-id="sec-recall"><span class="header-section-number">4.2.3</span> Coberturba (<em>Recall</em>)</h3>
<p>La siguiente medida de rendimiento es el recall, este calcula la probabilidad de ejemplos correctamente clasificados como <span class="math inline">\(p\)</span> dados todos los ejemplos que se tienen de la clase <span class="math inline">\(p\)</span>. En base a esta ecuación se puede observar que un algoritmo trivial con el máximo valor de recall solamente tiene que predecir como clase <span class="math inline">\(p\)</span> todos los elementos.</p>
<p>La segunda ecuación ayuda a medir en base de la tabla de confusión.</p>
<p><span id="eq-recall"><span class="math display">\[
\begin{split}
\textsf{recall}_p(\mathcal Y, \mathcal{\hat Y}) &amp;= \mathbb P(\mathcal{\hat Y}=p \mid \mathcal{Y}=p) \\
&amp;= \frac{\mathbb P(\mathcal{\hat Y}=p, \mathcal{Y}=p)}{\mathbb P(\mathcal Y=p)}
\end{split}
\tag{4.1}\]</span></span></p>
</section>
<section id="sec-precision" class="level3" data-number="4.2.4">
<h3 data-number="4.2.4" class="anchored" data-anchor-id="sec-precision"><span class="header-section-number">4.2.4</span> Precisión (<em>Precision</em>)</h3>
<p>La precisión complementa el recall, al calcular la probabilidad de los ejemplos correctamente clasificados como <span class="math inline">\(p\)</span> dadas las predicciones de los ejemplos. Es decir, en la probabilidad condicional se observa que se conocen las predicciones positivas y de esas predicciones se mide si estas son correctamente clasificadas. Basándose en esto, se puede ver que una manera de generar un algoritmo competitivo en esta media corresponde a predecir la clase solo cuando exista una gran seguridad de la clase.</p>
<p><span id="eq-precision"><span class="math display">\[
\begin{split}
\textsf{precision}_p(\mathcal Y, \mathcal{\hat Y}) &amp;= \mathbb P(\mathcal Y=p \mid \mathcal{\hat Y}=p)\\
&amp;= \frac{\mathbb P(\mathcal Y=p, \mathcal{\hat Y}=p)}{\mathbb P(\mathcal{\hat Y}=p)}
\end{split}
\tag{4.2}\]</span></span></p>
</section>
<section id="sec-f1" class="level3" data-number="4.2.5">
<h3 data-number="4.2.5" class="anchored" data-anchor-id="sec-f1"><span class="header-section-number">4.2.5</span> <span class="math inline">\(F_\beta\)</span></h3>
<p>Finalmente, una manera de combinar el recall (<a href="#eq-recall" class="quarto-xref">Ecuación&nbsp;<span>4.1</span></a>) con la precisión (<a href="#eq-precision" class="quarto-xref">Ecuación&nbsp;<span>4.2</span></a>) es la medida <span class="math inline">\(F_\beta\)</span>, es probable que esta medida se reconozca más cuando <span class="math inline">\(\beta=1\)</span>. La idea de <span class="math inline">\(\beta\)</span> es ponderar el peso que se le quiere dar a la precisión con respecto al recall.</p>
<p><span id="eq-f1"><span class="math display">\[
F^p_\beta(\mathcal Y, \mathcal{\hat Y}) = (1 + \beta^2) \frac{\textsf{precision}_p(\mathcal Y, \mathcal{\hat Y}) \cdot \textsf{recall}_p(\mathcal Y, \mathcal{\hat Y})}{\beta^2 \cdot \textsf{precision}_p(\mathcal Y, \mathcal{\hat Y}) + \textsf{recall}_p(\mathcal Y, \mathcal{\hat Y})}
\tag{4.3}\]</span></span></p>
</section>
<section id="sec-macro" class="level3" data-number="4.2.6">
<h3 data-number="4.2.6" class="anchored" data-anchor-id="sec-macro"><span class="header-section-number">4.2.6</span> Medidas Macro</h3>
<p>En las definiciones de precisión (<a href="#eq-precision" class="quarto-xref">Ecuación&nbsp;<span>4.2</span></a>), recall (<a href="#eq-recall" class="quarto-xref">Ecuación&nbsp;<span>4.1</span></a>) y <span class="math inline">\(F_\beta\)</span> (<a href="#eq-f1" class="quarto-xref">Ecuación&nbsp;<span>4.3</span></a>) se ha usado un subíndice y superíndice con la letra <span class="math inline">\(p\)</span> esto es para indicar que la medida se está realizando con respecto a la clase <span class="math inline">\(p\)</span>. Esto ayuda también a ilustrar que en un problema de <span class="math inline">\(K\)</span> clases se tendrán <span class="math inline">\(K\)</span> diferentes medidas de precisión, recall y <span class="math inline">\(F_\beta;\)</span> cada una de esas medidas corresponde a cada clase.</p>
<p>En ocasiones es importante tener solamente una medida que englobe el rendimiento en el caso de los tres rendimientos que se han mencionado, se puede calcular su versión macro que es la media de la medida. Esto es para un problema de <span class="math inline">\(K\)</span> clases la precisión, recall y <span class="math inline">\(F_\beta\)</span> se definen de la siguiente manera.</p>
<p><span class="math display">\[
\textsf{macro-precision}(\mathcal Y, \mathcal{\hat Y}) =  \frac{1}{K}\sum_{k} \textsf{precision}_k(\mathcal Y, \mathcal{\hat Y}),
\]</span></p>
<p><span class="math display">\[
\textsf{macro-recall}(\mathcal Y, \mathcal{\hat Y}) =  \frac{1}{K}\sum_{k} \textsf{recall}_k(\mathcal Y, \mathcal{\hat Y}),
\]</span></p>
<p><span class="math display">\[
\textsf{macro-}F_\beta(\mathcal Y, \mathcal{\hat Y}) =  \frac{1}{K}\sum_{k} F^k_\beta(\mathcal Y, \mathcal{\hat Y}).
\]</span></p>
</section>
<section id="sec-entropia-cruzada" class="level3" data-number="4.2.7">
<h3 data-number="4.2.7" class="anchored" data-anchor-id="sec-entropia-cruzada"><span class="header-section-number">4.2.7</span> Entropía Cruzada</h3>
<p>Una función de costo que ha sido muy utilizada en redes neuronales y en particular en aprendizaje profundo es la <strong>Entropía Cruzada</strong> (Cross Entropy) que para una distribución discreta se define como: <span class="math inline">\(H(P, Q) = - \sum_x P(x) \log Q(x)\)</span>.</p>
<p>Para cada ejemplo <span class="math inline">\(x\)</span> se tiene <span class="math inline">\(\mathbb P(\mathcal Y=k \mid \mathcal X=x)\)</span> y el clasificador predice <span class="math inline">\(\mathbb{\hat P}(\mathcal Y=k \mid \mathcal X=x).\)</span> Utilizando estas definiciones se puede decir que <span class="math inline">\(P=\mathbb P\)</span> y <span class="math inline">\(Q=\mathbb{\hat P}\)</span> en la definición de entropía cruzada; entonces</p>
<p><span class="math display">\[
\begin{split}
H(\mathbb P(\mathcal Y \mid \mathcal X=x) &amp;, \mathbb{\hat P}(\mathcal Y \mid \mathcal X=x)) =\\
&amp;-\sum_k^K \mathbb P(\mathcal Y=k \mid \mathcal X=x) \log \mathbb{\hat P}(\mathcal Y=k \mid \mathcal X=x).
\end{split}
\]</span></p>
<p>Finalmente la medida de rendimiento quedaría como <span class="math inline">\(\sum_x H(\mathbb P(\mathcal Y \mid \mathcal X=x), \mathbb{\hat P}(\mathcal Y \mid \mathcal X=x)).\)</span></p>
</section>
<section id="sec-roc-curve" class="level3" data-number="4.2.8">
<h3 data-number="4.2.8" class="anchored" data-anchor-id="sec-roc-curve"><span class="header-section-number">4.2.8</span> Área Bajo la Curva <em>ROC</em></h3>
<p>El área bajo la curva <em>ROC</em> (<em>Relative Operating Characteristic</em>) es una medida de rendimiento que también está pasada en la probabilidad a posteriori <span class="math inline">\(\mathbb P(\mathcal Y \mid \mathcal X)\)</span> con la característica de que la clase se selecciona en base a un umbral <span class="math inline">\(\rho\)</span>. Es decir, dado un ejemplo <span class="math inline">\(x\)</span>, este ejemplo pertenece a la clase <span class="math inline">\(p\)</span> si <span class="math inline">\(\mathbb P(\mathcal Y=p \mid \mathcal X=x) \geq \rho.\)</span></p>
<p>Se observa que modificando el umbral <span class="math inline">\(\rho\)</span> se tienen diferentes tablas de confusión, para cada tabla de confusión posible se calcula la tasa de verdaderos positivos (TPR) que corresponde al recall (<a href="#sec-recall" class="quarto-xref"><span>Sección 4.2.3</span></a>), i.e., <span class="math inline">\(\mathbb P(\mathcal{\hat Y}=p \mid \mathcal Y=p),\)</span> y la tasa de falsos positivos (FPR) que es <span class="math inline">\(\mathbb P(\mathcal{\hat Y}=p \mid \mathcal Y=n).\)</span> Cada par de TPR y FPR representan un punto de la curva <em>ROC</em>. El rendimiento corresponde al área debajo de la curva delimitada por los pares TPR y FPR.</p>
</section>
<section id="ejemplo" class="level3" data-number="4.2.9">
<h3 data-number="4.2.9" class="anchored" data-anchor-id="ejemplo"><span class="header-section-number">4.2.9</span> Ejemplo</h3>
<p>El ejemplo de Breast Cancer Wisconsin (<a href="03Parametricos.html#sec-ejemplo-breast-cancer-wisconsin" class="quarto-xref"><span>Sección 3.8</span></a>) se utiliza para ilustrar el uso de la medidas de rendimiento presentadas hasta el momento.</p>
<div id="b6ef2f9d" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>D, y <span class="op">=</span> load_breast_cancer(return_X_y<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>T, G, y_t, y_g <span class="op">=</span> train_test_split(D, y, </span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>                                  random_state<span class="op">=</span><span class="dv">0</span>,  </span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>                                  test_size<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>gaussian <span class="op">=</span> GaussianBayes().fit(T, y_t)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>hy_gaussian <span class="op">=</span> gaussian.predict(G)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>El clasificador Gausiano tiene un <code>accuracy</code> de <span class="math inline">\(0.8947\)</span>, el cual se puede calcular con el siguiente código.</p>
<div id="5fddb4a4" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>accuracy <span class="op">=</span> metrics.accuracy_score(y_g, hy_gaussian)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Las medidas de <code>recall</code>, <code>precision</code> y <code>f1</code> se presentan en la <a href="#tbl-performance" class="quarto-xref">Tabla&nbsp;<span>4.3</span></a>, en la última columna se presenta el macro de cada una de las medidas.</p>
<div id="6f1b497c" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>recall <span class="op">=</span> metrics.recall_score(y_g, hy_gaussian,</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>                              average<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>precision <span class="op">=</span> metrics.precision_score(y_g, hy_gaussian,</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>                                    average<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>f1 <span class="op">=</span> metrics.f1_score(y_g, hy_gaussian,</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>                      average<span class="op">=</span><span class="va">None</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="7">
<div id="tbl-performance" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-execution_count="7">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-performance-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Tabla&nbsp;4.3: Rendimiento
</figcaption>
<div aria-describedby="tbl-performance-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output cell-output-display cell-output-markdown" data-execution_count="36">
<table class="do-not-create-environment cell caption-top table table-sm table-striped small">
<colgroup>
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th><span class="math inline">\(\mathcal Y=0\)</span></th>
<th>&nbsp;<span class="math inline">\(\mathcal Y=1\)</span></th>
<th>Macro</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>recall</code></td>
<td><span class="math inline">\(0.8298\)</span></td>
<td><span class="math inline">\(0.9403\)</span></td>
<td><span class="math inline">\(0.8850\)</span></td>
</tr>
<tr class="even">
<td><code>precision</code></td>
<td><span class="math inline">\(0.9070\)</span></td>
<td><span class="math inline">\(0.8873\)</span></td>
<td><span class="math inline">\(0.8972\)</span></td>
</tr>
<tr class="odd">
<td><code>f1</code></td>
<td><span class="math inline">\(0.8667\)</span></td>
<td><span class="math inline">\(0.9130\)</span></td>
<td><span class="math inline">\(0.8899\)</span></td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</div>
</div>
<p>Por otro lado la <code>entropia</code> cruzada es <span class="math inline">\(2.1071\)</span> que se puede calcular con el siguiente código.</p>
<div id="260773f6" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>prob <span class="op">=</span> gaussian.predict_proba(G)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>entropia <span class="op">=</span> metrics.log_loss(y_g, prob)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Complementando la información de las medidas que se calculan mediante la posteriori se encuentra la curva ROC, la cual se puede calcular con el siguiente código y se muestra en la <a href="#fig-roc-curve" class="quarto-xref">Figura&nbsp;<span>4.1</span></a></p>
<div id="cell-fig-roc-curve" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>fpr, tpr, thresholds <span class="op">=</span> metrics.roc_curve(y_g, prob[:, <span class="dv">1</span>])</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(<span class="bu">dict</span>(FPR<span class="op">=</span>fpr, TPR<span class="op">=</span>tpr))</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>sns.set_style(<span class="st">'whitegrid'</span>)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> sns.lineplot(df, x<span class="op">=</span><span class="st">'FPR'</span>, y<span class="op">=</span><span class="st">'TPR'</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div id="fig-roc-curve" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-roc-curve-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="04Rendimiento_files/figure-html/fig-roc-curve-output-1.png" width="585" height="427" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-roc-curve-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;4.1: ROC
</figcaption>
</figure>
</div>
</div>
</div>
<p>Teniendo un valor de área bajo la curva (<code>auc_score</code>) de <span class="math inline">\(0.9540\)</span> que se obtuvo de la siguiente manera.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>auc_score <span class="op">=</span> metrics.roc_auc_score(y_g, prob[:, <span class="dv">1</span>])</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Actividad
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Medir el rendimiento del Clasificador Gausiano Ingenuo (<a href="03Parametricos.html#sec-cl-bayesiano-ingenuo" class="quarto-xref"><span>Sección 3.7</span></a>) en el problema del del Iris (ver <a href="16ConjuntosDatos.html#sec-iris" class="quarto-xref"><span>Sección B.3.2</span></a>) utilizando la función <span class="math inline">\(F_\beta\)</span> (<a href="#sec-f1" class="quarto-xref"><span>Sección 4.2.5</span></a>) variando <span class="math inline">\(\beta\)</span> entre <span class="math inline">\([0, 1],\)</span> tal y como se muestra en la <a href="#fig-actividad-fbeta" class="quarto-xref">Figura&nbsp;<span>4.2</span></a></p>
<div id="cell-fig-actividad-fbeta" class="cell" data-execution_count="12">
<div class="cell-output cell-output-display">
<div id="fig-actividad-fbeta" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-actividad-fbeta-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="04Rendimiento_files/figure-html/fig-actividad-fbeta-output-1.png" width="567" height="470" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-actividad-fbeta-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;4.2: Rendimiento de un Clasificador Bayesiano Ingenuo en el problema del Iris estimado mediante una validación cruzada estratificada.
</figcaption>
</figure>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
</section>
<section id="sec-rendimiento-regresion" class="level2" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="sec-rendimiento-regresion"><span class="header-section-number">4.3</span> Regresión</h2>
<p>Con respecto a regresión las siguientes funciones son utilizadas como medidas de rendimiento.</p>
<p>Error cuadrático medio (Mean Square Error):</p>
<p><span id="eq-mse"><span class="math display">\[
\textsf{mse}(\mathcal Y, \mathcal{\hat Y}) = \frac{1}{N} \sum_{i=1}^N (\mathcal Y_i - \mathcal{\hat Y}_i)^2.
\tag{4.4}\]</span></span></p>
<p>Error absoluto medio (Mean Absolute Error):</p>
<p><span id="eq-mae"><span class="math display">\[
\textsf{mae}(\mathcal Y, \mathcal{\hat Y}) = \frac{1}{N} \sum_{i=1}^N \mid \mathcal Y_i - \mathcal{\hat Y}_i \mid.
\tag{4.5}\]</span></span></p>
<p>Media del porcentaje de error absoluto: <span id="eq-mape"><span class="math display">\[
\textsf{mape}(\mathcal Y, \mathcal{\hat Y}) = \frac{1}{N} \sum_{i=1}^N \mid \frac{\mathcal Y_i - \mathcal{\hat Y}_i}{\mathcal Y_i}\mid.
\tag{4.6}\]</span></span></p>
<p>La proporción de la varianza explicada por el modelo:</p>
<p><span id="eq-r2"><span class="math display">\[
R^2(\mathcal Y, \mathcal{\hat Y}) = 1 - \frac{\sum_{i=1}^N (\mathcal Y_i - \mathcal{\hat Y}_i)^2)}{\sum_{i=1}^N (\mathcal Y_i - \mathcal{\bar Y}_i)^2)}.
\tag{4.7}\]</span></span></p>
<section id="ejemplo-1" class="level3" data-number="4.3.1">
<h3 data-number="4.3.1" class="anchored" data-anchor-id="ejemplo-1"><span class="header-section-number">4.3.1</span> Ejemplo</h3>
<p>Las medidas anteriores se ejemplifican utilizando el ejemplo de diabetes(#sec-diabetes) que se puede descargar y modelar mediante OLS (<a href="03Parametricos.html#sec-regresion-ols" class="quarto-xref"><span>Sección 3.10</span></a>) de la siguiente manera.</p>
<div id="410c73e1" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> load_diabetes(return_X_y<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>T, G, y_t, y_g <span class="op">=</span> train_test_split(X, y,</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>                                  random_state<span class="op">=</span><span class="dv">0</span>,  </span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>                                  test_size<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> LinearRegression().fit(T, y_t) </span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>La predicción en el conjunto de prueba sería:</p>
<div id="0c68c98f" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>hy <span class="op">=</span> m.predict(G)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Las diferentes medidas de rendimiento para problemas de regresión se puede calcular de la siguiente manera.</p>
<p>El error cuadrático medio (<a href="#eq-mse" class="quarto-xref">Ecuación&nbsp;<span>4.4</span></a>), <code>mse</code> corresponde a</p>
<div id="9ec50469" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>mse <span class="op">=</span> metrics.mean_squared_error(y_g, hy)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>y tienen un valor de <span class="math inline">\(3424.2593\)</span>.</p>
<p>El error absoluto medio (<a href="#eq-mae" class="quarto-xref">Ecuación&nbsp;<span>4.5</span></a>), <code>mae</code>, tiene un valor de <span class="math inline">\(46.1736\)</span> calculado de la siguiente manera</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>mae <span class="op">=</span> metrics.mean_absolute_error(y_g, hy)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>La media del porcentaje de error absoluto (<a href="#eq-mape" class="quarto-xref">Ecuación&nbsp;<span>4.6</span></a>), <code>mape</code>, es <span class="math inline">\(0.3805\)</span> obtenido con el siguiente código</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>mape <span class="op">=</span> metrics.mean_absolute_percentage_error(y_g, hy)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Finalmente, la varianza explicada por el modelo <span class="math inline">\(R^2\)</span> (<a href="#eq-r2" class="quarto-xref">Ecuación&nbsp;<span>4.7</span></a>), <code>r2</code>, es <span class="math inline">\(0.3322\)</span></p>
<div class="sourceCode" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>r2 <span class="op">=</span> metrics.r2_score(y_g, hy)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="sec-validacion-cruzada" class="level2" data-number="4.4">
<h2 data-number="4.4" class="anchored" data-anchor-id="sec-validacion-cruzada"><span class="header-section-number">4.4</span> Conjunto de Validación y Validación Cruzada</h2>
<p>Antes de inicia la descripción de otro algoritmo para la selección de características es necesario describir otro conjunto que se utiliza para optimizar los hiperparámetros del algoritmo de aprendizaje. Previamente se describieron los conjuntos de Entrenamiento y Prueba (<a href="03Parametricos.html#sec-conjunto-entre-prueba" class="quarto-xref"><span>Sección 3.5</span></a>), i.e., <span class="math inline">\(\mathcal T\)</span> y <span class="math inline">\(\mathcal G\)</span>. En particular estos conjuntos se definieron utilizando todos los datos <span class="math inline">\(\mathcal D\)</span> con lo que se especifica el problema.</p>
<p>La mayoría de algoritmos de aprendizaje tiene hiperparámetros que pueden ser ajustados para optimizar su comportamiento al conjunto de datos que se está analizando. Estos hiperparámetros pueden estar dentro del algoritmo o pueden ser modificaciones al conjunto de datos para adecuarlos al algoritmo. El segundo caso es el que se analizará en esta unidad. Es decir, se seleccionarán las variables que facilitan el aprendizaje.</p>
<p>Para optimizar los parámetros es necesario medir el rendimiento del algoritmo, es decir, observar como se comporta el algoritmo en el proceso de predicción. La manera trivial sería utilizar el conjunto de prueba <span class="math inline">\(\mathcal G\)</span> para medir el rendimiento. Pero es necesario recordar que este conjunto no debe ser visto durante el aprendizaje y la optimización de los parámetros es parte de ese proceso. Si se usara <span class="math inline">\(\mathcal G\)</span> entonces dejaría de ser el conjunto de prueba y se tendría que seleccionar otro conjunto de prueba.</p>
<p>Entonces para optimizar los parámetros del algoritmo se selecciona del conjunto de entrenamiento, i.e., <span class="math inline">\(\mathcal T\)</span>, el <strong>conjunto de validación</strong>, <span class="math inline">\(\mathcal V\)</span>. Este conjunto tiene la característica que <span class="math inline">\(\mathcal T \cap \mathcal V \cap \mathcal G = \emptyset\)</span> y <span class="math inline">\(\mathcal T \cup \mathcal V \cup \mathcal G = \mathcal D.\)</span> Una manera de realizar estos es seleccionar primeramente el conjunto de prueba <span class="math inline">\(\mathcal G\)</span> y de los datos restantes generar los conjuntos de entrenamiento <span class="math inline">\(\mathcal T\)</span> y validación <span class="math inline">\(\mathcal V.\)</span></p>
<p>Para ejemplificar esta idea se utiliza el ejemplo de Breast Cancer Wisconsin (<a href="03Parametricos.html#sec-ejemplo-breast-cancer-wisconsin" class="quarto-xref"><span>Sección 3.8</span></a>) utilizando un Clasificador Bayesiano donde el hiperparámetro es si se utilizar un Bayesiano Ingenuo o se estima la matriz de covarianza.</p>
<p>El primer paso es obtener los datos del problema, lo cual se muestra en la siguiente instrucción.</p>
<div id="6ddfd0cf" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>D, y <span class="op">=</span> load_breast_cancer(return_X_y<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Con los datos <span class="math inline">\(\mathcal D\)</span> se genera el conjunto de prueba <span class="math inline">\(\mathcal G\)</span> y los datos para estimar los parámetros y optimizar los hiperparámetros del algoritmo. En la variable <code>T</code> se tiene los datos para encontrar el algoritmo y en <code>G</code> se tiene el conjunto de prueba.</p>
<div id="77cbaba5" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>T, G, y_t, y_g <span class="op">=</span> train_test_split(D, y,</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>                                  random_state<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>                                  test_size<span class="op">=</span><span class="fl">0.2</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Los datos de entrenamiento y validación se generan de manera equivalente tal como se muestra en la siguiente instrucción. El conjunto de validación (<span class="math inline">\(\mathcal V\)</span>) se encuentra en la variable <code>V</code> y la variable dependiente en <code>y_v.</code></p>
<div id="f819be6a" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>T, V, y_t, y_v <span class="op">=</span> train_test_split(T, y_t,</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>                                  random_state<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>                                  test_size<span class="op">=</span><span class="fl">0.3</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>En este momento ya se tienen todos los elementos para medir el rendimiento de cada hiperparámetro. Empezando por el clasificador con la matriz de covarianza completa. El recall en ambas clases es [0.9615, 0.8824].</p>
<div id="ea88762d" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>gaussian <span class="op">=</span> GaussianBayes().fit(T, y_t)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>hy_gaussian <span class="op">=</span> gaussian.predict(V)</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>recall <span class="op">=</span> recall_score(y_v, hy_gaussian, average<span class="op">=</span><span class="va">None</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>La segunda opción es utilizar un clasificador Bayesiano Ingenuo, el cual se especifica con el parámetro <code>naive</code> tal y como se muestra en las siguientes instrucciones. El recall en las dos clases es [0.8654, 0.9765].</p>
<div id="7cd50add" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>ingenuo <span class="op">=</span> GaussianBayes(naive<span class="op">=</span><span class="va">True</span>).fit(T, y_t)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>hy_ingenuo <span class="op">=</span> ingenuo.predict(V)</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> recall_score(y_v, hy_ingenuo, average<span class="op">=</span><span class="va">None</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Comparando el rendimiento de los dos hiperparámetros se observa cual de los dos modelos obtiene el mejor rendimiento. Con el fin de completar el ejemplo se describe calcular el rendimiento en <span class="math inline">\(\mathcal G\)</span> del algoritmo con la matriz de covarianza completa. Este algoritmo tiene un rendimiento de [0.8298, 0.9403] que se puede calcular con el siguiente código.</p>
<div id="608f4772" class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>gaussian <span class="op">=</span> GaussianBayes().fit(np.concatenate((T, V)),</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>                               np.concatenate((y_t, y_v)))</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>hy_gaussian <span class="op">=</span> gaussian.predict(G)</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> recall_score(y_g, hy_gaussian, average<span class="op">=</span><span class="va">None</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="sec-kfold-cross-validation" class="level3" data-number="4.4.1">
<h3 data-number="4.4.1" class="anchored" data-anchor-id="sec-kfold-cross-validation"><span class="header-section-number">4.4.1</span> k-Iteraciones de Validación Cruzada</h3>
<p>Cuando se cuenta con pocos datos para medir el rendimiento del algoritmo es común utilizar la técnica de <em>k-fold cross-validation</em> la cual consiste en partir <span class="math inline">\(k\)</span> veces el conjunto de entrenamiento para generar <span class="math inline">\(k\)</span> conjuntos de entrenamiento y validación.</p>
<p>La idea se ilustra con la siguiente tabla, donde se asume que los datos son divididos en 5 bloques (<span class="math inline">\(k=5\)</span>), cada columna de la tabla ilustra los datos de ese bloque. Si los datos se dividen en <span class="math inline">\(k=5\)</span> bloques, entonces existen <span class="math inline">\(k\)</span> iteraciones que son representadas por cada renglón de la siguiente tabla, quitando el encabezado de la misma. La letra en cada celda identifica el uso que se le dará a esos datos en la respectiva iteración, es decir, <span class="math inline">\(\mathcal T\)</span> representa que se usará como conjunto de entrenamiento y <span class="math inline">\(\mathcal V\)</span> se usa para identificar aquellos datos que se usarán como conjunto de validación.</p>
<p>La idea es entrenar y probar el rendimiento del algoritmo <span class="math inline">\(k\)</span> veces usando las particiones en cada renglón. Es decir, la primera vez se usan los datos de la primera columna como el conjunto de validación, y el resto de columnas, <span class="math inline">\([2, 3, 4, 5]\)</span>, como conjunto de entrenamiento para estimar los parámetros del algoritmo. En la segunda iteración se usan los datos del segundo renglón donde se observa que los datos en la cuarta columna corresponden al conjunto de validación y los datos en las columnas <span class="math inline">\([1, 2, 3, 5]\)</span> son usados como conjunto de prueba. Las iteraciones siguen hasta que todos los datos fueron utilizados en una ocasión como conjunto de validación.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(\mathcal V\)</span></td>
<td><span class="math inline">\(\mathcal T\)</span></td>
<td><span class="math inline">\(\mathcal T\)</span></td>
<td><span class="math inline">\(\mathcal T\)</span></td>
<td><span class="math inline">\(\mathcal T\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\mathcal T\)</span></td>
<td><span class="math inline">\(\mathcal T\)</span></td>
<td><span class="math inline">\(\mathcal T\)</span></td>
<td><span class="math inline">\(\mathcal V\)</span></td>
<td><span class="math inline">\(\mathcal T\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\mathcal T\)</span></td>
<td><span class="math inline">\(\mathcal T\)</span></td>
<td><span class="math inline">\(\mathcal V\)</span></td>
<td><span class="math inline">\(\mathcal T\)</span></td>
<td><span class="math inline">\(\mathcal T\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\mathcal T\)</span></td>
<td><span class="math inline">\(\mathcal T\)</span></td>
<td><span class="math inline">\(\mathcal T\)</span></td>
<td><span class="math inline">\(\mathcal T\)</span></td>
<td><span class="math inline">\(\mathcal V\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\mathcal T\)</span></td>
<td><span class="math inline">\(\mathcal V\)</span></td>
<td><span class="math inline">\(\mathcal T\)</span></td>
<td><span class="math inline">\(\mathcal T\)</span></td>
<td><span class="math inline">\(\mathcal T\)</span></td>
</tr>
</tbody>
</table>
<p>Se utiliza el mismo problema para medir el rendimiento del hiperparámetro del clasificador Gausiano. Lo primero es seleccionar el conjunto de prueba (<span class="math inline">\(\mathcal G\)</span>) que se realiza con el siguiente código.</p>
<div id="5c4973ff" class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>T, G, y_t, y_g <span class="op">=</span> train_test_split(D, y,</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>                                  random_state<span class="op">=</span><span class="dv">0</span>,  </span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>                                  test_size<span class="op">=</span><span class="fl">0.2</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>La validación cruzada con k-iteraciones se puede realizar con la clase <code>KFold</code> de la siguiente manera. La primera línea crear una variable para guardar el rendimiento. En la segunda línea se inicializa el procedimiento indicando que los datos sean tomados al azar. Después se realiza el ciclo con las <span class="math inline">\(k\)</span> iteraciones, para cada iteración se genera un índice <code>ts</code> que indica cuales son los datos del conjunto de entrenamiento y <code>vs</code> que corresponde a los datos de validación. Se estiman los parámetros usando <code>ts</code> tal y como se observa en la cuarta línea. Habiendo estimado los parámetros se predicen los datos del conjunto de validación (5 línea), se mide el recall en todas las clases y se guarda en la lista <code>perf.</code> Al final se calcula la media de los <span class="math inline">\(k\)</span> rendimientos medidos, teniendo un valor de [0.8903, 0.9174].</p>
<div id="2444cadc" class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>perf <span class="op">=</span> []</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>kfold <span class="op">=</span> KFold(shuffle<span class="op">=</span><span class="va">True</span>, random_state<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ts, vs <span class="kw">in</span> kfold.split(T):</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>    gaussian <span class="op">=</span> GaussianBayes().fit(T[ts], y_t[ts])</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>    hy_gaussian <span class="op">=</span> gaussian.predict(T[vs])</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>    _ <span class="op">=</span> recall_score(y_t[vs], hy_gaussian, average<span class="op">=</span><span class="va">None</span>)    </span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>    perf.append(_)</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>perf <span class="op">=</span> np.mean(perf, axis<span class="op">=</span><span class="dv">0</span>)    </span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Un procedimiento equivalente se realiza para el caso del clasificador Bayesiano Ingenuo tal y como se muestra a continuación. La media del recall en las clases es [0.8260, 0.9785] Se observa que el clasificador Bayesiano con la matriz de covarianza tiene un mejor rendimiento en validación que el clasificador Bayesiano Ingenuo. El último paso sería calcular el rendimiento en el conjunto <span class="math inline">\(\mathcal G\)</span> lo cual fue presentado anteriormente.</p>
<div id="68ddb55f" class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>perf <span class="op">=</span> []</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>kfold <span class="op">=</span> KFold(shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ts, vs <span class="kw">in</span> kfold.split(T):</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>    gaussian <span class="op">=</span> GaussianBayes(naive<span class="op">=</span><span class="va">True</span>).fit(T[ts], y_t[ts])</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>    hy_gaussian <span class="op">=</span> gaussian.predict(T[vs])</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>    _ <span class="op">=</span> recall_score(y_t[vs], hy_gaussian, average<span class="op">=</span><span class="va">None</span>)    </span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>    perf.append(_)</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>perf <span class="op">=</span> np.mean(perf, axis<span class="op">=</span><span class="dv">0</span>)  </span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>


<!-- -->

<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-10.1145/2808194.2809449" class="csl-entry" role="listitem">
Sebastiani, Fabrizio. 2015. <span>«An Axiomatically Derived Measure for the Evaluation of Classification Algorithms»</span>. En <em>Proceedings of the 2015 International Conference on The Theory of Information Retrieval</em>, 11-20. ICTIR ’15. New York, NY, USA: Association for Computing Machinery. <a href="https://doi.org/10.1145/2808194.2809449">https://doi.org/10.1145/2808194.2809449</a>.
</div>
</div>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copiado");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copiado");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/ingeotec\.github\.io\/AprendizajeComputacional");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../capitulos/03Parametricos.html" class="pagination-link" aria-label="Métodos Paramétricos">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Métodos Paramétricos</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../capitulos/05ReduccionDim.html" class="pagination-link" aria-label="Reducción de Dimensión">
        <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Reducción de Dimensión</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Ejecutar el código</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb23" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># Rendimiento</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>El **objetivo** es contrastar las características de diferentes medidas de rendimiento en aprendizaje supervisado así como simular un procedimiento de aprendizaje supervisado. </span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="fu">## Paquetes usados {.unnumbered}</span></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> EvoMSA.model <span class="im">import</span> GaussianBayes</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_breast_cancer,<span class="op">\</span></span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>                             load_diabetes</span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> recall_score</span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split, KFold</span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> metrics</span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> pylab <span class="im">as</span> plt</span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb23-22"><a href="#cb23-22" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-23"><a href="#cb23-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-26"><a href="#cb23-26" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-27"><a href="#cb23-27" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb23-28"><a href="#cb23-28" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> Markdown</span>
<span id="cb23-29"><a href="#cb23-29" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-30"><a href="#cb23-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-31"><a href="#cb23-31" aria-hidden="true" tabindex="-1"></a>::: {.content-visible when-format="html"}</span>
<span id="cb23-32"><a href="#cb23-32" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb23-33"><a href="#cb23-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-34"><a href="#cb23-34" aria-hidden="true" tabindex="-1"></a>{{&lt; video https://www.youtube.com/embed/NUbGplcMRmw width="560" height="315" &gt;}}</span>
<span id="cb23-35"><a href="#cb23-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-36"><a href="#cb23-36" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb23-37"><a href="#cb23-37" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb23-38"><a href="#cb23-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-39"><a href="#cb23-39" aria-hidden="true" tabindex="-1"></a><span class="fu">## Introducción {#sec-intro-04}</span></span>
<span id="cb23-40"><a href="#cb23-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-41"><a href="#cb23-41" aria-hidden="true" tabindex="-1"></a>Es importante conocer el rendimiento del algoritmo de aprendizaje computacional desarrollado. En aprendizaje supervisado la medición se hace mediante el conjunto de prueba, $\mathcal G$, mientras que en aprendizaje no supervisado es posible utilizar el conjunto de entrenamiento $\mathcal T$ o utilizar un conjunto de prueba. Es importante notar que aunque en el proceso de entrenamiento puede usar una función de rendimiento para estimar o encontrar el algoritmo que modela los datos, es importante complementar esta medición con otras funciones de rendimiento. Esta unidad describe algunas de las medidas más utilizadas para medir el rendimiento de algoritmos de clasificación y regresión. </span>
<span id="cb23-42"><a href="#cb23-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-43"><a href="#cb23-43" aria-hidden="true" tabindex="-1"></a><span class="fu">## Clasificación {#sec-clasificacion}</span></span>
<span id="cb23-44"><a href="#cb23-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-45"><a href="#cb23-45" aria-hidden="true" tabindex="-1"></a>En clasificación existen diferentes medidas de rendimiento, algunas de ellas son exactitud (*accuracy*), precisión (*precision*), recall, y $F_1$, entre otras. @10.1145/2808194.2809449 describe de manera axiomática algunas de estas medidas y se dan recomendaciones en general sobre medidas de rendimiento para clasificadores. </span>
<span id="cb23-46"><a href="#cb23-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-47"><a href="#cb23-47" aria-hidden="true" tabindex="-1"></a>Varias de las medidas de rendimiento toman como insume la **Tabla de Confusión** (@tbl-confusion), la cual contiene la información del proceso de clasificación. La siguiente tabla muestra la estructura de esta tabla para un problema binario, donde se tiene una clase positiva identificada con $p$ y una clase negativa ($n$). La variable $\mathcal Y$ indica las clases reales y la variable $\mathcal{\hat Y}$ representa la estimación (predicción) hecha por el clasificador. Adicionalmente, la tabla se puede extender a $K$ clases siguiendo la misma estructura; la diagonal contienen los elementos correctamente identificados y los elementos fuera de la diagonal muestra los errores. </span>
<span id="cb23-48"><a href="#cb23-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-49"><a href="#cb23-49" aria-hidden="true" tabindex="-1"></a>|                |$\mathcal{\hat Y}=p$|$\mathcal{\hat Y}=n$|</span>
<span id="cb23-50"><a href="#cb23-50" aria-hidden="true" tabindex="-1"></a>|----------------|----------------------|----------------------|</span>
<span id="cb23-51"><a href="#cb23-51" aria-hidden="true" tabindex="-1"></a>|$\mathcal Y=p$|Verdaderos Pos.       |Falsos Neg.           |</span>
<span id="cb23-52"><a href="#cb23-52" aria-hidden="true" tabindex="-1"></a>|$\mathcal Y=n$|Falsos Pos.           |Verdaderos Neg.       |</span>
<span id="cb23-53"><a href="#cb23-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-54"><a href="#cb23-54" aria-hidden="true" tabindex="-1"></a>: Tabla de Confusión {#tbl-confusion}</span>
<span id="cb23-55"><a href="#cb23-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-56"><a href="#cb23-56" aria-hidden="true" tabindex="-1"></a>La tabla se puede ver como valores nominales, es decir contar el número de ejemplos clasificados como verdaderos positivos o como proporción de tal manera que las cuatro celdas sumen $1$. En esta descripción se asume que son proporcionen, esto porque se seguirá una interpretación probabilística descrita en <span class="co">[</span><span class="ot">este artículo</span><span class="co">](https://link.springer.com/chapter/10.1007/978-3-540-31865-1_25)</span> para presentar las diferentes medidas de rendimiento.</span>
<span id="cb23-57"><a href="#cb23-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-58"><a href="#cb23-58" aria-hidden="true" tabindex="-1"></a>Viendo la @tbl-confusion como una proporción y combinando con la interpretación probabilística la tabla quedaría de la siguiente manera.</span>
<span id="cb23-59"><a href="#cb23-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-60"><a href="#cb23-60" aria-hidden="true" tabindex="-1"></a>|                |$\mathcal{\hat Y}=p$|$\mathcal{\hat Y}=n$|</span>
<span id="cb23-61"><a href="#cb23-61" aria-hidden="true" tabindex="-1"></a>|----------------|----------------------|----------------------|</span>
<span id="cb23-62"><a href="#cb23-62" aria-hidden="true" tabindex="-1"></a>|$\mathcal Y=p$|$\mathbb P(\mathcal Y=p, \mathcal{\hat Y=p})$|$\mathbb P(\mathcal Y=p, \mathcal{\hat Y=n})$|</span>
<span id="cb23-63"><a href="#cb23-63" aria-hidden="true" tabindex="-1"></a>|$\mathcal Y=n$|$\mathbb P(\mathcal Y=n, \mathcal{\hat Y=p})$|$\mathbb P(\mathcal Y=n, \mathcal{\hat Y=n})$|</span>
<span id="cb23-64"><a href="#cb23-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-65"><a href="#cb23-65" aria-hidden="true" tabindex="-1"></a>: Tabla de Confusión como Proporción {#tbl-confusion-prob}</span>
<span id="cb23-66"><a href="#cb23-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-67"><a href="#cb23-67" aria-hidden="true" tabindex="-1"></a>Partiendo de la @tbl-confusion-prob se puede calcular la probabilidad marginal de cualquier variable y también las probabilidades condicionales, por ejemplo $\mathbb P(\mathcal Y=p) = \sum_k \mathbb P(\mathcal Y=p, \mathcal{\hat Y=k})$ que es la suma de los elementos del primer renglón de la tabla anterior.</span>
<span id="cb23-68"><a href="#cb23-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-69"><a href="#cb23-69" aria-hidden="true" tabindex="-1"></a><span class="fu">### Error {#sec-error }</span></span>
<span id="cb23-70"><a href="#cb23-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-71"><a href="#cb23-71" aria-hidden="true" tabindex="-1"></a>Se empieza la descripción con el error de clasificación (@sec-error-clasificacion) el cual es la proporción de errores y se puede definir como</span>
<span id="cb23-72"><a href="#cb23-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-73"><a href="#cb23-73" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-74"><a href="#cb23-74" aria-hidden="true" tabindex="-1"></a>\textsf{error}(\mathcal Y, \mathcal{\hat Y}) = 1 -  \textsf{accuracy}(\mathcal Y, \mathcal{\hat Y}).</span>
<span id="cb23-75"><a href="#cb23-75" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-76"><a href="#cb23-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-77"><a href="#cb23-77" aria-hidden="true" tabindex="-1"></a><span class="fu">### Exactitud (*Accuracy*) {#sec-accuracy}</span></span>
<span id="cb23-78"><a href="#cb23-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-79"><a href="#cb23-79" aria-hidden="true" tabindex="-1"></a>El error se define mediante la exactitud. La exactitud es la proporción de ejemplos correctamente clasificados, utilizando la notación de la tabla de confusión quedaría como:</span>
<span id="cb23-80"><a href="#cb23-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-81"><a href="#cb23-81" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-82"><a href="#cb23-82" aria-hidden="true" tabindex="-1"></a>\textsf{accuracy}(\mathcal Y, \mathcal{\hat Y}) = \mathbb P(\mathcal Y=p, \mathcal{\hat Y}=p) + \mathbb P(\mathcal Y=n, \mathcal{\hat Y}=n).</span>
<span id="cb23-83"><a href="#cb23-83" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-84"><a href="#cb23-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-85"><a href="#cb23-85" aria-hidden="true" tabindex="-1"></a>Una manera equivalente de ver la exactitud es utilizando la probabilidad condicional, es decir, </span>
<span id="cb23-86"><a href="#cb23-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-87"><a href="#cb23-87" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-88"><a href="#cb23-88" aria-hidden="true" tabindex="-1"></a>\begin{split}</span>
<span id="cb23-89"><a href="#cb23-89" aria-hidden="true" tabindex="-1"></a>\textsf{accuracy}(\mathcal Y, \mathcal{\hat Y}) &amp;= \mathbb P( \mathcal{\hat Y}=p \mid \mathcal Y=p)\mathbb P(\mathcal Y=p)<span class="sc">\\</span> </span>
<span id="cb23-90"><a href="#cb23-90" aria-hidden="true" tabindex="-1"></a>&amp;+ \mathbb P(\mathcal{\hat Y}=n \mid \mathcal Y=n)\mathbb P(\mathcal Y=n).</span>
<span id="cb23-91"><a href="#cb23-91" aria-hidden="true" tabindex="-1"></a>\end{split}</span>
<span id="cb23-92"><a href="#cb23-92" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-93"><a href="#cb23-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-94"><a href="#cb23-94" aria-hidden="true" tabindex="-1"></a>Esta manera ayuda a entender el caso cuando se tiene una clase con muchos ejemplos, e.g., $\mathbb P(\mathcal Y=p) \gg \mathbb P(\mathcal Y=n),$ en ese caso se ve que la exactitud está dominado por el primer término, i.e., $\mathbb P( \mathcal{\hat Y}=p \mid \mathcal Y=p)\mathbb P(\mathcal Y=p).$ En este caso, la manera trivial de optimizar la exactitud es crear un clasificador que siempre regrese la clase $p.$ Por esta razón la exactitud no es una medida adecuada cuando las clases son desbalanciadas, es buena medida cuando $\mathbb P(\mathcal Y=p) \approx \mathbb P(\mathcal Y=n).$</span>
<span id="cb23-95"><a href="#cb23-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-96"><a href="#cb23-96" aria-hidden="true" tabindex="-1"></a><span class="fu">### Coberturba (*Recall*) {#sec-recall}</span></span>
<span id="cb23-97"><a href="#cb23-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-98"><a href="#cb23-98" aria-hidden="true" tabindex="-1"></a>La siguiente medida de rendimiento es el recall, este calcula la probabilidad de ejemplos correctamente clasificados como $p$ dados todos los ejemplos que se tienen de la clase $p$. En base a esta ecuación se puede observar que un algoritmo trivial con el máximo valor de recall solamente tiene que predecir como clase $p$ todos los elementos. </span>
<span id="cb23-99"><a href="#cb23-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-100"><a href="#cb23-100" aria-hidden="true" tabindex="-1"></a>La segunda ecuación ayuda a medir en base de la tabla de confusión.</span>
<span id="cb23-101"><a href="#cb23-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-102"><a href="#cb23-102" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-103"><a href="#cb23-103" aria-hidden="true" tabindex="-1"></a>\begin{split}</span>
<span id="cb23-104"><a href="#cb23-104" aria-hidden="true" tabindex="-1"></a>\textsf{recall}_p(\mathcal Y, \mathcal{\hat Y}) &amp;= \mathbb P(\mathcal{\hat Y}=p \mid \mathcal{Y}=p) <span class="sc">\\</span></span>
<span id="cb23-105"><a href="#cb23-105" aria-hidden="true" tabindex="-1"></a>&amp;= \frac{\mathbb P(\mathcal{\hat Y}=p, \mathcal{Y}=p)}{\mathbb P(\mathcal Y=p)}</span>
<span id="cb23-106"><a href="#cb23-106" aria-hidden="true" tabindex="-1"></a>\end{split}</span>
<span id="cb23-107"><a href="#cb23-107" aria-hidden="true" tabindex="-1"></a>$$ {#eq-recall}</span>
<span id="cb23-108"><a href="#cb23-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-109"><a href="#cb23-109" aria-hidden="true" tabindex="-1"></a><span class="fu">### Precisión (*Precision*) {#sec-precision}</span></span>
<span id="cb23-110"><a href="#cb23-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-111"><a href="#cb23-111" aria-hidden="true" tabindex="-1"></a>La precisión complementa el recall, al calcular la probabilidad de los ejemplos correctamente clasificados como $p$ dadas las predicciones de los ejemplos. Es decir, en la probabilidad condicional se observa que se conocen las predicciones positivas y de esas predicciones se mide si estas son correctamente clasificadas. Basándose en esto, se puede ver que una manera de generar un algoritmo competitivo en esta media corresponde a predecir la clase solo cuando exista una gran seguridad de la clase. </span>
<span id="cb23-112"><a href="#cb23-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-113"><a href="#cb23-113" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-114"><a href="#cb23-114" aria-hidden="true" tabindex="-1"></a>\begin{split}</span>
<span id="cb23-115"><a href="#cb23-115" aria-hidden="true" tabindex="-1"></a>\textsf{precision}_p(\mathcal Y, \mathcal{\hat Y}) &amp;= \mathbb P(\mathcal Y=p \mid \mathcal{\hat Y}=p)<span class="sc">\\</span></span>
<span id="cb23-116"><a href="#cb23-116" aria-hidden="true" tabindex="-1"></a>&amp;= \frac{\mathbb P(\mathcal Y=p, \mathcal{\hat Y}=p)}{\mathbb P(\mathcal{\hat Y}=p)}</span>
<span id="cb23-117"><a href="#cb23-117" aria-hidden="true" tabindex="-1"></a>\end{split}</span>
<span id="cb23-118"><a href="#cb23-118" aria-hidden="true" tabindex="-1"></a>$$ {#eq-precision}</span>
<span id="cb23-119"><a href="#cb23-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-120"><a href="#cb23-120" aria-hidden="true" tabindex="-1"></a><span class="fu">### $F_\beta$ {#sec-f1}</span></span>
<span id="cb23-121"><a href="#cb23-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-122"><a href="#cb23-122" aria-hidden="true" tabindex="-1"></a>Finalmente, una manera de combinar el recall (@eq-recall) con la precisión (@eq-precision) es la medida $F_\beta$, es probable que esta medida se reconozca más cuando $\beta=1$. La idea de $\beta$ es ponderar el peso que se le quiere dar a la precisión con respecto al recall.</span>
<span id="cb23-123"><a href="#cb23-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-124"><a href="#cb23-124" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-125"><a href="#cb23-125" aria-hidden="true" tabindex="-1"></a>F^p_\beta(\mathcal Y, \mathcal{\hat Y}) = (1 + \beta^2) \frac{\textsf{precision}_p(\mathcal Y, \mathcal{\hat Y}) \cdot \textsf{recall}_p(\mathcal Y, \mathcal{\hat Y})}{\beta^2 \cdot \textsf{precision}_p(\mathcal Y, \mathcal{\hat Y}) + \textsf{recall}_p(\mathcal Y, \mathcal{\hat Y})}</span>
<span id="cb23-126"><a href="#cb23-126" aria-hidden="true" tabindex="-1"></a>$$ {#eq-f1}</span>
<span id="cb23-127"><a href="#cb23-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-128"><a href="#cb23-128" aria-hidden="true" tabindex="-1"></a><span class="fu">### Medidas Macro {#sec-macro}</span></span>
<span id="cb23-129"><a href="#cb23-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-130"><a href="#cb23-130" aria-hidden="true" tabindex="-1"></a>En las definiciones de precisión (@eq-precision), recall (@eq-recall) y $F_\beta$ (@eq-f1) se ha usado un subíndice y superíndice con la letra $p$ esto es para indicar que la medida se está realizando con respecto a la clase $p$. Esto ayuda también a ilustrar que en un problema de $K$ clases se tendrán $K$ diferentes medidas de precisión, recall y $F_\beta;$ cada una de esas medidas corresponde a cada clase. </span>
<span id="cb23-131"><a href="#cb23-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-132"><a href="#cb23-132" aria-hidden="true" tabindex="-1"></a>En ocasiones es importante tener solamente una medida que englobe el rendimiento en el caso de los tres rendimientos que se han mencionado, se puede calcular su versión macro que es la media de la medida. Esto es para un problema de $K$ clases la precisión, recall y $F_\beta$ se definen de la siguiente manera.</span>
<span id="cb23-133"><a href="#cb23-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-134"><a href="#cb23-134" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-135"><a href="#cb23-135" aria-hidden="true" tabindex="-1"></a>\textsf{macro-precision}(\mathcal Y, \mathcal{\hat Y}) =  \frac{1}{K}\sum_{k} \textsf{precision}_k(\mathcal Y, \mathcal{\hat Y}),</span>
<span id="cb23-136"><a href="#cb23-136" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb23-137"><a href="#cb23-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-138"><a href="#cb23-138" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-139"><a href="#cb23-139" aria-hidden="true" tabindex="-1"></a>\textsf{macro-recall}(\mathcal Y, \mathcal{\hat Y}) =  \frac{1}{K}\sum_{k} \textsf{recall}_k(\mathcal Y, \mathcal{\hat Y}),</span>
<span id="cb23-140"><a href="#cb23-140" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb23-141"><a href="#cb23-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-142"><a href="#cb23-142" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-143"><a href="#cb23-143" aria-hidden="true" tabindex="-1"></a>\textsf{macro-}F_\beta(\mathcal Y, \mathcal{\hat Y}) =  \frac{1}{K}\sum_{k} F^k_\beta(\mathcal Y, \mathcal{\hat Y}).</span>
<span id="cb23-144"><a href="#cb23-144" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb23-145"><a href="#cb23-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-146"><a href="#cb23-146" aria-hidden="true" tabindex="-1"></a><span class="fu">### Entropía Cruzada {#sec-entropia-cruzada}</span></span>
<span id="cb23-147"><a href="#cb23-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-148"><a href="#cb23-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-149"><a href="#cb23-149" aria-hidden="true" tabindex="-1"></a>Una función de costo que ha sido muy utilizada en redes neuronales y en particular en aprendizaje profundo es la **Entropía Cruzada** (Cross Entropy) que para una distribución discreta se define como: $H(P, Q) = - \sum_x P(x) \log Q(x)$. </span>
<span id="cb23-150"><a href="#cb23-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-151"><a href="#cb23-151" aria-hidden="true" tabindex="-1"></a>Para cada ejemplo $x$ se tiene $\mathbb P(\mathcal Y=k \mid \mathcal X=x)$ y el clasificador predice $\mathbb{\hat P}(\mathcal Y=k \mid \mathcal X=x).$ Utilizando estas definiciones se puede decir que $P=\mathbb P$ y $Q=\mathbb{\hat P}$ en la definición de entropía cruzada; entonces</span>
<span id="cb23-152"><a href="#cb23-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-153"><a href="#cb23-153" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-154"><a href="#cb23-154" aria-hidden="true" tabindex="-1"></a>\begin{split}</span>
<span id="cb23-155"><a href="#cb23-155" aria-hidden="true" tabindex="-1"></a>H(\mathbb P(\mathcal Y \mid \mathcal X=x) &amp;, \mathbb{\hat P}(\mathcal Y \mid \mathcal X=x)) =<span class="sc">\\</span> </span>
<span id="cb23-156"><a href="#cb23-156" aria-hidden="true" tabindex="-1"></a>&amp;-\sum_k^K \mathbb P(\mathcal Y=k \mid \mathcal X=x) \log \mathbb{\hat P}(\mathcal Y=k \mid \mathcal X=x).</span>
<span id="cb23-157"><a href="#cb23-157" aria-hidden="true" tabindex="-1"></a>\end{split}</span>
<span id="cb23-158"><a href="#cb23-158" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-159"><a href="#cb23-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-160"><a href="#cb23-160" aria-hidden="true" tabindex="-1"></a>Finalmente la medida de rendimiento quedaría como $\sum_x H(\mathbb P(\mathcal Y \mid \mathcal X=x), \mathbb{\hat P}(\mathcal Y \mid \mathcal X=x)).$ </span>
<span id="cb23-161"><a href="#cb23-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-162"><a href="#cb23-162" aria-hidden="true" tabindex="-1"></a><span class="fu">### Área Bajo la Curva *ROC* {#sec-roc-curve}</span></span>
<span id="cb23-163"><a href="#cb23-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-164"><a href="#cb23-164" aria-hidden="true" tabindex="-1"></a>El área bajo la curva *ROC* (*Relative Operating Characteristic*) es una medida de rendimiento que también está pasada en la probabilidad a posteriori $\mathbb P(\mathcal Y \mid \mathcal X)$ con la característica de que la clase se selecciona en base a un umbral $\rho$. Es decir, dado un ejemplo $x$, este ejemplo pertenece a la clase $p$ si $\mathbb P(\mathcal Y=p \mid \mathcal X=x) \geq \rho.$</span>
<span id="cb23-165"><a href="#cb23-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-166"><a href="#cb23-166" aria-hidden="true" tabindex="-1"></a>Se observa que modificando el umbral $\rho$ se tienen diferentes tablas de confusión, para cada tabla de confusión posible se calcula la tasa de verdaderos positivos (TPR) que corresponde al recall (@sec-recall), i.e., $\mathbb P(\mathcal{\hat Y}=p \mid \mathcal Y=p),$ y la tasa de falsos positivos (FPR) que es $\mathbb P(\mathcal{\hat Y}=p \mid \mathcal Y=n).$ Cada par de TPR y FPR representan un punto de la curva *ROC*. El rendimiento corresponde al área debajo de la curva delimitada por los pares TPR y FPR.</span>
<span id="cb23-167"><a href="#cb23-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-168"><a href="#cb23-168" aria-hidden="true" tabindex="-1"></a><span class="fu">### Ejemplo</span></span>
<span id="cb23-169"><a href="#cb23-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-170"><a href="#cb23-170" aria-hidden="true" tabindex="-1"></a>El ejemplo de Breast Cancer Wisconsin (@sec-ejemplo-breast-cancer-wisconsin) se utiliza para ilustrar el uso de la medidas de rendimiento presentadas hasta el momento. </span>
<span id="cb23-171"><a href="#cb23-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-174"><a href="#cb23-174" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-175"><a href="#cb23-175" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb23-176"><a href="#cb23-176" aria-hidden="true" tabindex="-1"></a>D, y <span class="op">=</span> load_breast_cancer(return_X_y<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb23-177"><a href="#cb23-177" aria-hidden="true" tabindex="-1"></a>T, G, y_t, y_g <span class="op">=</span> train_test_split(D, y, </span>
<span id="cb23-178"><a href="#cb23-178" aria-hidden="true" tabindex="-1"></a>                                  random_state<span class="op">=</span><span class="dv">0</span>,  </span>
<span id="cb23-179"><a href="#cb23-179" aria-hidden="true" tabindex="-1"></a>                                  test_size<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb23-180"><a href="#cb23-180" aria-hidden="true" tabindex="-1"></a>gaussian <span class="op">=</span> GaussianBayes().fit(T, y_t)</span>
<span id="cb23-181"><a href="#cb23-181" aria-hidden="true" tabindex="-1"></a>hy_gaussian <span class="op">=</span> gaussian.predict(G)</span>
<span id="cb23-182"><a href="#cb23-182" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-183"><a href="#cb23-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-186"><a href="#cb23-186" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-187"><a href="#cb23-187" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb23-188"><a href="#cb23-188" aria-hidden="true" tabindex="-1"></a>acc_f <span class="op">=</span> Markdown(<span class="ss">f'$</span><span class="sc">{</span>metrics<span class="sc">.</span>accuracy_score(y_g, hy_gaussian)<span class="sc">:0.4f}</span><span class="ss">$'</span>)</span>
<span id="cb23-189"><a href="#cb23-189" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-190"><a href="#cb23-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-191"><a href="#cb23-191" aria-hidden="true" tabindex="-1"></a>El clasificador Gausiano tiene un <span class="in">`accuracy`</span> de <span class="in">`{python} acc_f`</span>, el cual se puede calcular con el siguiente código.</span>
<span id="cb23-192"><a href="#cb23-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-195"><a href="#cb23-195" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-196"><a href="#cb23-196" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb23-197"><a href="#cb23-197" aria-hidden="true" tabindex="-1"></a>accuracy <span class="op">=</span> metrics.accuracy_score(y_g, hy_gaussian)</span>
<span id="cb23-198"><a href="#cb23-198" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-199"><a href="#cb23-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-200"><a href="#cb23-200" aria-hidden="true" tabindex="-1"></a>Las medidas de <span class="in">`recall`</span>, <span class="in">`precision`</span> y <span class="in">`f1`</span> se presentan en la @tbl-performance, en la última columna se presenta el macro de cada una de las medidas. </span>
<span id="cb23-201"><a href="#cb23-201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-204"><a href="#cb23-204" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-205"><a href="#cb23-205" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb23-206"><a href="#cb23-206" aria-hidden="true" tabindex="-1"></a>recall <span class="op">=</span> metrics.recall_score(y_g, hy_gaussian,</span>
<span id="cb23-207"><a href="#cb23-207" aria-hidden="true" tabindex="-1"></a>                              average<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb23-208"><a href="#cb23-208" aria-hidden="true" tabindex="-1"></a>precision <span class="op">=</span> metrics.precision_score(y_g, hy_gaussian,</span>
<span id="cb23-209"><a href="#cb23-209" aria-hidden="true" tabindex="-1"></a>                                    average<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb23-210"><a href="#cb23-210" aria-hidden="true" tabindex="-1"></a>f1 <span class="op">=</span> metrics.f1_score(y_g, hy_gaussian,</span>
<span id="cb23-211"><a href="#cb23-211" aria-hidden="true" tabindex="-1"></a>                      average<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb23-212"><a href="#cb23-212" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-213"><a href="#cb23-213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-216"><a href="#cb23-216" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-217"><a href="#cb23-217" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: tbl-performance</span></span>
<span id="cb23-218"><a href="#cb23-218" aria-hidden="true" tabindex="-1"></a><span class="co">#| tbl-cap: Rendimiento</span></span>
<span id="cb23-219"><a href="#cb23-219" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb23-220"><a href="#cb23-220" aria-hidden="true" tabindex="-1"></a>headers <span class="op">=</span> <span class="st">'|        |$</span><span class="ch">\\</span><span class="st">mathcal Y=0$ |&nbsp;$</span><span class="ch">\\</span><span class="st">mathcal Y=1$|Macro|'</span></span>
<span id="cb23-221"><a href="#cb23-221" aria-hidden="true" tabindex="-1"></a>linea <span class="op">=</span>   <span class="st">'|----------------------|----------------------|----------------------|----------------------|'</span></span>
<span id="cb23-222"><a href="#cb23-222" aria-hidden="true" tabindex="-1"></a>recall_f <span class="op">=</span> <span class="st">' | '</span>.join([<span class="ss">f'$</span><span class="sc">{</span>x<span class="sc">:0.4f}</span><span class="ss">$'</span> <span class="cf">for</span> x <span class="kw">in</span> recall.tolist() <span class="op">+</span> [np.mean(recall)]])</span>
<span id="cb23-223"><a href="#cb23-223" aria-hidden="true" tabindex="-1"></a>precision_f <span class="op">=</span> <span class="st">' | '</span>.join([<span class="ss">f'$</span><span class="sc">{</span>x<span class="sc">:0.4f}</span><span class="ss">$'</span> <span class="cf">for</span> x <span class="kw">in</span> precision.tolist() <span class="op">+</span> [np.mean(precision)]])</span>
<span id="cb23-224"><a href="#cb23-224" aria-hidden="true" tabindex="-1"></a>f1_f <span class="op">=</span> <span class="st">' | '</span>.join([<span class="ss">f'$</span><span class="sc">{</span>x<span class="sc">:0.4f}</span><span class="ss">$'</span> <span class="cf">for</span> x <span class="kw">in</span> f1.tolist() <span class="op">+</span> [np.mean(f1)]])</span>
<span id="cb23-225"><a href="#cb23-225" aria-hidden="true" tabindex="-1"></a>tab <span class="op">=</span> <span class="st">'</span><span class="ch">\n</span><span class="st">'</span>.join(([headers, linea,</span>
<span id="cb23-226"><a href="#cb23-226" aria-hidden="true" tabindex="-1"></a>                  <span class="ss">f'|`recall`|</span><span class="sc">{</span>recall_f<span class="sc">}</span><span class="ss">|'</span>,</span>
<span id="cb23-227"><a href="#cb23-227" aria-hidden="true" tabindex="-1"></a>                  <span class="ss">f'|`precision`|</span><span class="sc">{</span>precision_f<span class="sc">}</span><span class="ss">|'</span>,</span>
<span id="cb23-228"><a href="#cb23-228" aria-hidden="true" tabindex="-1"></a>                  <span class="ss">f'|`f1`|</span><span class="sc">{</span>f1_f<span class="sc">}</span><span class="ss">|'</span>]))</span>
<span id="cb23-229"><a href="#cb23-229" aria-hidden="true" tabindex="-1"></a>Markdown(tab)</span>
<span id="cb23-230"><a href="#cb23-230" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-231"><a href="#cb23-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-234"><a href="#cb23-234" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-235"><a href="#cb23-235" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb23-236"><a href="#cb23-236" aria-hidden="true" tabindex="-1"></a>prob <span class="op">=</span> gaussian.predict_proba(G)</span>
<span id="cb23-237"><a href="#cb23-237" aria-hidden="true" tabindex="-1"></a>entropia <span class="op">=</span> metrics.log_loss(y_g, prob)</span>
<span id="cb23-238"><a href="#cb23-238" aria-hidden="true" tabindex="-1"></a>entropia_f <span class="op">=</span> Markdown(<span class="ss">f'$</span><span class="sc">{</span>entropia<span class="sc">:0.4f}</span><span class="ss">$'</span>)</span>
<span id="cb23-239"><a href="#cb23-239" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-240"><a href="#cb23-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-241"><a href="#cb23-241" aria-hidden="true" tabindex="-1"></a>Por otro lado la <span class="in">`entropia`</span> cruzada es <span class="in">`{python} entropia_f`</span> que se puede calcular con el siguiente código.</span>
<span id="cb23-242"><a href="#cb23-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-245"><a href="#cb23-245" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-246"><a href="#cb23-246" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb23-247"><a href="#cb23-247" aria-hidden="true" tabindex="-1"></a>prob <span class="op">=</span> gaussian.predict_proba(G)</span>
<span id="cb23-248"><a href="#cb23-248" aria-hidden="true" tabindex="-1"></a>entropia <span class="op">=</span> metrics.log_loss(y_g, prob)</span>
<span id="cb23-249"><a href="#cb23-249" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-250"><a href="#cb23-250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-251"><a href="#cb23-251" aria-hidden="true" tabindex="-1"></a>Complementando la información de las medidas que se calculan mediante la posteriori se encuentra la curva ROC, la cual se puede calcular con el siguiente código y se muestra en la @fig-roc-curve</span>
<span id="cb23-252"><a href="#cb23-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-255"><a href="#cb23-255" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-256"><a href="#cb23-256" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-roc-curve</span></span>
<span id="cb23-257"><a href="#cb23-257" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: ROC</span></span>
<span id="cb23-258"><a href="#cb23-258" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb23-259"><a href="#cb23-259" aria-hidden="true" tabindex="-1"></a>fpr, tpr, thresholds <span class="op">=</span> metrics.roc_curve(y_g, prob[:, <span class="dv">1</span>])</span>
<span id="cb23-260"><a href="#cb23-260" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(<span class="bu">dict</span>(FPR<span class="op">=</span>fpr, TPR<span class="op">=</span>tpr))</span>
<span id="cb23-261"><a href="#cb23-261" aria-hidden="true" tabindex="-1"></a>sns.set_style(<span class="st">'whitegrid'</span>)</span>
<span id="cb23-262"><a href="#cb23-262" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> sns.lineplot(df, x<span class="op">=</span><span class="st">'FPR'</span>, y<span class="op">=</span><span class="st">'TPR'</span>)</span>
<span id="cb23-263"><a href="#cb23-263" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-264"><a href="#cb23-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-267"><a href="#cb23-267" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-268"><a href="#cb23-268" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb23-269"><a href="#cb23-269" aria-hidden="true" tabindex="-1"></a>auc_score_f <span class="op">=</span> Markdown(<span class="ss">f'$</span><span class="sc">{</span>metrics<span class="sc">.</span>roc_auc_score(y_g, prob[:, <span class="dv">1</span>])<span class="sc">:0.4f}</span><span class="ss">$'</span>)</span>
<span id="cb23-270"><a href="#cb23-270" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-271"><a href="#cb23-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-272"><a href="#cb23-272" aria-hidden="true" tabindex="-1"></a>Teniendo un valor de área bajo la curva (<span class="in">`auc_score`</span>) de <span class="in">`{python} auc_score_f`</span> que se obtuvo de la siguiente manera.</span>
<span id="cb23-273"><a href="#cb23-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-274"><a href="#cb23-274" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb23-275"><a href="#cb23-275" aria-hidden="true" tabindex="-1"></a>auc_score <span class="op">=</span> metrics.roc_auc_score(y_g, prob[:, <span class="dv">1</span>])</span>
<span id="cb23-276"><a href="#cb23-276" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-277"><a href="#cb23-277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-278"><a href="#cb23-278" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip collapse="true"}</span>
<span id="cb23-279"><a href="#cb23-279" aria-hidden="true" tabindex="-1"></a><span class="fu">### Actividad</span></span>
<span id="cb23-280"><a href="#cb23-280" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-281"><a href="#cb23-281" aria-hidden="true" tabindex="-1"></a>Medir el rendimiento del Clasificador Gausiano Ingenuo (@sec-cl-bayesiano-ingenuo) en el problema del del Iris (ver @sec-iris) utilizando la función $F_\beta$ (@sec-f1) variando $\beta$ entre $<span class="co">[</span><span class="ot">0, 1</span><span class="co">]</span>,$ tal y como se muestra en la @fig-actividad-fbeta</span>
<span id="cb23-282"><a href="#cb23-282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-285"><a href="#cb23-285" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-286"><a href="#cb23-286" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-actividad-fbeta</span></span>
<span id="cb23-287"><a href="#cb23-287" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Rendimiento de un Clasificador Bayesiano Ingenuo en el problema del Iris estimado mediante una validación cruzada estratificada."</span></span>
<span id="cb23-288"><a href="#cb23-288" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb23-289"><a href="#cb23-289" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-290"><a href="#cb23-290" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_iris</span>
<span id="cb23-291"><a href="#cb23-291" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> recall_score, precision_score</span>
<span id="cb23-292"><a href="#cb23-292" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> StratifiedKFold</span>
<span id="cb23-293"><a href="#cb23-293" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb23-294"><a href="#cb23-294" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb23-295"><a href="#cb23-295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-296"><a href="#cb23-296" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> load_iris(return_X_y<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb23-297"><a href="#cb23-297" aria-hidden="true" tabindex="-1"></a>hy <span class="op">=</span> np.empty_like(y)</span>
<span id="cb23-298"><a href="#cb23-298" aria-hidden="true" tabindex="-1"></a>skf <span class="op">=</span> StratifiedKFold()</span>
<span id="cb23-299"><a href="#cb23-299" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> tr, vs <span class="kw">in</span> skf.split(X, y):</span>
<span id="cb23-300"><a href="#cb23-300" aria-hidden="true" tabindex="-1"></a>    gaussian <span class="op">=</span> GaussianBayes().fit(X[tr], y[tr])</span>
<span id="cb23-301"><a href="#cb23-301" aria-hidden="true" tabindex="-1"></a>    hy[vs] <span class="op">=</span> gaussian.predict(X[vs])</span>
<span id="cb23-302"><a href="#cb23-302" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-303"><a href="#cb23-303" aria-hidden="true" tabindex="-1"></a>beta <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">10</span>)<span class="op">**</span><span class="dv">2</span></span>
<span id="cb23-304"><a href="#cb23-304" aria-hidden="true" tabindex="-1"></a>pre <span class="op">=</span> precision_score(y, hy, average<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb23-305"><a href="#cb23-305" aria-hidden="true" tabindex="-1"></a>recall <span class="op">=</span> recall_score(y, hy, average<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb23-306"><a href="#cb23-306" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-307"><a href="#cb23-307" aria-hidden="true" tabindex="-1"></a>num <span class="op">=</span> np.atleast_2d(<span class="dv">1</span> <span class="op">+</span> beta).T <span class="op">*</span> pre <span class="op">*</span> recall</span>
<span id="cb23-308"><a href="#cb23-308" aria-hidden="true" tabindex="-1"></a>den <span class="op">=</span> np.atleast_2d(beta).T <span class="op">*</span> pre <span class="op">+</span> recall</span>
<span id="cb23-309"><a href="#cb23-309" aria-hidden="true" tabindex="-1"></a>f1_beta <span class="op">=</span> num <span class="op">/</span> den</span>
<span id="cb23-310"><a href="#cb23-310" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-311"><a href="#cb23-311" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> load_iris()</span>
<span id="cb23-312"><a href="#cb23-312" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(np.c_[f1_beta, beta],</span>
<span id="cb23-313"><a href="#cb23-313" aria-hidden="true" tabindex="-1"></a>                  columns<span class="op">=</span>data.target_names.tolist() <span class="op">+</span> [<span class="st">'Beta^2'</span>])</span>
<span id="cb23-314"><a href="#cb23-314" aria-hidden="true" tabindex="-1"></a>df.set_index(<span class="st">'Beta^2'</span>, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb23-315"><a href="#cb23-315" aria-hidden="true" tabindex="-1"></a>df2 <span class="op">=</span> df.melt(value_name<span class="op">=</span><span class="st">'F-Beta'</span>, ignore_index<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb23-316"><a href="#cb23-316" aria-hidden="true" tabindex="-1"></a>              var_name<span class="op">=</span><span class="st">'Clase'</span>)</span>
<span id="cb23-317"><a href="#cb23-317" aria-hidden="true" tabindex="-1"></a>sns.relplot(df2.reset_index(), kind<span class="op">=</span><span class="st">'line'</span>, x<span class="op">=</span><span class="st">'Beta^2'</span>, hue<span class="op">=</span><span class="st">'Clase'</span>, y<span class="op">=</span><span class="st">'F-Beta'</span>)</span>
<span id="cb23-318"><a href="#cb23-318" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-319"><a href="#cb23-319" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb23-320"><a href="#cb23-320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-321"><a href="#cb23-321" aria-hidden="true" tabindex="-1"></a><span class="fu">## Regresión {#sec-rendimiento-regresion}</span></span>
<span id="cb23-322"><a href="#cb23-322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-323"><a href="#cb23-323" aria-hidden="true" tabindex="-1"></a>Con respecto a regresión las siguientes funciones son utilizadas como medidas de rendimiento.</span>
<span id="cb23-324"><a href="#cb23-324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-325"><a href="#cb23-325" aria-hidden="true" tabindex="-1"></a>Error cuadrático medio (Mean Square Error): </span>
<span id="cb23-326"><a href="#cb23-326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-327"><a href="#cb23-327" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-328"><a href="#cb23-328" aria-hidden="true" tabindex="-1"></a>\textsf{mse}(\mathcal Y, \mathcal{\hat Y}) = \frac{1}{N} \sum_{i=1}^N (\mathcal Y_i - \mathcal{\hat Y}_i)^2.</span>
<span id="cb23-329"><a href="#cb23-329" aria-hidden="true" tabindex="-1"></a>$$ {#eq-mse}</span>
<span id="cb23-330"><a href="#cb23-330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-331"><a href="#cb23-331" aria-hidden="true" tabindex="-1"></a>Error absoluto medio (Mean Absolute Error):</span>
<span id="cb23-332"><a href="#cb23-332" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-333"><a href="#cb23-333" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-334"><a href="#cb23-334" aria-hidden="true" tabindex="-1"></a>\textsf{mae}(\mathcal Y, \mathcal{\hat Y}) = \frac{1}{N} \sum_{i=1}^N \mid \mathcal Y_i - \mathcal{\hat Y}_i \mid.</span>
<span id="cb23-335"><a href="#cb23-335" aria-hidden="true" tabindex="-1"></a>$$ {#eq-mae}</span>
<span id="cb23-336"><a href="#cb23-336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-337"><a href="#cb23-337" aria-hidden="true" tabindex="-1"></a>Media del porcentaje de error absoluto: </span>
<span id="cb23-338"><a href="#cb23-338" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-339"><a href="#cb23-339" aria-hidden="true" tabindex="-1"></a>\textsf{mape}(\mathcal Y, \mathcal{\hat Y}) = \frac{1}{N} \sum_{i=1}^N \mid \frac{\mathcal Y_i - \mathcal{\hat Y}_i}{\mathcal Y_i}\mid.</span>
<span id="cb23-340"><a href="#cb23-340" aria-hidden="true" tabindex="-1"></a>$$ {#eq-mape}</span>
<span id="cb23-341"><a href="#cb23-341" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-342"><a href="#cb23-342" aria-hidden="true" tabindex="-1"></a>La proporción de la varianza explicada por el modelo: </span>
<span id="cb23-343"><a href="#cb23-343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-344"><a href="#cb23-344" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-345"><a href="#cb23-345" aria-hidden="true" tabindex="-1"></a>R^2(\mathcal Y, \mathcal{\hat Y}) = 1 - \frac{\sum_{i=1}^N (\mathcal Y_i - \mathcal{\hat Y}_i)^2)}{\sum_{i=1}^N (\mathcal Y_i - \mathcal{\bar Y}_i)^2)}.</span>
<span id="cb23-346"><a href="#cb23-346" aria-hidden="true" tabindex="-1"></a>$$ {#eq-r2}</span>
<span id="cb23-347"><a href="#cb23-347" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-348"><a href="#cb23-348" aria-hidden="true" tabindex="-1"></a><span class="fu">### Ejemplo</span></span>
<span id="cb23-349"><a href="#cb23-349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-350"><a href="#cb23-350" aria-hidden="true" tabindex="-1"></a>Las medidas anteriores se ejemplifican utilizando el ejemplo de diabetes(#sec-diabetes) que se puede descargar y modelar mediante OLS (@sec-regresion-ols) de la siguiente manera.</span>
<span id="cb23-351"><a href="#cb23-351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-352"><a href="#cb23-352" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-355"><a href="#cb23-355" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-356"><a href="#cb23-356" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb23-357"><a href="#cb23-357" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> load_diabetes(return_X_y<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb23-358"><a href="#cb23-358" aria-hidden="true" tabindex="-1"></a>T, G, y_t, y_g <span class="op">=</span> train_test_split(X, y,</span>
<span id="cb23-359"><a href="#cb23-359" aria-hidden="true" tabindex="-1"></a>                                  random_state<span class="op">=</span><span class="dv">0</span>,  </span>
<span id="cb23-360"><a href="#cb23-360" aria-hidden="true" tabindex="-1"></a>                                  test_size<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb23-361"><a href="#cb23-361" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> LinearRegression().fit(T, y_t) </span>
<span id="cb23-362"><a href="#cb23-362" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-363"><a href="#cb23-363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-364"><a href="#cb23-364" aria-hidden="true" tabindex="-1"></a>La predicción en el conjunto de prueba sería:</span>
<span id="cb23-365"><a href="#cb23-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-368"><a href="#cb23-368" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-369"><a href="#cb23-369" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb23-370"><a href="#cb23-370" aria-hidden="true" tabindex="-1"></a>hy <span class="op">=</span> m.predict(G)</span>
<span id="cb23-371"><a href="#cb23-371" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-372"><a href="#cb23-372" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-373"><a href="#cb23-373" aria-hidden="true" tabindex="-1"></a>Las diferentes medidas de rendimiento para problemas de regresión se puede calcular de la siguiente manera. </span>
<span id="cb23-374"><a href="#cb23-374" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-375"><a href="#cb23-375" aria-hidden="true" tabindex="-1"></a>El error cuadrático medio (@eq-mse), <span class="in">`mse`</span> corresponde a</span>
<span id="cb23-376"><a href="#cb23-376" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-379"><a href="#cb23-379" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-380"><a href="#cb23-380" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb23-381"><a href="#cb23-381" aria-hidden="true" tabindex="-1"></a>mse <span class="op">=</span> metrics.mean_squared_error(y_g, hy)</span>
<span id="cb23-382"><a href="#cb23-382" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-383"><a href="#cb23-383" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-386"><a href="#cb23-386" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-387"><a href="#cb23-387" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false </span></span>
<span id="cb23-388"><a href="#cb23-388" aria-hidden="true" tabindex="-1"></a>mse_f <span class="op">=</span> Markdown(<span class="ss">f'$</span><span class="sc">{</span>mse<span class="sc">:0.4f}</span><span class="ss">$'</span>)</span>
<span id="cb23-389"><a href="#cb23-389" aria-hidden="true" tabindex="-1"></a>mae_f <span class="op">=</span> Markdown(<span class="ss">f'$</span><span class="sc">{</span>metrics<span class="sc">.</span>mean_absolute_error(y_g, hy)<span class="sc">:0.4f}</span><span class="ss">$'</span>)</span>
<span id="cb23-390"><a href="#cb23-390" aria-hidden="true" tabindex="-1"></a>mape_f <span class="op">=</span> Markdown(<span class="ss">f'$</span><span class="sc">{</span>metrics<span class="sc">.</span>mean_absolute_percentage_error(y_g, hy)<span class="sc">:0.4f}</span><span class="ss">$'</span>)</span>
<span id="cb23-391"><a href="#cb23-391" aria-hidden="true" tabindex="-1"></a>r2_f <span class="op">=</span> Markdown(<span class="ss">f'$</span><span class="sc">{</span>metrics<span class="sc">.</span>r2_score(y_g, hy)<span class="sc">:0.4f}</span><span class="ss">$'</span>)</span>
<span id="cb23-392"><a href="#cb23-392" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-393"><a href="#cb23-393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-394"><a href="#cb23-394" aria-hidden="true" tabindex="-1"></a>y tienen un valor de <span class="in">`{python} mse_f`</span>.</span>
<span id="cb23-395"><a href="#cb23-395" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-396"><a href="#cb23-396" aria-hidden="true" tabindex="-1"></a>El error absoluto medio (@eq-mae), <span class="in">`mae`</span>, tiene un valor de <span class="in">`{python} mae_f`</span> calculado de la siguiente manera</span>
<span id="cb23-397"><a href="#cb23-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-398"><a href="#cb23-398" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb23-399"><a href="#cb23-399" aria-hidden="true" tabindex="-1"></a>mae <span class="op">=</span> metrics.mean_absolute_error(y_g, hy)</span>
<span id="cb23-400"><a href="#cb23-400" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-401"><a href="#cb23-401" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-402"><a href="#cb23-402" aria-hidden="true" tabindex="-1"></a>La media del porcentaje de error absoluto (@eq-mape), <span class="in">`mape`</span>, es <span class="in">`{python} mape_f`</span> obtenido con el siguiente código </span>
<span id="cb23-403"><a href="#cb23-403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-404"><a href="#cb23-404" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb23-405"><a href="#cb23-405" aria-hidden="true" tabindex="-1"></a>mape <span class="op">=</span> metrics.mean_absolute_percentage_error(y_g, hy)</span>
<span id="cb23-406"><a href="#cb23-406" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-407"><a href="#cb23-407" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-408"><a href="#cb23-408" aria-hidden="true" tabindex="-1"></a>Finalmente, la varianza explicada por el modelo $R^2$ (@eq-r2), <span class="in">`r2`</span>, es <span class="in">`{python} r2_f`</span></span>
<span id="cb23-409"><a href="#cb23-409" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-410"><a href="#cb23-410" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb23-411"><a href="#cb23-411" aria-hidden="true" tabindex="-1"></a>r2 <span class="op">=</span> metrics.r2_score(y_g, hy)</span>
<span id="cb23-412"><a href="#cb23-412" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-413"><a href="#cb23-413" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-414"><a href="#cb23-414" aria-hidden="true" tabindex="-1"></a><span class="fu">## Conjunto de Validación y Validación Cruzada {#sec-validacion-cruzada}</span></span>
<span id="cb23-415"><a href="#cb23-415" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-416"><a href="#cb23-416" aria-hidden="true" tabindex="-1"></a>Antes de inicia la descripción de otro algoritmo para la selección de características es necesario describir otro conjunto que se utiliza para optimizar los hiperparámetros del algoritmo de aprendizaje. Previamente se describieron los conjuntos de Entrenamiento y Prueba (@sec-conjunto-entre-prueba), i.e., $\mathcal T$ y $\mathcal G$. En particular estos conjuntos se definieron utilizando todos los datos $\mathcal D$ con lo que se especifica el problema.</span>
<span id="cb23-417"><a href="#cb23-417" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-418"><a href="#cb23-418" aria-hidden="true" tabindex="-1"></a>La mayoría de algoritmos de aprendizaje tiene hiperparámetros que pueden ser ajustados para optimizar su comportamiento al conjunto de datos que se está analizando. Estos hiperparámetros pueden estar dentro del algoritmo o pueden ser modificaciones al conjunto de datos para adecuarlos al algoritmo. El segundo caso es el que se analizará en esta unidad. Es decir, se seleccionarán las variables que facilitan el aprendizaje. </span>
<span id="cb23-419"><a href="#cb23-419" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-420"><a href="#cb23-420" aria-hidden="true" tabindex="-1"></a>Para optimizar los parámetros es necesario medir el rendimiento del algoritmo, es decir, observar como se comporta el algoritmo en el proceso de predicción. La manera trivial sería utilizar el conjunto de prueba $\mathcal G$ para medir el rendimiento. Pero es necesario recordar que este conjunto no debe ser visto durante el aprendizaje y la optimización de los parámetros es parte de ese proceso. Si se usara $\mathcal G$ entonces dejaría de ser el conjunto de prueba y se tendría que seleccionar otro conjunto de prueba. </span>
<span id="cb23-421"><a href="#cb23-421" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-422"><a href="#cb23-422" aria-hidden="true" tabindex="-1"></a>Entonces para optimizar los parámetros del algoritmo se selecciona del conjunto de entrenamiento, i.e., $\mathcal T$, el **conjunto de validación**, $\mathcal V$. Este conjunto tiene la característica que $\mathcal T \cap \mathcal V \cap \mathcal G = \emptyset$ y $\mathcal T \cup \mathcal V \cup \mathcal G = \mathcal D.$ Una manera de realizar estos es seleccionar primeramente el conjunto de prueba $\mathcal G$ y de los datos restantes generar los conjuntos de entrenamiento $\mathcal T$ y validación $\mathcal V.$</span>
<span id="cb23-423"><a href="#cb23-423" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-424"><a href="#cb23-424" aria-hidden="true" tabindex="-1"></a>Para ejemplificar esta idea se utiliza el ejemplo de Breast Cancer Wisconsin (@sec-ejemplo-breast-cancer-wisconsin) utilizando un Clasificador Bayesiano donde el hiperparámetro es si se utilizar un Bayesiano Ingenuo o se estima la matriz de covarianza. </span>
<span id="cb23-425"><a href="#cb23-425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-426"><a href="#cb23-426" aria-hidden="true" tabindex="-1"></a>El primer paso es obtener los datos del problema, lo cual se muestra en la siguiente instrucción.</span>
<span id="cb23-427"><a href="#cb23-427" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-430"><a href="#cb23-430" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-431"><a href="#cb23-431" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb23-432"><a href="#cb23-432" aria-hidden="true" tabindex="-1"></a>D, y <span class="op">=</span> load_breast_cancer(return_X_y<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb23-433"><a href="#cb23-433" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-434"><a href="#cb23-434" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-435"><a href="#cb23-435" aria-hidden="true" tabindex="-1"></a>Con los datos $\mathcal D$ se genera el conjunto de prueba $\mathcal G$ y los datos para estimar los parámetros y optimizar los hiperparámetros del algoritmo. En la variable <span class="in">`T`</span> se tiene los datos para encontrar el algoritmo y en <span class="in">`G`</span> se tiene el conjunto de prueba.</span>
<span id="cb23-436"><a href="#cb23-436" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-439"><a href="#cb23-439" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-440"><a href="#cb23-440" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb23-441"><a href="#cb23-441" aria-hidden="true" tabindex="-1"></a>T, G, y_t, y_g <span class="op">=</span> train_test_split(D, y,</span>
<span id="cb23-442"><a href="#cb23-442" aria-hidden="true" tabindex="-1"></a>                                  random_state<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb23-443"><a href="#cb23-443" aria-hidden="true" tabindex="-1"></a>                                  test_size<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb23-444"><a href="#cb23-444" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-445"><a href="#cb23-445" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-446"><a href="#cb23-446" aria-hidden="true" tabindex="-1"></a>Los datos de entrenamiento y validación se generan de manera equivalente tal como se muestra en la siguiente instrucción. El conjunto de validación ($\mathcal V$) se encuentra en la variable <span class="in">`V`</span> y la variable dependiente en <span class="in">`y_v.`</span></span>
<span id="cb23-447"><a href="#cb23-447" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-450"><a href="#cb23-450" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-451"><a href="#cb23-451" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb23-452"><a href="#cb23-452" aria-hidden="true" tabindex="-1"></a>T, V, y_t, y_v <span class="op">=</span> train_test_split(T, y_t,</span>
<span id="cb23-453"><a href="#cb23-453" aria-hidden="true" tabindex="-1"></a>                                  random_state<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb23-454"><a href="#cb23-454" aria-hidden="true" tabindex="-1"></a>                                  test_size<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb23-455"><a href="#cb23-455" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-456"><a href="#cb23-456" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-459"><a href="#cb23-459" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-460"><a href="#cb23-460" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb23-461"><a href="#cb23-461" aria-hidden="true" tabindex="-1"></a>gaussian <span class="op">=</span> GaussianBayes().fit(T, y_t)</span>
<span id="cb23-462"><a href="#cb23-462" aria-hidden="true" tabindex="-1"></a>hy_gaussian <span class="op">=</span> gaussian.predict(V)</span>
<span id="cb23-463"><a href="#cb23-463" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> recall_score(y_v, hy_gaussian, average<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb23-464"><a href="#cb23-464" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> [<span class="ss">f'</span><span class="sc">{</span>x<span class="sc">:0.4f}</span><span class="ss">'</span> <span class="cf">for</span> x <span class="kw">in</span> score]</span>
<span id="cb23-465"><a href="#cb23-465" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> Markdown(<span class="ss">f'[</span><span class="sc">{</span><span class="st">", "</span><span class="sc">.</span>join(score)<span class="sc">}</span><span class="ss">]'</span>)</span>
<span id="cb23-466"><a href="#cb23-466" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-467"><a href="#cb23-467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-468"><a href="#cb23-468" aria-hidden="true" tabindex="-1"></a>En este momento ya se tienen todos los elementos para medir el rendimiento de cada hiperparámetro. Empezando por el clasificador con la matriz de covarianza completa. El recall en ambas clases es <span class="in">`{python} score`</span>. </span>
<span id="cb23-469"><a href="#cb23-469" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-470"><a href="#cb23-470" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-473"><a href="#cb23-473" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-474"><a href="#cb23-474" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb23-475"><a href="#cb23-475" aria-hidden="true" tabindex="-1"></a>gaussian <span class="op">=</span> GaussianBayes().fit(T, y_t)</span>
<span id="cb23-476"><a href="#cb23-476" aria-hidden="true" tabindex="-1"></a>hy_gaussian <span class="op">=</span> gaussian.predict(V)</span>
<span id="cb23-477"><a href="#cb23-477" aria-hidden="true" tabindex="-1"></a>recall <span class="op">=</span> recall_score(y_v, hy_gaussian, average<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb23-478"><a href="#cb23-478" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-479"><a href="#cb23-479" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-482"><a href="#cb23-482" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-483"><a href="#cb23-483" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb23-484"><a href="#cb23-484" aria-hidden="true" tabindex="-1"></a>ingenuo <span class="op">=</span> GaussianBayes(naive<span class="op">=</span><span class="va">True</span>).fit(T, y_t)</span>
<span id="cb23-485"><a href="#cb23-485" aria-hidden="true" tabindex="-1"></a>hy_ingenuo <span class="op">=</span> ingenuo.predict(V)</span>
<span id="cb23-486"><a href="#cb23-486" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> recall_score(y_v, hy_ingenuo, average<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb23-487"><a href="#cb23-487" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> [<span class="ss">f'</span><span class="sc">{</span>x<span class="sc">:0.4f}</span><span class="ss">'</span> <span class="cf">for</span> x <span class="kw">in</span> score]</span>
<span id="cb23-488"><a href="#cb23-488" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> Markdown(<span class="ss">f'[</span><span class="sc">{</span><span class="st">", "</span><span class="sc">.</span>join(score)<span class="sc">}</span><span class="ss">]'</span>)</span>
<span id="cb23-489"><a href="#cb23-489" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-490"><a href="#cb23-490" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-491"><a href="#cb23-491" aria-hidden="true" tabindex="-1"></a>La segunda opción es utilizar un clasificador Bayesiano Ingenuo, el cual se especifica con el parámetro <span class="in">`naive`</span> tal y como se muestra en las siguientes instrucciones. El recall en las dos clases es <span class="in">`{python} score`</span>.  </span>
<span id="cb23-492"><a href="#cb23-492" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-495"><a href="#cb23-495" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-496"><a href="#cb23-496" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb23-497"><a href="#cb23-497" aria-hidden="true" tabindex="-1"></a>ingenuo <span class="op">=</span> GaussianBayes(naive<span class="op">=</span><span class="va">True</span>).fit(T, y_t)</span>
<span id="cb23-498"><a href="#cb23-498" aria-hidden="true" tabindex="-1"></a>hy_ingenuo <span class="op">=</span> ingenuo.predict(V)</span>
<span id="cb23-499"><a href="#cb23-499" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> recall_score(y_v, hy_ingenuo, average<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb23-500"><a href="#cb23-500" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-501"><a href="#cb23-501" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-504"><a href="#cb23-504" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-505"><a href="#cb23-505" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb23-506"><a href="#cb23-506" aria-hidden="true" tabindex="-1"></a>gaussian <span class="op">=</span> GaussianBayes().fit(np.concatenate((T, V)),</span>
<span id="cb23-507"><a href="#cb23-507" aria-hidden="true" tabindex="-1"></a>                               np.concatenate((y_t, y_v)))</span>
<span id="cb23-508"><a href="#cb23-508" aria-hidden="true" tabindex="-1"></a>hy_gaussian <span class="op">=</span> gaussian.predict(G)</span>
<span id="cb23-509"><a href="#cb23-509" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> recall_score(y_g, hy_gaussian, average<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb23-510"><a href="#cb23-510" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> [<span class="ss">f'</span><span class="sc">{</span>x<span class="sc">:0.4f}</span><span class="ss">'</span> <span class="cf">for</span> x <span class="kw">in</span> score]</span>
<span id="cb23-511"><a href="#cb23-511" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> Markdown(<span class="ss">f'[</span><span class="sc">{</span><span class="st">", "</span><span class="sc">.</span>join(score)<span class="sc">}</span><span class="ss">]'</span>)</span>
<span id="cb23-512"><a href="#cb23-512" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-513"><a href="#cb23-513" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-514"><a href="#cb23-514" aria-hidden="true" tabindex="-1"></a>Comparando el rendimiento de los dos hiperparámetros se observa cual de los dos modelos obtiene el mejor rendimiento. Con el fin de completar el ejemplo se describe calcular el rendimiento en  $\mathcal G$ del algoritmo con la matriz de covarianza completa. Este algoritmo tiene un rendimiento de <span class="in">`{python} score`</span> que se puede calcular con el siguiente código. </span>
<span id="cb23-515"><a href="#cb23-515" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-518"><a href="#cb23-518" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-519"><a href="#cb23-519" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb23-520"><a href="#cb23-520" aria-hidden="true" tabindex="-1"></a>gaussian <span class="op">=</span> GaussianBayes().fit(np.concatenate((T, V)),</span>
<span id="cb23-521"><a href="#cb23-521" aria-hidden="true" tabindex="-1"></a>                               np.concatenate((y_t, y_v)))</span>
<span id="cb23-522"><a href="#cb23-522" aria-hidden="true" tabindex="-1"></a>hy_gaussian <span class="op">=</span> gaussian.predict(G)</span>
<span id="cb23-523"><a href="#cb23-523" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> recall_score(y_g, hy_gaussian, average<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb23-524"><a href="#cb23-524" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-525"><a href="#cb23-525" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-526"><a href="#cb23-526" aria-hidden="true" tabindex="-1"></a><span class="fu">### k-Iteraciones de Validación Cruzada {#sec-kfold-cross-validation}</span></span>
<span id="cb23-527"><a href="#cb23-527" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-528"><a href="#cb23-528" aria-hidden="true" tabindex="-1"></a>Cuando se cuenta con pocos datos para medir el rendimiento del algoritmo es común utilizar la técnica de _k-fold cross-validation_ la cual consiste en partir $k$ veces el conjunto de entrenamiento para generar $k$ conjuntos de entrenamiento y validación. </span>
<span id="cb23-529"><a href="#cb23-529" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-530"><a href="#cb23-530" aria-hidden="true" tabindex="-1"></a>La idea se ilustra con la siguiente tabla, donde se asume que los datos son divididos en 5 bloques ($k=5$), cada columna de la tabla ilustra los datos de ese bloque. Si los datos se dividen en $k=5$ bloques, entonces existen $k$ iteraciones que son representadas por cada renglón de la siguiente tabla, quitando el encabezado de la misma. La letra en cada celda identifica el uso que se le dará a esos datos en la respectiva iteración, es decir, $\mathcal T$ representa que se usará como conjunto de entrenamiento y $\mathcal V$ se usa para identificar aquellos datos que se usarán como conjunto de validación.</span>
<span id="cb23-531"><a href="#cb23-531" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-532"><a href="#cb23-532" aria-hidden="true" tabindex="-1"></a>La idea es entrenar y probar el rendimiento del algoritmo $k$ veces usando las particiones en cada renglón. Es decir, la primera vez se usan los datos de la primera columna como el conjunto de validación, y el resto de columnas, $<span class="co">[</span><span class="ot">2, 3, 4, 5</span><span class="co">]</span>$, como conjunto de entrenamiento para estimar los parámetros del algoritmo. En la segunda iteración se usan los datos del segundo renglón donde se observa que los datos en la cuarta columna corresponden al conjunto de validación y los datos en las columnas $<span class="co">[</span><span class="ot">1, 2, 3, 5</span><span class="co">]</span>$ son usados como conjunto de prueba. Las iteraciones siguen hasta que todos los datos fueron utilizados en una ocasión como conjunto de validación. </span>
<span id="cb23-533"><a href="#cb23-533" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-534"><a href="#cb23-534" aria-hidden="true" tabindex="-1"></a>|  1 |  2 |  3 |  4 |  5 |</span>
<span id="cb23-535"><a href="#cb23-535" aria-hidden="true" tabindex="-1"></a>|----|----|----|----|----|</span>
<span id="cb23-536"><a href="#cb23-536" aria-hidden="true" tabindex="-1"></a>|$\mathcal V$   |$\mathcal T$   |$\mathcal T$   |$\mathcal T$   |$\mathcal T$   |</span>
<span id="cb23-537"><a href="#cb23-537" aria-hidden="true" tabindex="-1"></a>|$\mathcal T$   |$\mathcal T$   |$\mathcal T$   |$\mathcal V$   |$\mathcal T$   |</span>
<span id="cb23-538"><a href="#cb23-538" aria-hidden="true" tabindex="-1"></a>|$\mathcal T$   |$\mathcal T$   |$\mathcal V$   |$\mathcal T$   |$\mathcal T$   |</span>
<span id="cb23-539"><a href="#cb23-539" aria-hidden="true" tabindex="-1"></a>|$\mathcal T$   |$\mathcal T$   |$\mathcal T$   |$\mathcal T$   |$\mathcal V$   |</span>
<span id="cb23-540"><a href="#cb23-540" aria-hidden="true" tabindex="-1"></a>|$\mathcal T$   |$\mathcal V$   |$\mathcal T$   |$\mathcal T$   |$\mathcal T$   |</span>
<span id="cb23-541"><a href="#cb23-541" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-542"><a href="#cb23-542" aria-hidden="true" tabindex="-1"></a>Se utiliza el mismo problema para medir el rendimiento del hiperparámetro del clasificador Gausiano. Lo primero es seleccionar el conjunto de prueba ($\mathcal G$) que se realiza con el siguiente código. </span>
<span id="cb23-543"><a href="#cb23-543" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-546"><a href="#cb23-546" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-547"><a href="#cb23-547" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb23-548"><a href="#cb23-548" aria-hidden="true" tabindex="-1"></a>T, G, y_t, y_g <span class="op">=</span> train_test_split(D, y,</span>
<span id="cb23-549"><a href="#cb23-549" aria-hidden="true" tabindex="-1"></a>                                  random_state<span class="op">=</span><span class="dv">0</span>,  </span>
<span id="cb23-550"><a href="#cb23-550" aria-hidden="true" tabindex="-1"></a>                                  test_size<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb23-551"><a href="#cb23-551" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-552"><a href="#cb23-552" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-555"><a href="#cb23-555" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-556"><a href="#cb23-556" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb23-557"><a href="#cb23-557" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb23-558"><a href="#cb23-558" aria-hidden="true" tabindex="-1"></a>perf <span class="op">=</span> []</span>
<span id="cb23-559"><a href="#cb23-559" aria-hidden="true" tabindex="-1"></a>perf2 <span class="op">=</span> []</span>
<span id="cb23-560"><a href="#cb23-560" aria-hidden="true" tabindex="-1"></a>kfold <span class="op">=</span> KFold(shuffle<span class="op">=</span><span class="va">True</span>, random_state<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb23-561"><a href="#cb23-561" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ts, vs <span class="kw">in</span> kfold.split(T):</span>
<span id="cb23-562"><a href="#cb23-562" aria-hidden="true" tabindex="-1"></a>    gaussian <span class="op">=</span> GaussianBayes().fit(T[ts], y_t[ts])</span>
<span id="cb23-563"><a href="#cb23-563" aria-hidden="true" tabindex="-1"></a>    hy_gaussian <span class="op">=</span> gaussian.predict(T[vs])</span>
<span id="cb23-564"><a href="#cb23-564" aria-hidden="true" tabindex="-1"></a>    _ <span class="op">=</span> recall_score(y_t[vs], hy_gaussian, average<span class="op">=</span><span class="va">None</span>)    </span>
<span id="cb23-565"><a href="#cb23-565" aria-hidden="true" tabindex="-1"></a>    perf.append(_)</span>
<span id="cb23-566"><a href="#cb23-566" aria-hidden="true" tabindex="-1"></a>    gaussian <span class="op">=</span> GaussianBayes(naive<span class="op">=</span><span class="va">True</span>).fit(T[ts], y_t[ts])</span>
<span id="cb23-567"><a href="#cb23-567" aria-hidden="true" tabindex="-1"></a>    hy_gaussian <span class="op">=</span> gaussian.predict(T[vs])</span>
<span id="cb23-568"><a href="#cb23-568" aria-hidden="true" tabindex="-1"></a>    _ <span class="op">=</span> recall_score(y_t[vs], hy_gaussian, average<span class="op">=</span><span class="va">None</span>)    </span>
<span id="cb23-569"><a href="#cb23-569" aria-hidden="true" tabindex="-1"></a>    perf2.append(_)</span>
<span id="cb23-570"><a href="#cb23-570" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-571"><a href="#cb23-571" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> np.mean(perf, axis<span class="op">=</span><span class="dv">0</span>)    </span>
<span id="cb23-572"><a href="#cb23-572" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> [<span class="ss">f'</span><span class="sc">{</span>x<span class="sc">:0.4f}</span><span class="ss">'</span> <span class="cf">for</span> x <span class="kw">in</span> score]</span>
<span id="cb23-573"><a href="#cb23-573" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> Markdown(<span class="ss">f'[</span><span class="sc">{</span><span class="st">", "</span><span class="sc">.</span>join(score)<span class="sc">}</span><span class="ss">]'</span>)</span>
<span id="cb23-574"><a href="#cb23-574" aria-hidden="true" tabindex="-1"></a>score2 <span class="op">=</span> np.mean(perf2, axis<span class="op">=</span><span class="dv">0</span>)    </span>
<span id="cb23-575"><a href="#cb23-575" aria-hidden="true" tabindex="-1"></a>score2 <span class="op">=</span> [<span class="ss">f'</span><span class="sc">{</span>x<span class="sc">:0.4f}</span><span class="ss">'</span> <span class="cf">for</span> x <span class="kw">in</span> score2]</span>
<span id="cb23-576"><a href="#cb23-576" aria-hidden="true" tabindex="-1"></a>score2 <span class="op">=</span> Markdown(<span class="ss">f'[</span><span class="sc">{</span><span class="st">", "</span><span class="sc">.</span>join(score2)<span class="sc">}</span><span class="ss">]'</span>)</span>
<span id="cb23-577"><a href="#cb23-577" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-578"><a href="#cb23-578" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-579"><a href="#cb23-579" aria-hidden="true" tabindex="-1"></a>La validación cruzada con k-iteraciones se puede realizar con la clase <span class="in">`KFold`</span> de la siguiente manera. La primera línea crear una variable para guardar el rendimiento. En la segunda línea se inicializa el procedimiento indicando que los datos sean tomados al azar. Después se realiza el ciclo con las $k$ iteraciones, para cada iteración se genera un índice <span class="in">`ts`</span> que indica cuales son los datos del conjunto de entrenamiento y <span class="in">`vs`</span> que corresponde a los datos de validación. Se estiman los parámetros usando <span class="in">`ts`</span> tal y como se observa en la cuarta línea. Habiendo estimado los parámetros se predicen los datos del conjunto de validación (5 línea), se mide el recall en todas las clases y se guarda en la lista <span class="in">`perf.`</span> Al final se calcula la media de los $k$ rendimientos medidos, teniendo un valor de <span class="in">`{python} score`</span>.</span>
<span id="cb23-580"><a href="#cb23-580" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-583"><a href="#cb23-583" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-584"><a href="#cb23-584" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb23-585"><a href="#cb23-585" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb23-586"><a href="#cb23-586" aria-hidden="true" tabindex="-1"></a>perf <span class="op">=</span> []</span>
<span id="cb23-587"><a href="#cb23-587" aria-hidden="true" tabindex="-1"></a>kfold <span class="op">=</span> KFold(shuffle<span class="op">=</span><span class="va">True</span>, random_state<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb23-588"><a href="#cb23-588" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ts, vs <span class="kw">in</span> kfold.split(T):</span>
<span id="cb23-589"><a href="#cb23-589" aria-hidden="true" tabindex="-1"></a>    gaussian <span class="op">=</span> GaussianBayes().fit(T[ts], y_t[ts])</span>
<span id="cb23-590"><a href="#cb23-590" aria-hidden="true" tabindex="-1"></a>    hy_gaussian <span class="op">=</span> gaussian.predict(T[vs])</span>
<span id="cb23-591"><a href="#cb23-591" aria-hidden="true" tabindex="-1"></a>    _ <span class="op">=</span> recall_score(y_t[vs], hy_gaussian, average<span class="op">=</span><span class="va">None</span>)    </span>
<span id="cb23-592"><a href="#cb23-592" aria-hidden="true" tabindex="-1"></a>    perf.append(_)</span>
<span id="cb23-593"><a href="#cb23-593" aria-hidden="true" tabindex="-1"></a>perf <span class="op">=</span> np.mean(perf, axis<span class="op">=</span><span class="dv">0</span>)    </span>
<span id="cb23-594"><a href="#cb23-594" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-595"><a href="#cb23-595" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-596"><a href="#cb23-596" aria-hidden="true" tabindex="-1"></a>Un procedimiento equivalente se realiza para el caso del clasificador Bayesiano Ingenuo tal y como se muestra a continuación. La media del recall en las clases es <span class="in">`{python} score2`</span> Se observa que el clasificador Bayesiano con la matriz de covarianza tiene un mejor rendimiento en validación que el clasificador Bayesiano Ingenuo. El último paso sería calcular el rendimiento en el conjunto $\mathcal G$ lo cual fue presentado anteriormente.  </span>
<span id="cb23-597"><a href="#cb23-597" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-600"><a href="#cb23-600" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-601"><a href="#cb23-601" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb23-602"><a href="#cb23-602" aria-hidden="true" tabindex="-1"></a>perf <span class="op">=</span> []</span>
<span id="cb23-603"><a href="#cb23-603" aria-hidden="true" tabindex="-1"></a>kfold <span class="op">=</span> KFold(shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb23-604"><a href="#cb23-604" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ts, vs <span class="kw">in</span> kfold.split(T):</span>
<span id="cb23-605"><a href="#cb23-605" aria-hidden="true" tabindex="-1"></a>    gaussian <span class="op">=</span> GaussianBayes(naive<span class="op">=</span><span class="va">True</span>).fit(T[ts], y_t[ts])</span>
<span id="cb23-606"><a href="#cb23-606" aria-hidden="true" tabindex="-1"></a>    hy_gaussian <span class="op">=</span> gaussian.predict(T[vs])</span>
<span id="cb23-607"><a href="#cb23-607" aria-hidden="true" tabindex="-1"></a>    _ <span class="op">=</span> recall_score(y_t[vs], hy_gaussian, average<span class="op">=</span><span class="va">None</span>)    </span>
<span id="cb23-608"><a href="#cb23-608" aria-hidden="true" tabindex="-1"></a>    perf.append(_)</span>
<span id="cb23-609"><a href="#cb23-609" aria-hidden="true" tabindex="-1"></a>perf <span class="op">=</span> np.mean(perf, axis<span class="op">=</span><span class="dv">0</span>)  </span>
<span id="cb23-610"><a href="#cb23-610" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
</code><button title="Copiar al portapapeles" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
<p><a href="http://creativecommons.org/licenses/by-sa/4.0/"><img src="https://i.creativecommons.org/l/by-sa/4.0/80x15.png" class="img-fluid"></a> <br> Esta obra está bajo una <a href="http://creativecommons.org/licenses/by-sa/4.0/">Licencia Creative Commons Atribución-CompartirIgual 4.0 Internacional</a></p>
</div>
  </div>
</footer>




</body></html>