<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="es" xml:lang="es"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>1&nbsp; Introducción – Aprendizaje Computacional</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../capitulos/02Teoria_Decision.html" rel="next">
<link href="../index.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-78faf54a06e50be45dc6d83ab59297a7.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Sin resultados",
    "search-matching-documents-text": "documentos encontrados",
    "search-copy-link-title": "Copiar el enlace en la búsqueda",
    "search-hide-matches-text": "Ocultar resultados adicionales",
    "search-more-match-text": "resultado adicional en este documento",
    "search-more-matches-text": "resultados adicionales en este documento",
    "search-clear-button-title": "Borrar",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancelar",
    "search-submit-button-title": "Enviar",
    "search-label": "Buscar"
  }
}</script>
<script src="../site_libs/quarto-diagram/mermaid.min.js"></script>
<script src="../site_libs/quarto-diagram/mermaid-init.js"></script>
<link href="../site_libs/quarto-diagram/mermaid.css" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../capitulos/01Introduccion.html"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introducción</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Buscar" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Aprendizaje Computacional</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/INGEOTEC/AprendizajeComputacional" title="Ejecutar el código" class="quarto-navigation-tool px-1" aria-label="Ejecutar el código"><i class="bi bi-github"></i></a>
    <a href="../Aprendizaje-Computacional.pdf" title="Descargar PDF" class="quarto-navigation-tool px-1" aria-label="Descargar PDF"><i class="bi bi-file-pdf"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Buscar"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Prefacio</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../capitulos/01Introduccion.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introducción</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../capitulos/02Teoria_Decision.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Teoría de Decisión Bayesiana</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../capitulos/03Parametricos.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Métodos Paramétricos</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../capitulos/04Rendimiento.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Rendimiento</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../capitulos/05ReduccionDim.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Reducción de Dimensión</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../capitulos/06Agrupamiento.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Agrupamiento</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../capitulos/07NoParametricos.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Métodos No Paramétricos</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../capitulos/08Arboles.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Árboles de Decisión</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../capitulos/09Lineal.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Discriminantes Lineales</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../capitulos/10Optimizacion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Optimización</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../capitulos/11RedesNeuronales.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Redes Neuronales</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../capitulos/12Ensambles.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Ensambles</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../capitulos/13Comparacion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Comparación de Algoritmos</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../capitulos/17Referencias.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Referencias</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Apéndices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Alternar sección">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../capitulos/14Estadistica.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Estadística</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../capitulos/16ConjuntosDatos.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Conjunto de Datos</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Tabla de contenidos</h2>
   
  <ul>
  <li><a href="#aprendizaje-computacional" id="toc-aprendizaje-computacional" class="nav-link active" data-scroll-target="#aprendizaje-computacional"><span class="header-section-number">1.1</span> Aprendizaje Computacional</a></li>
  <li><a href="#sec-metodologia-general" id="toc-sec-metodologia-general" class="nav-link" data-scroll-target="#sec-metodologia-general"><span class="header-section-number">1.2</span> Metodología General en Aprendizaje Supervisado y No Supervisado</a></li>
  <li><a href="#sec-aprendizaje-no-supervisado" id="toc-sec-aprendizaje-no-supervisado" class="nav-link" data-scroll-target="#sec-aprendizaje-no-supervisado"><span class="header-section-number">1.3</span> Aprendizaje No Supervisado</a></li>
  <li><a href="#sec-aprendizaje-supervisado" id="toc-sec-aprendizaje-supervisado" class="nav-link" data-scroll-target="#sec-aprendizaje-supervisado"><span class="header-section-number">1.4</span> Aprendizaje Supervisado</a></li>
  <li><a href="#sec-definiciones-aprendizaje-supervisado" id="toc-sec-definiciones-aprendizaje-supervisado" class="nav-link" data-scroll-target="#sec-definiciones-aprendizaje-supervisado"><span class="header-section-number">1.5</span> Definiciones de Aprendizaje Supervisado</a>
  <ul class="collapse">
  <li><a href="#estilos-de-aprendizaje" id="toc-estilos-de-aprendizaje" class="nav-link" data-scroll-target="#estilos-de-aprendizaje"><span class="header-section-number">1.5.1</span> Estilos de Aprendizaje</a></li>
  <li><a href="#sobre-aprendizaje" id="toc-sobre-aprendizaje" class="nav-link" data-scroll-target="#sobre-aprendizaje"><span class="header-section-number">1.5.2</span> Sobre-aprendizaje</a></li>
  <li><a href="#sub-aprendizaje" id="toc-sub-aprendizaje" class="nav-link" data-scroll-target="#sub-aprendizaje"><span class="header-section-number">1.5.3</span> Sub-aprendizaje</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span id="sec-intro-01" class="quarto-section-identifier"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introducción</span></span></h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Código</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Mostrar todo el código</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Ocultar todo el código</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">Ver el código fuente</a></li></ul></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>El <strong>objetivo</strong> de la unidad es explicar el área de aprendizaje computacional, los diferentes tipos de aprendizaje que la componen, la metodología general del área y su relación con otras áreas del conocimiento.</p>
<hr>
<div class="quarto-video"><iframe data-external="1" src="https://www.youtube.com/embed/FlipLNC36Zo" width="560" height="315" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<hr>
<section id="aprendizaje-computacional" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="aprendizaje-computacional"><span class="header-section-number">1.1</span> Aprendizaje Computacional</h2>
<p>Utilizando la descripción de <span class="citation" data-cites="langley1986machine">Langley (<a href="17Referencias.html#ref-langley1986machine" role="doc-biblioref">1986</a>)</span>, se puede definir el <strong>aprendizaje computacional</strong> como una rama de la Inteligencia Artificial (IA) que estudia los enfoques computacionales capaces de aprender y mejorar su rendimiento con el paso del tiempo. En sus inicios, el campo estaba enfocado al desarrollo de representaciones simbólicas, de la misma manera que la IA, sin prohibir las representaciones numéricas. Actualmente, el campo ha cambiado de dirección privilegiando las representaciones numéricas a las simbólicas, en particular, este documento se enfoca solamente a representaciones numéricas.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Actividad
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Leer la carta editorial de <span class="citation" data-cites="langley1986machine">Langley (<a href="17Referencias.html#ref-langley1986machine" role="doc-biblioref">1986</a>)</span> para conocer la visión que se tenía de aprendizaje computacional en esa época y contrastarla con la visión actual.</p>
</div>
</div>
</div>
<p>De acuerdo a <span class="citation" data-cites="breiman2001statistical">Breiman (<a href="17Referencias.html#ref-breiman2001statistical" role="doc-biblioref">2001</a>)</span>, existen dos metas al analizar datos donde es posible identificar valores de entrada y su respuesta. Estos objetivos son el <strong>predecir</strong> la respuesta de futuros eventos y el segundo es <strong>extraer conocimiento</strong> del proceso o fenómeno. Estas metas han dado origen a dos culturas en el modelado de los datos: la cultura del modelado de datos y la cultura del modelado de algoritmos.</p>
<p>En la cultura del modelado de datos, se asume que los datos provienen de una función que dependen de los valores de entrada, un conjunto de parámetros y ruido. Utilizando los datos se estiman los parámetros y si los datos cumplen con las condiciones impuestas a la función, entonces se conoce el procedimiento que genera los datos y se está en la posición de obtener conocimiento del sistema, es decir se atacó la segunda meta. Dado que se tienen los parámetros y la estructura de la función es factible hacer predicciones de futuros eventos (primera meta).</p>
<p>En la cultura del modelado del algoritmo, no se asume ninguna estructura al sistema que genera los datos, el procedimiento es diseñar un algoritmo que replique la respuesta dada las entradas. Considerando que no se está asumiendo ningún modelo particular entonces el obtener conocimiento del sistema no es un prioridad. Por otro lado, es una prioridad encontrar el algoritmo que mejor se reproduzca los datos y por lo tanto se desarrollan diferentes estrategias para medir el rendimiento del algoritmo y poder estimar su comportamiento en diferentes escenarios. El área de aprendizaje computacional se encuentra en esta segunda cultura.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Actividad
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Leer el artículo de <span class="citation" data-cites="breiman2001statistical">Breiman (<a href="17Referencias.html#ref-breiman2001statistical" role="doc-biblioref">2001</a>)</span> para profundizar en las ventajas y desventajas de cada una de las culturas y como estas influyen en la forma de abordar un problema. En este momento no es necesario detenerse en la parte técnica de los algoritmos descritos en el artículo.</p>
</div>
</div>
</div>
<p>Existen diferentes tipos de aprendizaje computacional, los mas comunes son: aprendizaje supervisado, aprendizaje no-supervisado y aprendizaje por refuerzo. En <strong>aprendizaje supervisado</strong> se crean modelos partiendo de un conjunto de pares, entrada y salida, donde el objetivo es encontrar un modelo que logra aprender esta relación y predecir ejemplos no vistos en el proceso, en particular a esto se le conoce como <em>inductive learning</em>. Complementando este tipo de aprendizaje supervisado se tiene lo que se conoce como <em>transductive learning</em>, en el cual se cuenta con un conjunto de pares y solamente se requiere conocer la salida en otro conjunto de datos. En este segundo tipo de aprendizaje todos los datos son conocidos en el proceso de aprendizaje.</p>
<p><strong>Aprendizaje no-supervisado</strong> es aquel donde se tiene un conjunto de entradas y se busca aprender alguna relación de estas entradas, por ejemplo, generando grupos o utilizando estas entradas para hacer una transformación o encontrar un patrón.</p>
<p>Finalmente <strong>aprendizaje por refuerzo</strong> es aquel donde se tiene un agente que tiene que aprender como interactuar con un ambiente. La interacción es tomando una acción en cada diferente estado del ambiente. Por ejemplo, el agente puede ser un jugador virtual en un juego de ajedrez entonces la acción es identificar y mover una pieza en el tablero, el objetivo de ganar la partida. La característica de aprendizaje por refuerzo es que el agente va a recibir una recompensa al final de la interacción con el ambiente, e.g., final del juego y el objetivo es optimizar las acciones para que la recompensa sea la mayor posible.</p>
<p>El área de aprendizaje computacional ha tenido un crecimiento importante en los últimos años, algunos ejemplos del impacto de área se pueden encontrar en artículos publicados en la revista de la editorial <a href="https://www.nature.com">Nature</a>. Por ejemplo, en el área médica en específico en Cardiología <span class="citation" data-cites="Hannun2019">Hannun et&nbsp;al. (<a href="17Referencias.html#ref-Hannun2019" role="doc-biblioref">2019</a>)</span> propone una metodología para detectar arritmias o en dermatología <span class="citation" data-cites="Esteva2017">Esteva et&nbsp;al. (<a href="17Referencias.html#ref-Esteva2017" role="doc-biblioref">2017</a>)</span> propone un algoritmo para la detección de cancer.</p>
<p>Cabe mencionar que los tres tipos de aprendizaje no son excluyentes uno del otro, comúnmente para resolver un problema complejo se combinan diferentes tipos de aprendizaje y otras tecnologías de IA para encontrar una solución aceptable. Probablemente una de las pruebas más significativas de lo que puede realizarse con aprendizaje automático es lo realizado por AlphaGo descrito por <span class="citation" data-cites="Silver2016">Silver et&nbsp;al. (<a href="17Referencias.html#ref-Silver2016" role="doc-biblioref">2016</a>)</span> y en <span class="citation" data-cites="Silver2017">Silver et&nbsp;al. (<a href="17Referencias.html#ref-Silver2017" role="doc-biblioref">2017</a>)</span> se quitan una de las restricciones originales, la cual consiste en contar con un conjunto de jugadas realizadas por expertos.</p>
<p>En el área de aprendizaje, hay una tendencia de utilizar plataformas donde diferentes empresas u organismos gubernamentales o sin fines de lucro, ponen un problema e incentivan al publico en general a resolver este problema. La plataforma sirve de mediador en este proceso. Ver por ejemplo <a href="">https://www.kaggle.com</a>.</p>
<p>En el ámbito científico también se han generado este tipo de plataformas aunque su objetivo es ligeramente diferente, lo que se busca es tener una medida objetiva de diferentes soluciones y en algunos casos facilitar la reproducibilidad de las soluciones. Ver por ejemplo <a href="">http://codalab.org</a>.</p>
</section>
<section id="sec-metodologia-general" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="sec-metodologia-general"><span class="header-section-number">1.2</span> Metodología General en Aprendizaje Supervisado y No Supervisado</h2>
<p>Antes de continuar con la descripción de los diferentes tipos de aprendizaje es importante mencionar la metodología que se sigue en los problemas de aprendizaje supervisado y no supervidado</p>
<ol type="1">
<li>Todo empieza con un conjunto de datos <span class="math inline">\(\mathcal D\)</span> que tiene la información del fenómeno de interés.</li>
<li>Se selecciona el conjunto de entrenamiento <span class="math inline">\(\mathcal T \subseteq \mathcal D\)</span>.</li>
<li>Se diseña un algoritmo, <span class="math inline">\(f\)</span>, utilizando <span class="math inline">\(\mathcal T\)</span>.</li>
<li>Se utiliza <span class="math inline">\(f\)</span> para estimar las características modeladas.</li>
<li>Se mide el rendimiento de <span class="math inline">\(f\)</span>.</li>
</ol>
</section>
<section id="sec-aprendizaje-no-supervisado" class="level2" data-number="1.3">
<h2 data-number="1.3" class="anchored" data-anchor-id="sec-aprendizaje-no-supervisado"><span class="header-section-number">1.3</span> Aprendizaje No Supervisado</h2>
<p>Iniciamos la descripción de los diferentes tipos de aprendizaje computacional con <strong>aprendizaje no-supervisado</strong>; el cual inicia con un conjunto de elementos. Estos tradicionalmente se puede transformar en conjunto de vectores, i.e.&nbsp;<span class="math inline">\(\mathcal D = \{ x_1, \ldots, x_N \}\)</span>, donde <span class="math inline">\(x_i \in \mathbb R^d\)</span>. Durante este curso asumiremos que esta transformación existe y en algunos casos se hará explícito el algoritmo de transformación.</p>
<p>El <strong>objetivo</strong> en aprendizaje no supervisado es desarrollar algoritmos capaces de encontrar patrones en los datos, es decir, en <span class="math inline">\(\mathcal D\)</span>. Existen diferentes tareas que se pueden considerar dentro de este tipo de aprendizaje. Por ejemplo, el agrupamiento puede servir para segmentar clientes o productos, en otra línea también cabría el análisis del carrito de compras (Market Basket Analysis); donde el objetivo es encontrar la co-ocurrencias de productos, es decir, se quiere estimar la probabilidad de que habiendo comprado un determinado artículo también se compre otro artículo. Con esta descripción ya se podrá estar imaginando la cantidad de aplicaciones en las que este tipo de algoritmos es utilizado en la actualidad.</p>
<p>Regresando a la representación vectorial, existen casos donde se pueden visualizar los elementos de <span class="math inline">\(\mathcal D\)</span>, lo cuales están representados como puntos que se muestran en la <a href="#fig-puntos-iris" class="quarto-xref">Figura&nbsp;<span>1.1</span></a>. Claramente esto solo es posible si <span class="math inline">\(x_i \in \mathbb R^2\)</span> o si se hace algún tipo de transformación <span class="math inline">\(f: \mathbb R^d \rightarrow \mathbb R^2\)</span>, como se realizó en la figura.</p>
<div id="cell-fig-puntos-iris" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> decomposition</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_iris</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> pylab <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>D, y <span class="op">=</span> load_iris(return_X_y<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> decomposition.PCA(n_components<span class="op">=</span><span class="dv">2</span>).fit(D)</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>Dn <span class="op">=</span> pca.transform(D)</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>Dn <span class="op">=</span> np.concatenate((Dn, np.atleast_2d(y).T), axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(Dn, columns<span class="op">=</span>[<span class="st">'x'</span>, <span class="st">'y'</span>, <span class="st">'Clase'</span>])</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> sns.relplot(data<span class="op">=</span>df, kind<span class="op">=</span><span class="st">'scatter'</span>,</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>                  x<span class="op">=</span><span class="st">'x'</span>, y<span class="op">=</span><span class="st">'y'</span>)</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>fig.tick_params(bottom<span class="op">=</span><span class="va">False</span>, top<span class="op">=</span><span class="va">False</span>, </span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>                left<span class="op">=</span><span class="va">False</span>, right<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>                labelbottom<span class="op">=</span><span class="va">False</span>, labelleft<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>fig.<span class="bu">set</span>(xlabel<span class="op">=</span><span class="va">None</span>, ylabel<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>plt.grid()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-puntos-iris" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-puntos-iris-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="01Introduccion_files/figure-html/fig-puntos-iris-output-1.png" width="409" height="423" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-puntos-iris-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;1.1: Proyección de los datos del Iris en dos dimensiones
</figcaption>
</figure>
</div>
</div>
</div>
<p>En la <a href="#fig-puntos-iris" class="quarto-xref">Figura&nbsp;<span>1.1</span></a> se pueden observar dos o tres grupos de puntos, entonces el objetivo sería crear el algoritmo que dado <span class="math inline">\(\mathcal D\)</span> regrese un identificador por cada elemento, dicho identificador representa el grupo al que pertenece el elemento en cuestión. Esta tarea se le conoce como agrupamiento (Clustering). Asumiendo que se aplica un algoritmo de agrupamiento a los datos anteriores; entonces, dado que podemos visualizar los datos, es factible representar el resultado del algoritmo si a cada punto se le asigna un color dependiendo de la clase a la que pertenece. La <a href="#fig-kmeans-iris" class="quarto-xref">Figura&nbsp;<span>1.2</span></a> muestra el resultado de este procedimiento.</p>
<div id="cell-fig-kmeans-iris" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> decomposition</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_iris</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> pylab <span class="im">as</span> plt</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>D, y <span class="op">=</span> load_iris(return_X_y<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">3</span>, n_init<span class="op">=</span><span class="st">'auto'</span>).fit(D)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>cl <span class="op">=</span> m.predict(D)</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> decomposition.PCA(n_components<span class="op">=</span><span class="dv">2</span>).fit(D)</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>Dn <span class="op">=</span> pca.transform(D)</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>Dn <span class="op">=</span> np.concatenate((Dn, np.atleast_2d(y).T,</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>                     np.atleast_2d(cl).T), axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(Dn, columns<span class="op">=</span>[<span class="st">'x'</span>, <span class="st">'y'</span>, <span class="st">'Clase'</span>, <span class="st">'Grupo'</span>])</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> sns.relplot(data<span class="op">=</span>df, kind<span class="op">=</span><span class="st">'scatter'</span>,</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>                  x<span class="op">=</span><span class="st">'x'</span>, y<span class="op">=</span><span class="st">'y'</span>, hue<span class="op">=</span><span class="st">'Grupo'</span>)</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>fig.tick_params(bottom<span class="op">=</span><span class="va">False</span>, top<span class="op">=</span><span class="va">False</span>, </span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>                left<span class="op">=</span><span class="va">False</span>, right<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>                labelbottom<span class="op">=</span><span class="va">False</span>, labelleft<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>fig.<span class="bu">set</span>(xlabel<span class="op">=</span><span class="va">None</span>, ylabel<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>plt.grid()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-kmeans-iris" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-kmeans-iris-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="01Introduccion_files/figure-html/fig-kmeans-iris-output-1.png" width="475" height="423" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-kmeans-iris-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;1.2: Proyección de agrupar los datos del Iris usando K-medias
</figcaption>
</figure>
</div>
</div>
</div>
<p>Se puede observar en la figura anterior, el algoritmo de agrupamiento separa los puntos en tres grupos, representados por los colores diferentes colores. Cabe mencionar que utilizando algún otro criterio de optimización se hubiera podido encontrar dos grupos, el primero de ellos sería el grupo de los puntos que se encuentran a la izquierda de la figura y el segundo sería el grupo formado por los grupos que se encuentran en el centro y a la derecha de la figura. Es importante recalcar que no es necesario visualizar los datos para aplicar un algoritmo de agrupamiento. En particular el ejercicio de visualización de datos y del resultado de agrupamiento que se muestra en la figuras anteriores tiene el objetivo de generar una intuición de lo que está haciendo un algoritmo de agrupamiento.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Actividad
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Generar la figura anterior para el conjunto de datos de Breast Cancer Wisconsin (<a href="16ConjuntosDatos.html#sec-breast-cancer-wisconsin" class="quarto-xref"><span>Sección B.3.1</span></a>). Es necesario considerar que ese problema solamente tiene dos clases y el problema del Iris (<a href="16ConjuntosDatos.html#sec-iris" class="quarto-xref"><span>Sección B.3.2</span></a>) tiene tres clases, entonces se tienen que hacer las modificaciones para atender este cambio.</p>
<p>El procedimiento desarrollado debe de generar una figura similar a la mostrada en la <a href="#fig-kmeans-breast-cancer" class="quarto-xref">Figura&nbsp;<span>1.3</span></a></p>
<div id="cell-fig-kmeans-breast-cancer" class="cell" data-execution_count="3">
<div class="cell-output cell-output-display">
<div id="fig-kmeans-breast-cancer" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-kmeans-breast-cancer-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="01Introduccion_files/figure-html/fig-kmeans-breast-cancer-output-1.png" width="471" height="425" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-kmeans-breast-cancer-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;1.3: Proyección de agrupar los datos de Breast Cancer Wisconsin usando K-medias
</figcaption>
</figure>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="sec-aprendizaje-supervisado" class="level2" data-number="1.4">
<h2 data-number="1.4" class="anchored" data-anchor-id="sec-aprendizaje-supervisado"><span class="header-section-number">1.4</span> Aprendizaje Supervisado</h2>
<p>Aprendizaje supervisado inicia con un conjunto de pares, entrada y salida; la <a href="#fig-datos-aprendizaje-supervisado" class="quarto-xref">Figura&nbsp;<span>1.4</span></a> ilustra el mecanismo que genera estos pares, del lado izquierdo se tiene las variables medibles que entran al proceso o fenómeno que se desconoce y del lado derecho se mide la(s) variable(s) respuesta, es decir, la(s) salida(s) del sistema. En otras palabras se tiene <span class="math inline">\(\mathcal D = \{ (x_1, y_1), \ldots, (x_N, y_N )\}\)</span>, donde <span class="math inline">\(x_i \in \mathbb R^d\)</span> corresponde a la <span class="math inline">\(i\)</span>-ésima entrada y <span class="math inline">\(y_i\)</span> es la salida asociada a esa entrada.</p>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div id="fig-datos-aprendizaje-supervisado" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-datos-aprendizaje-supervisado-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div>
<pre class="mermaid mermaid-js" data-label="fig-datos-aprendizaje-supervisado">flowchart LR
    Entrada([Entradas]) --&gt;  Proceso[Proceso / Fenómeno]
    Proceso --&gt; Salidas([Salidas])
</pre>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-datos-aprendizaje-supervisado-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;1.4: Datos de Aprendizaje Supervisado
</figcaption>
</figure>
</div>
</div>
</div>
<p>Considerando que se desconoce el modelo del proceso o fenómeno que generó la respuesta y además que pueden existir variables de entrada que no son medibles, se puede definir el <strong>objetivo</strong> de aprendizaje supervisado como encontrar un algoritmo o función, <span class="math inline">\(f\)</span>, capaz de regresar la salida, <span class="math inline">\(y\)</span>, dada una entrada <span class="math inline">\(x\)</span>.</p>
<p>Los posibles fines de desarrollar la función <span class="math inline">\(f\)</span> es por un lado <strong>predecir</strong> la salida dada una nueva entrada <span class="math inline">\(x\)</span> y por el otro lado <strong>extraer conocimiento</strong> del proceso que asocia la respuesta de las variables de entrada (ver <span class="citation" data-cites="breiman2001statistical">Breiman (<a href="17Referencias.html#ref-breiman2001statistical" role="doc-biblioref">2001</a>)</span>). Estos dos metas se pueden contraponer, es decir, extraer conocimiento implica una reducción en la calidad de la predicción y viceversa mejorar la calidad de predicción en general trae consigo una menor capacidad para entender el fenómeno generador de datos.</p>
<p>Existe una gran variedad de problemas que se puede categorizar como tareas de aprendizaje supervisado, solamente hay que recordar que en todos los casos se inicia con un conjunto <span class="math inline">\(\mathcal D\)</span> de pares entrada y salida. En ocasiones la construcción del conjunto es directa, por ejemplo en el caso de que se quiera identificar si una persona será sujeta a un crédito, entonces el conjunto a crear esta compuesto por las características de las personas que se les ha otorgado un crédito y el estado final de crédito, es decir, si el crédito fue pagado o no fue pagado. En otro ejemplo, suponiendo que se quiere crear un algoritmo capaz de identificar si un texto dado tiene una polaridad positiva o negativa, entonces el conjunto se crea recolectando textos y a cada texto un conjunto de personas decide si el texto dado es positivo o negativo y la polaridad final es el consenso de varias opiniones; a este problema en general se le conoce como análisis de sentimientos.</p>
<p>La cantidad de problema que se pueden poner en términos de aprendizaje supervisado es amplia, un problema tangible en esta época y relacionado a la pandemia del COVID-19 sería el crear un algoritmo que pudiera predecir cuántos serán los casos positivos el día de mañana dando como entradas las restricciones en las actividades; por ejemplo escuelas cerradas, restaurantes al 30% de capacidad entre otras.</p>
<p>Los ejemplos anteriores corresponden a dos de las clases de problemas que se resuelven en aprendizaje supervisado estas son problemas de clasificación y regresión. Definamos de manera formal estos dos problemas. Cuando <span class="math inline">\(y \in \{0, 1\}\)</span> se dice que es un problema de <strong>clasificación binaria</strong>, por otro lado cuando <span class="math inline">\(y \in \{0, 1\}^K\)</span> se encuentra uno en clasificación <strong>multi-clase</strong> o <strong>multi-etiqueta</strong> y finalmente si <span class="math inline">\(y \in \mathbb R\)</span> entonces es un problema de <strong>regresión</strong>.</p>
<p>Haciendo la liga entre los ejemplos y las definiciones anteriores, podemos observar que el asignar un crédito o la polaridad a un texto es un problema de clasificación binaria, dado que se puede asociar 0 y 1 a la clase positivo y negativo; y en el otro caso a pagar o no pagar el crédito. Si el problema tiene mas categorías, supongamos que se desea identificar positivo, negativo o neutro, entonces se estaría en el problema de clasificación multi-clase. Por otro lado el problema de predecir el número de casos positivos se puede considerar como un problema de regresión, dado que el valor a predecir difícilmente se podría considerar como una categoría.</p>
<p>Al igual que en aprendizaje no supervisado, en algunos casos es posible visualizar los elementos de <span class="math inline">\(\mathcal D\)</span>, el detalle adicional es que cada objeto tiene asociado una clase, entonces se selecciona un color para representar cada clase. En la <a href="#fig-iris-2clases" class="quarto-xref">Figura&nbsp;<span>1.5</span></a> se muestra el resultado donde los elementos de <span class="math inline">\(\mathcal D\)</span> se encuentra en <span class="math inline">\(\mathbb R^2\)</span> y el color representa cada una de la clases de este problema de clasificación binaria.</p>
<div id="cell-fig-iris-2clases" class="cell" data-execution_count="4">
<details class="code-fold">
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> decomposition</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_iris</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> pylab <span class="im">as</span> plt</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>D, y <span class="op">=</span> load_iris(return_X_y<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>mask <span class="op">=</span> y <span class="op">&lt;=</span> <span class="dv">1</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>D <span class="op">=</span> D[mask]</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> y[mask]</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> decomposition.PCA(n_components<span class="op">=</span><span class="dv">2</span>).fit(D)</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>Dn <span class="op">=</span> pca.transform(D)</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(Dn, columns<span class="op">=</span>[<span class="st">'x'</span>, <span class="st">'y'</span>])</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'Clase'</span>] <span class="op">=</span> [<span class="st">'P'</span> <span class="cf">if</span> i <span class="cf">else</span> <span class="st">'N'</span> <span class="cf">for</span> i <span class="kw">in</span> y]</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> sns.relplot(data<span class="op">=</span>df, kind<span class="op">=</span><span class="st">'scatter'</span>,</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>                  x<span class="op">=</span><span class="st">'x'</span>, y<span class="op">=</span><span class="st">'y'</span>, hue<span class="op">=</span><span class="st">'Clase'</span>)</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>fig.tick_params(bottom<span class="op">=</span><span class="va">False</span>, top<span class="op">=</span><span class="va">False</span>, </span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>                left<span class="op">=</span><span class="va">False</span>, right<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>                labelbottom<span class="op">=</span><span class="va">False</span>, labelleft<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>fig.<span class="bu">set</span>(xlabel<span class="op">=</span><span class="va">None</span>, ylabel<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>plt.grid()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-iris-2clases" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-iris-2clases-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="01Introduccion_files/figure-html/fig-iris-2clases-output-1.png" width="466" height="428" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-iris-2clases-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;1.5: Proyección del Iris mostrando dos clases linealmente separables
</figcaption>
</figure>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Actividad
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Generar la figura anterior para el conjunto de datos de Breast Cancer Wisconsin (<a href="16ConjuntosDatos.html#sec-breast-cancer-wisconsin" class="quarto-xref"><span>Sección B.3.1</span></a>). Como se mencionó, el problema tiene dos clases entonces no se necesita ningún tipo de transformación en el número de clases como se hizo en el ejemplo anterior. La <a href="#fig-breast-cancer" class="quarto-xref">Figura&nbsp;<span>1.6</span></a> muestra el resultado de la actividad.</p>
<div id="cell-fig-breast-cancer" class="cell" data-execution_count="5">
<div class="cell-output cell-output-display">
<div id="fig-breast-cancer" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-breast-cancer-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="01Introduccion_files/figure-html/fig-breast-cancer-output-1.png" width="471" height="425" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-breast-cancer-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;1.6: Proyección de los datos de Breast Cancer Wisconsin.
</figcaption>
</figure>
</div>
</div>
</div>
</div>
</div>
</div>
<p>Usando esta representación es sencillo imaginar que el problema de clasificación se trata en encontrar una función que separe los puntos naranjas de los puntos azules, como se pueden imagina una simple línea recta podría separar estos puntos. La <a href="#fig-iris-2clases-df" class="quarto-xref">Figura&nbsp;<span>1.7</span></a> muestra un ejemplo de lo que haría un clasificador representado por la línea; la clase es dada por el signo de <span class="math inline">\(ax + by + c\)</span>, donde <span class="math inline">\(a\)</span>, <span class="math inline">\(b\)</span> y <span class="math inline">\(c\)</span> son parámetros identificados a partir de <span class="math inline">\(\mathcal D\)</span>.</p>
<div id="cell-fig-iris-2clases-df" class="cell" data-execution_count="6">
<details class="code-fold">
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> LinearSVC</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> decomposition</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_iris</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> pylab <span class="im">as</span> plt</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>D, y <span class="op">=</span> load_iris(return_X_y<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>mask <span class="op">=</span> y <span class="op">&lt;=</span> <span class="dv">1</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>D <span class="op">=</span> D[mask]</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> y[mask]</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> decomposition.PCA(n_components<span class="op">=</span><span class="dv">2</span>).fit(D)</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>Dn <span class="op">=</span> pca.transform(D)</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>linear <span class="op">=</span> LinearSVC(dual<span class="op">=</span><span class="va">False</span>).fit(Dn, y)</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>w_1, w_2 <span class="op">=</span> linear.coef_[<span class="dv">0</span>]</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>w_0 <span class="op">=</span> linear.intercept_[<span class="dv">0</span>]</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(Dn, columns<span class="op">=</span>[<span class="st">'x1'</span>, <span class="st">'x2'</span>])</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'Clase'</span>] <span class="op">=</span> [<span class="st">'N'</span> <span class="cf">if</span> i <span class="cf">else</span> <span class="st">'P'</span> <span class="cf">for</span> i <span class="kw">in</span> y]</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>g_0 <span class="op">=</span> [<span class="bu">dict</span>(x1<span class="op">=</span>x, x2<span class="op">=</span>y, tipo<span class="op">=</span><span class="st">'g(x)=0'</span>)</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>       <span class="cf">for</span> x, y <span class="kw">in</span> <span class="bu">zip</span>(Dn[:, <span class="dv">0</span>], (<span class="op">-</span>w_0 <span class="op">-</span> w_1 <span class="op">*</span> Dn[:, <span class="dv">0</span>]) <span class="op">/</span> w_2)]</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>g <span class="op">=</span> pd.DataFrame(g_0)</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>g[<span class="st">'Tipo'</span>] <span class="op">=</span> <span class="st">'g(x)=0'</span></span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.concat((df, g))</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> sns.scatterplot(data<span class="op">=</span>df, x<span class="op">=</span><span class="st">'x1'</span>, y<span class="op">=</span><span class="st">'x2'</span>, hue<span class="op">=</span><span class="st">'Clase'</span>, legend<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>sns.lineplot(data<span class="op">=</span>df, x<span class="op">=</span><span class="st">'x1'</span>, y<span class="op">=</span><span class="st">'x2'</span>, ax<span class="op">=</span>ax, hue<span class="op">=</span><span class="st">'Tipo'</span>, palette<span class="op">=</span>[<span class="st">'k'</span>], legend<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>ax.tick_params(axis<span class="op">=</span><span class="st">"both"</span>, which<span class="op">=</span><span class="st">"both"</span>, bottom<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>                top<span class="op">=</span><span class="va">False</span>, left<span class="op">=</span><span class="va">False</span>, right<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>                labelbottom<span class="op">=</span><span class="va">False</span>, labelleft<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>ax.<span class="bu">set</span>(xlabel<span class="op">=</span><span class="va">None</span>, ylabel<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a>plt.grid()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-iris-2clases-df" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-iris-2clases-df-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="01Introduccion_files/figure-html/fig-iris-2clases-df-output-1.png" width="540" height="389" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-iris-2clases-df-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;1.7: Proyección del Iris mostrando dos clases linealmente separables
</figcaption>
</figure>
</div>
</div>
</div>
<p>Siguiendo en esta misma línea, también es posible observar los puntos en un problema de regresión, solamente que en este caso un eje corresponde a las entradas, i.e.&nbsp;<span class="math inline">\(x\)</span>, y el otro eje es la salida, i.e.&nbsp;<span class="math inline">\(y\)</span>. La <a href="#fig-regresion" class="quarto-xref">Figura&nbsp;<span>1.8</span></a> muestra un ejemplo de regresión, donde se puede observar que la idea es una encontrar una función que pueda seguir de manera adecuada los puntos datos.</p>
<div id="cell-fig-regresion" class="cell" data-execution_count="7">
<details class="code-fold">
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> pylab <span class="im">as</span> plt</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">100</span>)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> <span class="fl">12.3</span> <span class="op">*</span> x<span class="op">**</span><span class="dv">2</span> <span class="op">-</span> <span class="fl">3.2</span> <span class="op">*</span> x <span class="op">+</span> <span class="fl">1.2</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>ym <span class="op">=</span> np.random.normal(loc<span class="op">=</span><span class="dv">0</span>, scale<span class="op">=</span><span class="fl">0.2</span>, size<span class="op">=</span>x.shape[<span class="dv">0</span>]) <span class="op">+</span> y</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(<span class="bu">dict</span>(x<span class="op">=</span>x, y<span class="op">=</span>y, ym<span class="op">=</span>ym))</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&nbsp;sns.lineplot(data=df, x='x', y='y', legend=False, color='k')</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> sns.scatterplot(data<span class="op">=</span>df, x<span class="op">=</span><span class="st">'x'</span>, y<span class="op">=</span><span class="st">'ym'</span>, legend<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>fig.tick_params(bottom<span class="op">=</span><span class="va">False</span>, top<span class="op">=</span><span class="va">False</span>, </span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>                left<span class="op">=</span><span class="va">False</span>, right<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>                labelbottom<span class="op">=</span><span class="va">False</span>, labelleft<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>fig.<span class="bu">set</span>(xlabel<span class="op">=</span><span class="st">'x'</span>, ylabel<span class="op">=</span><span class="st">'y'</span>)</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>plt.grid()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-regresion" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-regresion-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="01Introduccion_files/figure-html/fig-regresion-output-1.png" width="558" height="407" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-regresion-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;1.8: Problema de regresión
</figcaption>
</figure>
</div>
</div>
</div>
<p>El problema de regresión es muy conocido y seguramente ya se imaginaron que la respuesta sería encontrar los parámetros de una parábola. La <a href="#fig-regresion-2" class="quarto-xref">Figura&nbsp;<span>1.9</span></a> muestra una visualización del regresor, mostrado en color negro y los datos de entrenamiento en color azul.</p>
<div id="cell-fig-regresion-2" class="cell" data-execution_count="8">
<details class="code-fold">
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>sns.lineplot(data<span class="op">=</span>df, x<span class="op">=</span><span class="st">'x'</span>, y<span class="op">=</span><span class="st">'y'</span>, legend<span class="op">=</span><span class="va">False</span>, color<span class="op">=</span><span class="st">'k'</span>)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> sns.scatterplot(data<span class="op">=</span>df, x<span class="op">=</span><span class="st">'x'</span>, y<span class="op">=</span><span class="st">'ym'</span>, legend<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>fig.tick_params(axis<span class="op">=</span><span class="st">"both"</span>, which<span class="op">=</span><span class="st">"both"</span>, bottom<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>                top<span class="op">=</span><span class="va">False</span>, left<span class="op">=</span><span class="va">False</span>, right<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>                labelbottom<span class="op">=</span><span class="va">False</span>, labelleft<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>fig.<span class="bu">set</span>(xlabel<span class="op">=</span><span class="st">'x'</span>, ylabel<span class="op">=</span><span class="st">'y'</span>)</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>plt.grid()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-regresion-2" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-regresion-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="01Introduccion_files/figure-html/fig-regresion-2-output-1.png" width="558" height="407" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-regresion-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;1.9: Problema de regresión con función con función estimada
</figcaption>
</figure>
</div>
</div>
</div>
<p>Al igual que en aprendizaje no supervisado, este ejercicio de visualización no es posible en todos los problemas de aprendizaje supervisado, pero si permite ganar intuición sobre la forma en que trabajan estos algoritmos.</p>
</section>
<section id="sec-definiciones-aprendizaje-supervisado" class="level2" data-number="1.5">
<h2 data-number="1.5" class="anchored" data-anchor-id="sec-definiciones-aprendizaje-supervisado"><span class="header-section-number">1.5</span> Definiciones de Aprendizaje Supervisado</h2>
<p>El primer paso es empezar a definir los diferentes conjuntos con los que se trabaja en aprendizeje computacional. Todo inicia con el <strong>conjunto de entrenamiento</strong> identificado en este documento como <span class="math inline">\(\mathcal T\)</span>. Este conjunto se utiliza para estimar los parámetros o en general buscar un algoritmo que tenga el comportamiento esperado.</p>
<p>Se puede asumir que existe una función <span class="math inline">\(f\)</span> que genera la relación entrada salida mostrada en <span class="math inline">\(\mathcal T\)</span>, es decir, idealmente se tiene que <span class="math inline">\(\forall_{(x, y) \in \mathcal D} f(x) = y\)</span>. En este contexto, aprendizaje supervisado se entiende como el proceso de encontrar una función <span class="math inline">\(h^*\)</span> que se comporta similar a <span class="math inline">\(f\)</span>.</p>
<p>Para encontrar <span class="math inline">\(h^*\)</span>, se utiliza <span class="math inline">\(\mathcal T\)</span>; el conjunto de hipótesis (funciones), <span class="math inline">\(\mathcal H\)</span>, que se considera puede aproximar <span class="math inline">\(f\)</span>; una función de error, <span class="math inline">\(L\)</span>; y el error empírico <span class="math inline">\(E(h \mid \mathcal T) = \sum_{(x, y) \in \mathcal T} L(y, h(x))\)</span>. Utilizando estos elementos la función buscada es: <span class="math inline">\(h^* = \textsf{argmin}_{h \in \mathcal{H}} E(h \mid \mathcal T)\)</span>.</p>
<p>El encontrar la función <span class="math inline">\(h^*\)</span> no resuelve el problema de aprendizaje en su totalidad, además se busca una función que sea capaz de generalizar, es decir, que pueda predecir correctamente instancias no vistas. Considerando que se tiene un <strong>conjunto de prueba</strong>, <span class="math inline">\(\mathcal G=\{(x_i, y_i)\}\)</span> para <span class="math inline">\(i=1 \ldots M\)</span>, donde <span class="math inline">\(\mathcal T \cap \mathcal G = \emptyset\)</span> y <span class="math inline">\(\mathcal T \cup \mathcal G = \mathcal D.\)</span> La idea es que el error empírico sea similar en el conjunto de entrenamiento y prueba. Es decir <span class="math inline">\(E(h^* \mid \mathcal T) \approx E(h^* \mid \mathcal G)\)</span>.</p>
<section id="estilos-de-aprendizaje" class="level3" data-number="1.5.1">
<h3 data-number="1.5.1" class="anchored" data-anchor-id="estilos-de-aprendizaje"><span class="header-section-number">1.5.1</span> Estilos de Aprendizaje</h3>
<p>Utilizando <span class="math inline">\(\mathcal T\)</span> y <span class="math inline">\(\mathcal G\)</span> podemos definir <strong>inductive learning</strong> como el proceso de aprendizaje en donde solamente se utiliza <span class="math inline">\(\mathcal T\)</span> y el algoritmo debe de ser capaz de predecir cualquier instancia. Por otro lado, <strong>transductive learning</strong> es el proceso de aprendizaje donde se utilizar <span class="math inline">\(\mathcal T \cup \{ x \mid (x, y) \in \mathcal G \}\)</span> para aprender y solamente es de interés el conocer la clase o variable dependiente del conjunto <span class="math inline">\(\mathcal G\)</span>.</p>
</section>
<section id="sobre-aprendizaje" class="level3" data-number="1.5.2">
<h3 data-number="1.5.2" class="anchored" data-anchor-id="sobre-aprendizaje"><span class="header-section-number">1.5.2</span> Sobre-aprendizaje</h3>
<p>Existen clases de algoritmos, <span class="math inline">\(\mathcal H\)</span>, que tienen un mayor grado de libertad el cual se ve reflejado en una capacidad superior para aprender, pero por otro lado, existen problemas donde no se requiere tanta libertad, esta combinación se traduce en que el algoritmo no es capaz de generalizar y cuantitativamente se ve como <span class="math inline">\(E(h^* \mid \mathcal T) \ll E(h^* \mid \mathcal G)\)</span>.</p>
<p>Para mostrar este caso hay que imaginar que se tiene un algoritmo que guarda el conjunto de entrenamiento y responde lo siguiente:</p>
<p><span class="math display">\[h^*(x) = \begin{cases} y &amp; \text{si} (x, y) \in \mathcal T\\ 0 &amp; \end{cases}\]</span></p>
<p>Es fácil observar que este algoritmo tiene <span class="math inline">\(E(h^* \mid \mathcal T) = 0\)</span> dado que se aprende todo el conjunto de entrenamiento.</p>
<p>La <a href="#fig-sobre-aprendizaje" class="quarto-xref">Figura&nbsp;<span>1.10</span></a> muestra el comportamiento de un algoritmo que sobre-aprende, el algoritmo se muestra en la línea naranja, la línea azul corresponde a una parábola (cuyos parámetros son identificados con los datos de entrenamiento) y los datos de entrenamiento no se muestran; pero se pueden visualizar dado que son datos generados por una parábola mas un error gaussiano. Entonces podemos ver que la línea naranja pasa de manera exacta por todos los datos de entrenamiento y da como resultado la línea naranja que claramente tiene un comportamiento mas complejo que el comportamiento de la parábola que generó los datos.</p>
<div id="cell-fig-sobre-aprendizaje" class="cell" data-execution_count="9">
<details class="code-fold">
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> tree</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>arbol <span class="op">=</span> tree.DecisionTreeRegressor().fit(np.atleast_2d(x).T, ym)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>hy <span class="op">=</span> arbol.predict(np.atleast_2d(x).T)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'arbol'</span>] <span class="op">=</span> hy</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>sns.lineplot(data<span class="op">=</span>df, x<span class="op">=</span><span class="st">'x'</span>, y<span class="op">=</span><span class="st">'arbol'</span>, legend<span class="op">=</span><span class="va">False</span>, color<span class="op">=</span><span class="st">'k'</span>)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> sns.scatterplot(data<span class="op">=</span>df, x<span class="op">=</span><span class="st">'x'</span>, y<span class="op">=</span><span class="st">'y'</span>, legend<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>fig.tick_params(bottom<span class="op">=</span><span class="va">False</span>, top<span class="op">=</span><span class="va">False</span>, </span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>                left<span class="op">=</span><span class="va">False</span>, right<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>                labelbottom<span class="op">=</span><span class="va">False</span>, labelleft<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>fig.<span class="bu">set</span>(xlabel<span class="op">=</span><span class="st">'x'</span>, ylabel<span class="op">=</span><span class="st">'y'</span>)</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>plt.grid()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-sobre-aprendizaje" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-sobre-aprendizaje-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="01Introduccion_files/figure-html/fig-sobre-aprendizaje-output-1.png" width="558" height="407" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sobre-aprendizaje-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;1.10: Sobre-aprendizaje en un problema de regresión
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="sub-aprendizaje" class="level3" data-number="1.5.3">
<h3 data-number="1.5.3" class="anchored" data-anchor-id="sub-aprendizaje"><span class="header-section-number">1.5.3</span> Sub-aprendizaje</h3>
<p>Por otro lado existen problemas donde el conjunto de algoritmos <span class="math inline">\(\mathcal H\)</span> no tienen los grados de libertad necesarios para aprender, dependiendo de la medida de error esto se refleja como <span class="math inline">\(E(h^* \mid \mathcal T) \gg 0\)</span>. La <a href="#fig-sub-aprendizaje" class="quarto-xref">Figura&nbsp;<span>1.11</span></a> muestra un problema de regresión donde el algoritmo de aprendizaje presenta el problema de sub-aprendizaje.</p>
<div id="cell-fig-sub-aprendizaje" class="cell" data-execution_count="10">
<details class="code-fold">
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> tree</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>arbol <span class="op">=</span> tree.DecisionTreeRegressor(max_depth<span class="op">=</span><span class="dv">2</span>).fit(np.atleast_2d(x).T, ym)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>hy <span class="op">=</span> arbol.predict(np.atleast_2d(x).T)</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'arbol'</span>] <span class="op">=</span> hy</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>sns.lineplot(data<span class="op">=</span>df, x<span class="op">=</span><span class="st">'x'</span>, y<span class="op">=</span><span class="st">'arbol'</span>, legend<span class="op">=</span><span class="va">False</span>, color<span class="op">=</span><span class="st">'k'</span>)</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> sns.scatterplot(data<span class="op">=</span>df, x<span class="op">=</span><span class="st">'x'</span>, y<span class="op">=</span><span class="st">'y'</span>, legend<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>fig.tick_params(bottom<span class="op">=</span><span class="va">False</span>, top<span class="op">=</span><span class="va">False</span>, </span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>                left<span class="op">=</span><span class="va">False</span>, right<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>                labelbottom<span class="op">=</span><span class="va">False</span>, labelleft<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>fig.<span class="bu">set</span>(xlabel<span class="op">=</span><span class="st">'x'</span>, ylabel<span class="op">=</span><span class="st">'y'</span>)</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>plt.grid()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-sub-aprendizaje" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-sub-aprendizaje-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="01Introduccion_files/figure-html/fig-sub-aprendizaje-output-1.png" width="558" height="407" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sub-aprendizaje-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;1.11: Sub-aprendizaje en un problema de regresión
</figcaption>
</figure>
</div>
</div>
</div>


<!-- -->

<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-breiman2001statistical" class="csl-entry" role="listitem">
Breiman, Leo. 2001. <span>«Statistical modeling: The two cultures»</span>. <em>Statistical science</em> 16 (3): 199-231. <a href="https://doi.org/10.1214/ss/1009213726">https://doi.org/10.1214/ss/1009213726</a>.
</div>
<div id="ref-Esteva2017" class="csl-entry" role="listitem">
Esteva, Andre, Brett Kuprel, Roberto A. Novoa, Justin Ko, Susan M. Swetter, Helen M. Blau, y Sebastian Thrun. 2017. <span>«Dermatologist-level classification of skin cancer with deep neural networks»</span>. <em>Nature</em> 542 (7639): 115-18. <a href="https://doi.org/10.1038/nature21056">https://doi.org/10.1038/nature21056</a>.
</div>
<div id="ref-Hannun2019" class="csl-entry" role="listitem">
Hannun, Awni Y., Pranav Rajpurkar, Masoumeh Haghpanahi, Geoffrey H. Tison, Codie Bourn, Mintu P. Turakhia, y Andrew Y. Ng. 2019. <span>«Cardiologist-level arrhythmia detection and classification in ambulatory electrocardiograms using a deep neural network»</span>. <em>Nature Medicine</em> 25 (1): 65-69. <a href="https://doi.org/10.1038/s41591-018-0268-3">https://doi.org/10.1038/s41591-018-0268-3</a>.
</div>
<div id="ref-langley1986machine" class="csl-entry" role="listitem">
Langley, Pat. 1986. <span>«Machine learning: An editorial»</span>. <em>Maching Learning</em> 1: 5-10. <a href="https://doi.org/10.1023/A:1022687019898">https://doi.org/10.1023/A:1022687019898</a>.
</div>
<div id="ref-Silver2016" class="csl-entry" role="listitem">
Silver, David, Aja Huang, Chris J. Maddison, Arthur Guez, Laurent Sifre, George van den Driessche, Julian Schrittwieser, et&nbsp;al. 2016. <span>«Mastering the game of Go with deep neural networks and tree search»</span>. <em>Nature</em> 529 (7587): 484-89. <a href="https://doi.org/10.1038/nature16961">https://doi.org/10.1038/nature16961</a>.
</div>
<div id="ref-Silver2017" class="csl-entry" role="listitem">
Silver, David, Julian Schrittwieser, Karen Simonyan, Ioannis Antonoglou, Aja Huang, Arthur Guez, Thomas Hubert, et&nbsp;al. 2017. <span>«Mastering the game of Go without human knowledge»</span>. <em>Nature</em> 550 (7676): 354-59. <a href="https://doi.org/10.1038/nature24270">https://doi.org/10.1038/nature24270</a>.
</div>
</div>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copiado");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copiado");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/ingeotec\.github\.io\/AprendizajeComputacional");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../index.html" class="pagination-link" aria-label="Prefacio">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Prefacio</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../capitulos/02Teoria_Decision.html" class="pagination-link" aria-label="Teoría de Decisión Bayesiana">
        <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Teoría de Decisión Bayesiana</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Ejecutar el código</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb9" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># Introducción {#sec-intro-01}</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>El **objetivo** de la unidad es explicar el área de aprendizaje computacional, los diferentes tipos de aprendizaje que la componen, la metodología general del área y su relación con otras áreas del conocimiento. </span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>::: {.content-visible when-format="html"}</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>{{&lt; video https://www.youtube.com/embed/FlipLNC36Zo width="560" height="315" &gt;}}</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a><span class="fu">## Aprendizaje Computacional</span></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>Utilizando la descripción de @langley1986machine, se puede definir el **aprendizaje computacional** como una rama de la Inteligencia Artificial (IA) que estudia los enfoques computacionales capaces de aprender y mejorar su rendimiento con el paso del tiempo. En sus inicios, el campo estaba enfocado al desarrollo de representaciones simbólicas, de la misma manera que la IA, sin prohibir las representaciones numéricas. Actualmente, el campo ha cambiado de dirección privilegiando las representaciones numéricas a las simbólicas, en particular, este documento se enfoca solamente a representaciones numéricas. </span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip collapse="true"}</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a><span class="fu">### Actividad</span></span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>Leer la carta editorial de @langley1986machine para conocer la visión que se tenía de aprendizaje computacional en esa época y contrastarla con la visión actual. </span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>De acuerdo a @breiman2001statistical, existen dos metas al analizar datos donde es posible identificar valores de entrada y su respuesta. Estos objetivos son el **predecir** la respuesta de futuros eventos y el segundo es **extraer conocimiento** del proceso o fenómeno. Estas metas han dado origen a dos culturas en el modelado de los datos: la cultura del modelado de datos y la cultura del modelado de algoritmos. </span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a>En la cultura del modelado de datos, se asume que los datos provienen de una función que dependen de los valores de entrada, un conjunto de parámetros y ruido. Utilizando los datos se estiman los parámetros y si los datos cumplen con las condiciones impuestas a la función, entonces se conoce el procedimiento que genera los datos y se está en la posición de obtener conocimiento del sistema, es decir se atacó la segunda meta. Dado que se tienen los parámetros y la estructura de la función es factible hacer predicciones de futuros eventos (primera meta).</span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a>En la cultura del modelado del algoritmo, no se asume ninguna estructura al sistema que genera los datos, el procedimiento es diseñar un algoritmo que replique la respuesta dada las entradas. Considerando que no se está asumiendo ningún modelo particular entonces el obtener conocimiento del sistema no es un prioridad. Por otro lado, es una prioridad encontrar el algoritmo que mejor se reproduzca los datos y por lo tanto se desarrollan diferentes estrategias para medir el rendimiento del algoritmo y poder estimar su comportamiento en diferentes escenarios. El área de aprendizaje computacional se encuentra en esta segunda cultura. </span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip collapse="true"}</span>
<span id="cb9-30"><a href="#cb9-30" aria-hidden="true" tabindex="-1"></a><span class="fu">### Actividad</span></span>
<span id="cb9-31"><a href="#cb9-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-32"><a href="#cb9-32" aria-hidden="true" tabindex="-1"></a>Leer el artículo de @breiman2001statistical para profundizar en las ventajas y desventajas de cada una de las culturas y como estas influyen en la forma de abordar un problema. En este momento no es necesario detenerse en la parte técnica de los algoritmos descritos en el artículo. </span>
<span id="cb9-33"><a href="#cb9-33" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb9-34"><a href="#cb9-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-35"><a href="#cb9-35" aria-hidden="true" tabindex="-1"></a>Existen diferentes tipos de aprendizaje computacional, los mas comunes son: aprendizaje supervisado, aprendizaje no-supervisado y aprendizaje por refuerzo. En **aprendizaje supervisado** se crean modelos partiendo de un conjunto de pares, entrada y salida, donde el objetivo es encontrar un modelo que logra aprender esta relación y predecir ejemplos no vistos en el proceso, en particular a esto se le conoce como _inductive learning_. Complementando este tipo de aprendizaje supervisado se tiene lo que se conoce como _transductive learning_, en el cual se cuenta con un conjunto de pares y solamente se requiere conocer la salida en otro conjunto de datos. En este segundo tipo de aprendizaje todos los datos son conocidos en el proceso de aprendizaje. </span>
<span id="cb9-36"><a href="#cb9-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-37"><a href="#cb9-37" aria-hidden="true" tabindex="-1"></a>**Aprendizaje no-supervisado** es aquel donde se tiene un conjunto de entradas y se busca aprender alguna relación de estas entradas, por ejemplo, generando grupos o utilizando estas entradas para hacer una transformación o encontrar un patrón. </span>
<span id="cb9-38"><a href="#cb9-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-39"><a href="#cb9-39" aria-hidden="true" tabindex="-1"></a>Finalmente **aprendizaje por refuerzo** es aquel donde se tiene un agente que tiene que aprender como interactuar con un ambiente. La interacción es tomando una acción en cada diferente estado del ambiente. Por ejemplo, el agente puede ser un jugador virtual en un juego de ajedrez entonces la acción es identificar y mover una pieza en el tablero, el objetivo de ganar la partida. La característica de aprendizaje por refuerzo es que el agente va a recibir una recompensa al final de la interacción con el ambiente, e.g., final del juego y el objetivo es optimizar las acciones para que la recompensa sea la mayor posible. </span>
<span id="cb9-40"><a href="#cb9-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-41"><a href="#cb9-41" aria-hidden="true" tabindex="-1"></a>El área de aprendizaje computacional ha tenido un crecimiento importante en los últimos años, algunos ejemplos del impacto de área se pueden encontrar en artículos publicados en la revista de la editorial <span class="co">[</span><span class="ot">Nature</span><span class="co">](https://www.nature.com)</span>. Por ejemplo, en el área médica en específico en Cardiología @Hannun2019 propone una metodología para detectar arritmias o en dermatología @Esteva2017 propone un algoritmo para la detección de cancer.</span>
<span id="cb9-42"><a href="#cb9-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-43"><a href="#cb9-43" aria-hidden="true" tabindex="-1"></a>Cabe mencionar que los tres tipos de aprendizaje no son excluyentes uno del otro, comúnmente para resolver un problema complejo se combinan diferentes tipos de aprendizaje y otras tecnologías de IA para encontrar una solución aceptable. Probablemente una de las pruebas más significativas de lo que puede realizarse con aprendizaje automático es lo realizado por AlphaGo descrito por @Silver2016 y en @Silver2017 se quitan una de las restricciones originales, la cual consiste en contar con un conjunto de jugadas realizadas por expertos.</span>
<span id="cb9-44"><a href="#cb9-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-45"><a href="#cb9-45" aria-hidden="true" tabindex="-1"></a>En el área de aprendizaje, hay una tendencia de utilizar plataformas donde diferentes empresas u organismos gubernamentales o sin fines de lucro, ponen un problema e incentivan al publico en general a resolver este problema. La plataforma sirve de mediador en este proceso. Ver por ejemplo <span class="co">[</span><span class="ot">https://www.kaggle.com</span><span class="co">]()</span>.</span>
<span id="cb9-46"><a href="#cb9-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-47"><a href="#cb9-47" aria-hidden="true" tabindex="-1"></a>En el ámbito científico también se han generado este tipo de plataformas aunque su objetivo es ligeramente diferente, lo que se busca es tener una medida objetiva de diferentes soluciones y en algunos casos facilitar la reproducibilidad de las soluciones. Ver por ejemplo <span class="co">[</span><span class="ot">http://codalab.org</span><span class="co">]()</span>.</span>
<span id="cb9-48"><a href="#cb9-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-49"><a href="#cb9-49" aria-hidden="true" tabindex="-1"></a><span class="fu">## Metodología General en Aprendizaje Supervisado y No Supervisado {#sec-metodologia-general }</span></span>
<span id="cb9-50"><a href="#cb9-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-51"><a href="#cb9-51" aria-hidden="true" tabindex="-1"></a>Antes de continuar con la descripción de los diferentes tipos de aprendizaje es importante mencionar la metodología que se sigue en los problemas de aprendizaje supervisado y no supervidado</span>
<span id="cb9-52"><a href="#cb9-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-53"><a href="#cb9-53" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Todo empieza con un conjunto de datos $\mathcal D$ que tiene la información del fenómeno de interés.</span>
<span id="cb9-54"><a href="#cb9-54" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Se selecciona el conjunto de entrenamiento $\mathcal T \subseteq \mathcal D$.</span>
<span id="cb9-55"><a href="#cb9-55" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Se diseña un algoritmo, $f$, utilizando $\mathcal T$.</span>
<span id="cb9-56"><a href="#cb9-56" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>Se utiliza $f$ para estimar las características modeladas.</span>
<span id="cb9-57"><a href="#cb9-57" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>Se mide el rendimiento de $f$.</span>
<span id="cb9-58"><a href="#cb9-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-59"><a href="#cb9-59" aria-hidden="true" tabindex="-1"></a><span class="fu">## Aprendizaje No Supervisado {#sec-aprendizaje-no-supervisado}</span></span>
<span id="cb9-60"><a href="#cb9-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-61"><a href="#cb9-61" aria-hidden="true" tabindex="-1"></a>Iniciamos la descripción de los diferentes tipos de aprendizaje computacional con **aprendizaje no-supervisado**; el cual inicia con un conjunto de elementos. Estos tradicionalmente se puede transformar en conjunto de vectores, i.e. $\mathcal D = <span class="sc">\{</span> x_1, \ldots, x_N <span class="sc">\}</span>$, donde $x_i \in \mathbb R^d$. Durante este curso asumiremos que esta transformación existe y en algunos casos se hará explícito el algoritmo de transformación.</span>
<span id="cb9-62"><a href="#cb9-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-63"><a href="#cb9-63" aria-hidden="true" tabindex="-1"></a>El **objetivo** en aprendizaje no supervisado es desarrollar algoritmos capaces de encontrar patrones en los datos, es decir, en $\mathcal D$. Existen diferentes tareas que se pueden considerar dentro de este tipo de aprendizaje. Por ejemplo, el agrupamiento puede servir para segmentar clientes o productos, en otra línea también cabría el análisis del carrito de compras (Market Basket Analysis); donde el objetivo es encontrar la co-ocurrencias de productos, es decir, se quiere estimar la probabilidad de que habiendo comprado un determinado artículo también se compre otro artículo. Con esta descripción ya se podrá estar imaginando la cantidad de aplicaciones en las que este tipo de algoritmos es utilizado en la actualidad. </span>
<span id="cb9-64"><a href="#cb9-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-65"><a href="#cb9-65" aria-hidden="true" tabindex="-1"></a>Regresando a la representación vectorial, existen casos donde se pueden visualizar los elementos de $\mathcal D$, lo cuales están representados como puntos que se muestran en la @fig-puntos-iris. Claramente esto solo es posible si $x_i \in \mathbb R^2$ o si se hace algún tipo de transformación  $f: \mathbb R^d \rightarrow \mathbb R^2$, como se realizó en la figura.</span>
<span id="cb9-66"><a href="#cb9-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-69"><a href="#cb9-69" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb9-70"><a href="#cb9-70" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-puntos-iris</span></span>
<span id="cb9-71"><a href="#cb9-71" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Proyección de los datos del Iris en dos dimensiones"</span></span>
<span id="cb9-72"><a href="#cb9-72" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb9-73"><a href="#cb9-73" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> decomposition</span>
<span id="cb9-74"><a href="#cb9-74" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_iris</span>
<span id="cb9-75"><a href="#cb9-75" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> pylab <span class="im">as</span> plt</span>
<span id="cb9-76"><a href="#cb9-76" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb9-77"><a href="#cb9-77" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb9-78"><a href="#cb9-78" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb9-79"><a href="#cb9-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-80"><a href="#cb9-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-81"><a href="#cb9-81" aria-hidden="true" tabindex="-1"></a>D, y <span class="op">=</span> load_iris(return_X_y<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb9-82"><a href="#cb9-82" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> decomposition.PCA(n_components<span class="op">=</span><span class="dv">2</span>).fit(D)</span>
<span id="cb9-83"><a href="#cb9-83" aria-hidden="true" tabindex="-1"></a>Dn <span class="op">=</span> pca.transform(D)</span>
<span id="cb9-84"><a href="#cb9-84" aria-hidden="true" tabindex="-1"></a>Dn <span class="op">=</span> np.concatenate((Dn, np.atleast_2d(y).T), axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb9-85"><a href="#cb9-85" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(Dn, columns<span class="op">=</span>[<span class="st">'x'</span>, <span class="st">'y'</span>, <span class="st">'Clase'</span>])</span>
<span id="cb9-86"><a href="#cb9-86" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> sns.relplot(data<span class="op">=</span>df, kind<span class="op">=</span><span class="st">'scatter'</span>,</span>
<span id="cb9-87"><a href="#cb9-87" aria-hidden="true" tabindex="-1"></a>                  x<span class="op">=</span><span class="st">'x'</span>, y<span class="op">=</span><span class="st">'y'</span>)</span>
<span id="cb9-88"><a href="#cb9-88" aria-hidden="true" tabindex="-1"></a>fig.tick_params(bottom<span class="op">=</span><span class="va">False</span>, top<span class="op">=</span><span class="va">False</span>, </span>
<span id="cb9-89"><a href="#cb9-89" aria-hidden="true" tabindex="-1"></a>                left<span class="op">=</span><span class="va">False</span>, right<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb9-90"><a href="#cb9-90" aria-hidden="true" tabindex="-1"></a>                labelbottom<span class="op">=</span><span class="va">False</span>, labelleft<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb9-91"><a href="#cb9-91" aria-hidden="true" tabindex="-1"></a>fig.<span class="bu">set</span>(xlabel<span class="op">=</span><span class="va">None</span>, ylabel<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb9-92"><a href="#cb9-92" aria-hidden="true" tabindex="-1"></a>plt.grid()</span>
<span id="cb9-93"><a href="#cb9-93" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-94"><a href="#cb9-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-95"><a href="#cb9-95" aria-hidden="true" tabindex="-1"></a>En la @fig-puntos-iris se pueden observar dos o tres grupos de puntos, entonces el objetivo sería crear el algoritmo que dado $\mathcal D$ regrese un identificador por cada elemento, dicho identificador representa el grupo al que pertenece el elemento en cuestión. Esta tarea se le conoce como agrupamiento (Clustering). Asumiendo que se aplica un algoritmo de agrupamiento a los datos anteriores; entonces, dado que podemos visualizar los datos, es factible representar el resultado del algoritmo si a cada punto se le asigna un color dependiendo de la clase a la que pertenece. La @fig-kmeans-iris muestra el resultado de este procedimiento. </span>
<span id="cb9-96"><a href="#cb9-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-99"><a href="#cb9-99" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb9-100"><a href="#cb9-100" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-kmeans-iris</span></span>
<span id="cb9-101"><a href="#cb9-101" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Proyección de agrupar los datos del Iris usando K-medias"</span></span>
<span id="cb9-102"><a href="#cb9-102" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb9-103"><a href="#cb9-103" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span>
<span id="cb9-104"><a href="#cb9-104" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> decomposition</span>
<span id="cb9-105"><a href="#cb9-105" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_iris</span>
<span id="cb9-106"><a href="#cb9-106" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> pylab <span class="im">as</span> plt</span>
<span id="cb9-107"><a href="#cb9-107" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb9-108"><a href="#cb9-108" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb9-109"><a href="#cb9-109" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb9-110"><a href="#cb9-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-111"><a href="#cb9-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-112"><a href="#cb9-112" aria-hidden="true" tabindex="-1"></a>D, y <span class="op">=</span> load_iris(return_X_y<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb9-113"><a href="#cb9-113" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">3</span>, n_init<span class="op">=</span><span class="st">'auto'</span>).fit(D)</span>
<span id="cb9-114"><a href="#cb9-114" aria-hidden="true" tabindex="-1"></a>cl <span class="op">=</span> m.predict(D)</span>
<span id="cb9-115"><a href="#cb9-115" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> decomposition.PCA(n_components<span class="op">=</span><span class="dv">2</span>).fit(D)</span>
<span id="cb9-116"><a href="#cb9-116" aria-hidden="true" tabindex="-1"></a>Dn <span class="op">=</span> pca.transform(D)</span>
<span id="cb9-117"><a href="#cb9-117" aria-hidden="true" tabindex="-1"></a>Dn <span class="op">=</span> np.concatenate((Dn, np.atleast_2d(y).T,</span>
<span id="cb9-118"><a href="#cb9-118" aria-hidden="true" tabindex="-1"></a>                     np.atleast_2d(cl).T), axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb9-119"><a href="#cb9-119" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(Dn, columns<span class="op">=</span>[<span class="st">'x'</span>, <span class="st">'y'</span>, <span class="st">'Clase'</span>, <span class="st">'Grupo'</span>])</span>
<span id="cb9-120"><a href="#cb9-120" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> sns.relplot(data<span class="op">=</span>df, kind<span class="op">=</span><span class="st">'scatter'</span>,</span>
<span id="cb9-121"><a href="#cb9-121" aria-hidden="true" tabindex="-1"></a>                  x<span class="op">=</span><span class="st">'x'</span>, y<span class="op">=</span><span class="st">'y'</span>, hue<span class="op">=</span><span class="st">'Grupo'</span>)</span>
<span id="cb9-122"><a href="#cb9-122" aria-hidden="true" tabindex="-1"></a>fig.tick_params(bottom<span class="op">=</span><span class="va">False</span>, top<span class="op">=</span><span class="va">False</span>, </span>
<span id="cb9-123"><a href="#cb9-123" aria-hidden="true" tabindex="-1"></a>                left<span class="op">=</span><span class="va">False</span>, right<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb9-124"><a href="#cb9-124" aria-hidden="true" tabindex="-1"></a>                labelbottom<span class="op">=</span><span class="va">False</span>, labelleft<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb9-125"><a href="#cb9-125" aria-hidden="true" tabindex="-1"></a>fig.<span class="bu">set</span>(xlabel<span class="op">=</span><span class="va">None</span>, ylabel<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb9-126"><a href="#cb9-126" aria-hidden="true" tabindex="-1"></a>plt.grid()</span>
<span id="cb9-127"><a href="#cb9-127" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-128"><a href="#cb9-128" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-129"><a href="#cb9-129" aria-hidden="true" tabindex="-1"></a>Se puede observar en la figura anterior, el algoritmo de agrupamiento separa los puntos en tres grupos, representados por los colores diferentes colores. Cabe mencionar que utilizando algún otro criterio de optimización se hubiera podido encontrar dos grupos, el primero de ellos sería el grupo de los puntos que se encuentran a la izquierda de la figura y el segundo sería el grupo formado por los grupos que se encuentran en el centro y a la derecha de la figura. Es importante recalcar que no es necesario visualizar los datos para aplicar un algoritmo de agrupamiento. En particular el ejercicio de visualización de datos y del resultado de agrupamiento que se muestra en la figuras anteriores tiene el objetivo de generar una intuición de lo que está haciendo un algoritmo de agrupamiento. </span>
<span id="cb9-130"><a href="#cb9-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-131"><a href="#cb9-131" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip collapse="true"}</span>
<span id="cb9-132"><a href="#cb9-132" aria-hidden="true" tabindex="-1"></a><span class="fu">### Actividad</span></span>
<span id="cb9-133"><a href="#cb9-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-134"><a href="#cb9-134" aria-hidden="true" tabindex="-1"></a>Generar la figura anterior para el conjunto de datos de Breast Cancer Wisconsin (@sec-breast-cancer-wisconsin). Es necesario considerar que ese problema solamente tiene dos clases y el problema del Iris (@sec-iris) tiene tres clases, entonces se tienen que hacer las modificaciones para atender este cambio. </span>
<span id="cb9-135"><a href="#cb9-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-136"><a href="#cb9-136" aria-hidden="true" tabindex="-1"></a>El procedimiento desarrollado debe de generar una figura similar a la mostrada en la @fig-kmeans-breast-cancer</span>
<span id="cb9-137"><a href="#cb9-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-140"><a href="#cb9-140" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb9-141"><a href="#cb9-141" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-kmeans-breast-cancer</span></span>
<span id="cb9-142"><a href="#cb9-142" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Proyección de agrupar los datos de Breast Cancer Wisconsin usando K-medias"</span></span>
<span id="cb9-143"><a href="#cb9-143" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb9-144"><a href="#cb9-144" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_breast_cancer</span>
<span id="cb9-145"><a href="#cb9-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-146"><a href="#cb9-146" aria-hidden="true" tabindex="-1"></a>D, y <span class="op">=</span> load_breast_cancer(return_X_y<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb9-147"><a href="#cb9-147" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">2</span>, n_init<span class="op">=</span><span class="st">'auto'</span>).fit(D)</span>
<span id="cb9-148"><a href="#cb9-148" aria-hidden="true" tabindex="-1"></a>cl <span class="op">=</span> m.predict(D)</span>
<span id="cb9-149"><a href="#cb9-149" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> decomposition.PCA(n_components<span class="op">=</span><span class="dv">2</span>).fit(D)</span>
<span id="cb9-150"><a href="#cb9-150" aria-hidden="true" tabindex="-1"></a>Dn <span class="op">=</span> pca.transform(D)</span>
<span id="cb9-151"><a href="#cb9-151" aria-hidden="true" tabindex="-1"></a>Dn <span class="op">=</span> np.concatenate((Dn, np.atleast_2d(y).T,</span>
<span id="cb9-152"><a href="#cb9-152" aria-hidden="true" tabindex="-1"></a>                     np.atleast_2d(cl).T), axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb9-153"><a href="#cb9-153" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(Dn, columns<span class="op">=</span>[<span class="st">'x'</span>, <span class="st">'y'</span>, <span class="st">'Clase'</span>, <span class="st">'Grupo'</span>])</span>
<span id="cb9-154"><a href="#cb9-154" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> sns.relplot(data<span class="op">=</span>df, kind<span class="op">=</span><span class="st">'scatter'</span>,</span>
<span id="cb9-155"><a href="#cb9-155" aria-hidden="true" tabindex="-1"></a>                  x<span class="op">=</span><span class="st">'x'</span>, y<span class="op">=</span><span class="st">'y'</span>, hue<span class="op">=</span><span class="st">'Grupo'</span>)</span>
<span id="cb9-156"><a href="#cb9-156" aria-hidden="true" tabindex="-1"></a>fig.tick_params(bottom<span class="op">=</span><span class="va">False</span>, top<span class="op">=</span><span class="va">False</span>, </span>
<span id="cb9-157"><a href="#cb9-157" aria-hidden="true" tabindex="-1"></a>                left<span class="op">=</span><span class="va">False</span>, right<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb9-158"><a href="#cb9-158" aria-hidden="true" tabindex="-1"></a>                labelbottom<span class="op">=</span><span class="va">False</span>, labelleft<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb9-159"><a href="#cb9-159" aria-hidden="true" tabindex="-1"></a>fig.<span class="bu">set</span>(xlabel<span class="op">=</span><span class="va">None</span>, ylabel<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb9-160"><a href="#cb9-160" aria-hidden="true" tabindex="-1"></a>plt.grid()</span>
<span id="cb9-161"><a href="#cb9-161" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-162"><a href="#cb9-162" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb9-163"><a href="#cb9-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-164"><a href="#cb9-164" aria-hidden="true" tabindex="-1"></a><span class="fu">## Aprendizaje Supervisado {#sec-aprendizaje-supervisado}</span></span>
<span id="cb9-165"><a href="#cb9-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-166"><a href="#cb9-166" aria-hidden="true" tabindex="-1"></a>Aprendizaje supervisado inicia con un conjunto de pares, entrada y salida; la @fig-datos-aprendizaje-supervisado ilustra el mecanismo que genera estos pares, del lado izquierdo se tiene las variables medibles que entran al proceso o fenómeno que se desconoce y del lado derecho se mide la(s) variable(s) respuesta, es decir, la(s) salida(s) del sistema. En otras palabras se tiene $\mathcal D = <span class="sc">\{</span> (x_1, y_1), \ldots, (x_N, y_N )<span class="sc">\}</span>$, donde $x_i \in \mathbb R^d$ corresponde a la  $i$-ésima entrada y $y_i$ es la salida asociada a esa entrada. </span>
<span id="cb9-167"><a href="#cb9-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-170"><a href="#cb9-170" aria-hidden="true" tabindex="-1"></a><span class="in">```{mermaid}</span></span>
<span id="cb9-171"><a href="#cb9-171" aria-hidden="true" tabindex="-1"></a><span class="in">%%| echo: false</span></span>
<span id="cb9-172"><a href="#cb9-172" aria-hidden="true" tabindex="-1"></a><span class="in">%%| fig-cap: Datos de Aprendizaje Supervisado</span></span>
<span id="cb9-173"><a href="#cb9-173" aria-hidden="true" tabindex="-1"></a><span class="in">%%| label: fig-datos-aprendizaje-supervisado</span></span>
<span id="cb9-174"><a href="#cb9-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-175"><a href="#cb9-175" aria-hidden="true" tabindex="-1"></a><span class="in">flowchart LR</span></span>
<span id="cb9-176"><a href="#cb9-176" aria-hidden="true" tabindex="-1"></a><span class="in">    Entrada([Entradas]) --&gt;  Proceso[Proceso / Fenómeno]</span></span>
<span id="cb9-177"><a href="#cb9-177" aria-hidden="true" tabindex="-1"></a><span class="in">    Proceso --&gt; Salidas([Salidas])</span></span>
<span id="cb9-178"><a href="#cb9-178" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-179"><a href="#cb9-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-180"><a href="#cb9-180" aria-hidden="true" tabindex="-1"></a>Considerando que se desconoce el modelo del proceso o fenómeno que generó la respuesta y además que pueden existir variables de entrada que no son medibles, se puede definir el **objetivo** de aprendizaje supervisado como encontrar un algoritmo o función, $f$, capaz de regresar la salida, $y$, dada una entrada $x$.</span>
<span id="cb9-181"><a href="#cb9-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-182"><a href="#cb9-182" aria-hidden="true" tabindex="-1"></a>Los posibles fines de desarrollar la función $f$ es por un lado **predecir** la salida dada una nueva entrada $x$ y por el otro lado **extraer conocimiento** del proceso que asocia la respuesta de las variables de entrada (ver @breiman2001statistical). Estos dos metas se pueden contraponer, es decir, extraer conocimiento implica una reducción en la calidad de la predicción y viceversa mejorar la calidad de predicción en general trae consigo una menor capacidad para entender el fenómeno generador de datos.  </span>
<span id="cb9-183"><a href="#cb9-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-184"><a href="#cb9-184" aria-hidden="true" tabindex="-1"></a>Existe una gran variedad de problemas que se puede categorizar como tareas de aprendizaje supervisado, solamente hay que recordar que en todos los casos se inicia con un conjunto $\mathcal D$ de pares entrada y salida. En ocasiones la construcción del conjunto es directa, por ejemplo en el caso de que se quiera identificar si una persona será sujeta a un crédito, entonces el conjunto a crear esta compuesto por las características de las personas que se les ha otorgado un crédito y el estado final de crédito, es decir, si el crédito fue pagado o no fue pagado. En otro ejemplo, suponiendo que se quiere crear un algoritmo capaz de identificar si un texto dado tiene una polaridad positiva o negativa, entonces el conjunto se crea recolectando textos y a cada texto un conjunto de personas decide si el texto dado es positivo o negativo y la polaridad final es el consenso de varias opiniones; a este problema en general se le conoce como análisis de sentimientos.</span>
<span id="cb9-185"><a href="#cb9-185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-186"><a href="#cb9-186" aria-hidden="true" tabindex="-1"></a>La cantidad de problema que se pueden poner en términos de aprendizaje supervisado es amplia, un problema tangible en esta época y relacionado a la pandemia del COVID-19 sería el crear un algoritmo que pudiera predecir cuántos serán los casos positivos el día de mañana dando como entradas las restricciones en las actividades; por ejemplo escuelas cerradas, restaurantes al 30% de capacidad entre otras. </span>
<span id="cb9-187"><a href="#cb9-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-188"><a href="#cb9-188" aria-hidden="true" tabindex="-1"></a>Los ejemplos anteriores corresponden a dos de las clases de problemas que se resuelven en aprendizaje supervisado estas son problemas de clasificación y regresión. Definamos de manera formal estos dos problemas. Cuando  $y \in <span class="sc">\{</span>0, 1<span class="sc">\}</span>$ se dice que es un problema de **clasificación binaria**, por otro lado cuando  $y \in \{0, 1\}^K$ se encuentra uno en clasificación **multi-clase** o **multi-etiqueta** y finalmente si  $y \in \mathbb R$ entonces es un problema de **regresión**.</span>
<span id="cb9-189"><a href="#cb9-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-190"><a href="#cb9-190" aria-hidden="true" tabindex="-1"></a>Haciendo la liga entre los ejemplos y las definiciones anteriores, podemos observar que el asignar un crédito o la polaridad a un texto es un problema de clasificación binaria, dado que se puede asociar 0 y 1 a la clase positivo y negativo; y en el otro caso a pagar o no pagar el crédito. Si el problema tiene mas categorías, supongamos que se desea identificar positivo, negativo o neutro, entonces se estaría en el problema de clasificación multi-clase. Por otro lado el problema de predecir el número de casos positivos se puede considerar como un problema de regresión, dado que el valor a predecir difícilmente se podría considerar como una categoría.</span>
<span id="cb9-191"><a href="#cb9-191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-192"><a href="#cb9-192" aria-hidden="true" tabindex="-1"></a>Al igual que en aprendizaje no supervisado, en algunos casos es posible visualizar los elementos de  $\mathcal D$, el detalle adicional es que cada objeto tiene asociado una clase, entonces se selecciona un color para representar cada clase. En la @fig-iris-2clases se muestra el resultado donde los elementos de  $\mathcal D$ se encuentra en $\mathbb R^2$ y el color representa cada una de la clases de este problema de clasificación binaria.</span>
<span id="cb9-193"><a href="#cb9-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-196"><a href="#cb9-196" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb9-197"><a href="#cb9-197" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-iris-2clases</span></span>
<span id="cb9-198"><a href="#cb9-198" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Proyección del Iris mostrando dos clases linealmente separables"</span></span>
<span id="cb9-199"><a href="#cb9-199" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb9-200"><a href="#cb9-200" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span>
<span id="cb9-201"><a href="#cb9-201" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> decomposition</span>
<span id="cb9-202"><a href="#cb9-202" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_iris</span>
<span id="cb9-203"><a href="#cb9-203" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> pylab <span class="im">as</span> plt</span>
<span id="cb9-204"><a href="#cb9-204" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb9-205"><a href="#cb9-205" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb9-206"><a href="#cb9-206" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb9-207"><a href="#cb9-207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-208"><a href="#cb9-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-209"><a href="#cb9-209" aria-hidden="true" tabindex="-1"></a>D, y <span class="op">=</span> load_iris(return_X_y<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb9-210"><a href="#cb9-210" aria-hidden="true" tabindex="-1"></a>mask <span class="op">=</span> y <span class="op">&lt;=</span> <span class="dv">1</span></span>
<span id="cb9-211"><a href="#cb9-211" aria-hidden="true" tabindex="-1"></a>D <span class="op">=</span> D[mask]</span>
<span id="cb9-212"><a href="#cb9-212" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> y[mask]</span>
<span id="cb9-213"><a href="#cb9-213" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> decomposition.PCA(n_components<span class="op">=</span><span class="dv">2</span>).fit(D)</span>
<span id="cb9-214"><a href="#cb9-214" aria-hidden="true" tabindex="-1"></a>Dn <span class="op">=</span> pca.transform(D)</span>
<span id="cb9-215"><a href="#cb9-215" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(Dn, columns<span class="op">=</span>[<span class="st">'x'</span>, <span class="st">'y'</span>])</span>
<span id="cb9-216"><a href="#cb9-216" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'Clase'</span>] <span class="op">=</span> [<span class="st">'P'</span> <span class="cf">if</span> i <span class="cf">else</span> <span class="st">'N'</span> <span class="cf">for</span> i <span class="kw">in</span> y]</span>
<span id="cb9-217"><a href="#cb9-217" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> sns.relplot(data<span class="op">=</span>df, kind<span class="op">=</span><span class="st">'scatter'</span>,</span>
<span id="cb9-218"><a href="#cb9-218" aria-hidden="true" tabindex="-1"></a>                  x<span class="op">=</span><span class="st">'x'</span>, y<span class="op">=</span><span class="st">'y'</span>, hue<span class="op">=</span><span class="st">'Clase'</span>)</span>
<span id="cb9-219"><a href="#cb9-219" aria-hidden="true" tabindex="-1"></a>fig.tick_params(bottom<span class="op">=</span><span class="va">False</span>, top<span class="op">=</span><span class="va">False</span>, </span>
<span id="cb9-220"><a href="#cb9-220" aria-hidden="true" tabindex="-1"></a>                left<span class="op">=</span><span class="va">False</span>, right<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb9-221"><a href="#cb9-221" aria-hidden="true" tabindex="-1"></a>                labelbottom<span class="op">=</span><span class="va">False</span>, labelleft<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb9-222"><a href="#cb9-222" aria-hidden="true" tabindex="-1"></a>fig.<span class="bu">set</span>(xlabel<span class="op">=</span><span class="va">None</span>, ylabel<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb9-223"><a href="#cb9-223" aria-hidden="true" tabindex="-1"></a>plt.grid()</span>
<span id="cb9-224"><a href="#cb9-224" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-225"><a href="#cb9-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-226"><a href="#cb9-226" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip collapse="true"}</span>
<span id="cb9-227"><a href="#cb9-227" aria-hidden="true" tabindex="-1"></a><span class="fu">### Actividad</span></span>
<span id="cb9-228"><a href="#cb9-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-229"><a href="#cb9-229" aria-hidden="true" tabindex="-1"></a>Generar la figura anterior para el conjunto de datos de Breast Cancer Wisconsin (@sec-breast-cancer-wisconsin). Como se mencionó, el problema tiene dos clases entonces no se necesita ningún tipo de transformación en el número de clases como se hizo en el ejemplo anterior. La @fig-breast-cancer muestra el resultado de la actividad. </span>
<span id="cb9-230"><a href="#cb9-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-233"><a href="#cb9-233" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb9-234"><a href="#cb9-234" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-breast-cancer</span></span>
<span id="cb9-235"><a href="#cb9-235" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Proyección de los datos de Breast Cancer Wisconsin."</span></span>
<span id="cb9-236"><a href="#cb9-236" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb9-237"><a href="#cb9-237" aria-hidden="true" tabindex="-1"></a>D, cl <span class="op">=</span> load_breast_cancer(return_X_y<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb9-238"><a href="#cb9-238" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> decomposition.PCA(n_components<span class="op">=</span><span class="dv">2</span>).fit(D)</span>
<span id="cb9-239"><a href="#cb9-239" aria-hidden="true" tabindex="-1"></a>Dn <span class="op">=</span> pca.transform(D)</span>
<span id="cb9-240"><a href="#cb9-240" aria-hidden="true" tabindex="-1"></a>Dn <span class="op">=</span> np.concatenate((Dn, np.atleast_2d(cl).T), axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb9-241"><a href="#cb9-241" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(Dn, columns<span class="op">=</span>[<span class="st">'x'</span>, <span class="st">'y'</span>, <span class="st">'Clase'</span>])</span>
<span id="cb9-242"><a href="#cb9-242" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> sns.relplot(data<span class="op">=</span>df, kind<span class="op">=</span><span class="st">'scatter'</span>,</span>
<span id="cb9-243"><a href="#cb9-243" aria-hidden="true" tabindex="-1"></a>                  x<span class="op">=</span><span class="st">'x'</span>, y<span class="op">=</span><span class="st">'y'</span>, hue<span class="op">=</span><span class="st">'Clase'</span>)</span>
<span id="cb9-244"><a href="#cb9-244" aria-hidden="true" tabindex="-1"></a>fig.tick_params(bottom<span class="op">=</span><span class="va">False</span>, top<span class="op">=</span><span class="va">False</span>, </span>
<span id="cb9-245"><a href="#cb9-245" aria-hidden="true" tabindex="-1"></a>                left<span class="op">=</span><span class="va">False</span>, right<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb9-246"><a href="#cb9-246" aria-hidden="true" tabindex="-1"></a>                labelbottom<span class="op">=</span><span class="va">False</span>, labelleft<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb9-247"><a href="#cb9-247" aria-hidden="true" tabindex="-1"></a>fig.<span class="bu">set</span>(xlabel<span class="op">=</span><span class="va">None</span>, ylabel<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb9-248"><a href="#cb9-248" aria-hidden="true" tabindex="-1"></a>plt.grid()</span>
<span id="cb9-249"><a href="#cb9-249" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-250"><a href="#cb9-250" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb9-251"><a href="#cb9-251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-252"><a href="#cb9-252" aria-hidden="true" tabindex="-1"></a>Usando esta representación es sencillo imaginar que el problema de clasificación se trata en encontrar una función que separe los puntos naranjas de los puntos azules, como se pueden imagina una simple línea recta podría separar estos puntos. La @fig-iris-2clases-df muestra un ejemplo de lo que haría un clasificador representado por la línea; la clase es dada por el signo de  $ax + by + c$, donde  $a$, $b$ y $c$ son parámetros identificados a partir de  $\mathcal D$.</span>
<span id="cb9-253"><a href="#cb9-253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-256"><a href="#cb9-256" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb9-257"><a href="#cb9-257" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-iris-2clases-df</span></span>
<span id="cb9-258"><a href="#cb9-258" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Proyección del Iris mostrando dos clases linealmente separables"</span></span>
<span id="cb9-259"><a href="#cb9-259" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb9-260"><a href="#cb9-260" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span>
<span id="cb9-261"><a href="#cb9-261" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> LinearSVC</span>
<span id="cb9-262"><a href="#cb9-262" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> decomposition</span>
<span id="cb9-263"><a href="#cb9-263" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_iris</span>
<span id="cb9-264"><a href="#cb9-264" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> pylab <span class="im">as</span> plt</span>
<span id="cb9-265"><a href="#cb9-265" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb9-266"><a href="#cb9-266" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb9-267"><a href="#cb9-267" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb9-268"><a href="#cb9-268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-269"><a href="#cb9-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-270"><a href="#cb9-270" aria-hidden="true" tabindex="-1"></a>D, y <span class="op">=</span> load_iris(return_X_y<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb9-271"><a href="#cb9-271" aria-hidden="true" tabindex="-1"></a>mask <span class="op">=</span> y <span class="op">&lt;=</span> <span class="dv">1</span></span>
<span id="cb9-272"><a href="#cb9-272" aria-hidden="true" tabindex="-1"></a>D <span class="op">=</span> D[mask]</span>
<span id="cb9-273"><a href="#cb9-273" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> y[mask]</span>
<span id="cb9-274"><a href="#cb9-274" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> decomposition.PCA(n_components<span class="op">=</span><span class="dv">2</span>).fit(D)</span>
<span id="cb9-275"><a href="#cb9-275" aria-hidden="true" tabindex="-1"></a>Dn <span class="op">=</span> pca.transform(D)</span>
<span id="cb9-276"><a href="#cb9-276" aria-hidden="true" tabindex="-1"></a>linear <span class="op">=</span> LinearSVC(dual<span class="op">=</span><span class="va">False</span>).fit(Dn, y)</span>
<span id="cb9-277"><a href="#cb9-277" aria-hidden="true" tabindex="-1"></a>w_1, w_2 <span class="op">=</span> linear.coef_[<span class="dv">0</span>]</span>
<span id="cb9-278"><a href="#cb9-278" aria-hidden="true" tabindex="-1"></a>w_0 <span class="op">=</span> linear.intercept_[<span class="dv">0</span>]</span>
<span id="cb9-279"><a href="#cb9-279" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(Dn, columns<span class="op">=</span>[<span class="st">'x1'</span>, <span class="st">'x2'</span>])</span>
<span id="cb9-280"><a href="#cb9-280" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'Clase'</span>] <span class="op">=</span> [<span class="st">'N'</span> <span class="cf">if</span> i <span class="cf">else</span> <span class="st">'P'</span> <span class="cf">for</span> i <span class="kw">in</span> y]</span>
<span id="cb9-281"><a href="#cb9-281" aria-hidden="true" tabindex="-1"></a>g_0 <span class="op">=</span> [<span class="bu">dict</span>(x1<span class="op">=</span>x, x2<span class="op">=</span>y, tipo<span class="op">=</span><span class="st">'g(x)=0'</span>)</span>
<span id="cb9-282"><a href="#cb9-282" aria-hidden="true" tabindex="-1"></a>       <span class="cf">for</span> x, y <span class="kw">in</span> <span class="bu">zip</span>(Dn[:, <span class="dv">0</span>], (<span class="op">-</span>w_0 <span class="op">-</span> w_1 <span class="op">*</span> Dn[:, <span class="dv">0</span>]) <span class="op">/</span> w_2)]</span>
<span id="cb9-283"><a href="#cb9-283" aria-hidden="true" tabindex="-1"></a>g <span class="op">=</span> pd.DataFrame(g_0)</span>
<span id="cb9-284"><a href="#cb9-284" aria-hidden="true" tabindex="-1"></a>g[<span class="st">'Tipo'</span>] <span class="op">=</span> <span class="st">'g(x)=0'</span></span>
<span id="cb9-285"><a href="#cb9-285" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.concat((df, g))</span>
<span id="cb9-286"><a href="#cb9-286" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> sns.scatterplot(data<span class="op">=</span>df, x<span class="op">=</span><span class="st">'x1'</span>, y<span class="op">=</span><span class="st">'x2'</span>, hue<span class="op">=</span><span class="st">'Clase'</span>, legend<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb9-287"><a href="#cb9-287" aria-hidden="true" tabindex="-1"></a>sns.lineplot(data<span class="op">=</span>df, x<span class="op">=</span><span class="st">'x1'</span>, y<span class="op">=</span><span class="st">'x2'</span>, ax<span class="op">=</span>ax, hue<span class="op">=</span><span class="st">'Tipo'</span>, palette<span class="op">=</span>[<span class="st">'k'</span>], legend<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb9-288"><a href="#cb9-288" aria-hidden="true" tabindex="-1"></a>ax.tick_params(axis<span class="op">=</span><span class="st">"both"</span>, which<span class="op">=</span><span class="st">"both"</span>, bottom<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb9-289"><a href="#cb9-289" aria-hidden="true" tabindex="-1"></a>                top<span class="op">=</span><span class="va">False</span>, left<span class="op">=</span><span class="va">False</span>, right<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb9-290"><a href="#cb9-290" aria-hidden="true" tabindex="-1"></a>                labelbottom<span class="op">=</span><span class="va">False</span>, labelleft<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb9-291"><a href="#cb9-291" aria-hidden="true" tabindex="-1"></a>ax.<span class="bu">set</span>(xlabel<span class="op">=</span><span class="va">None</span>, ylabel<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb9-292"><a href="#cb9-292" aria-hidden="true" tabindex="-1"></a>plt.grid()</span>
<span id="cb9-293"><a href="#cb9-293" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-294"><a href="#cb9-294" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-295"><a href="#cb9-295" aria-hidden="true" tabindex="-1"></a>Siguiendo en esta misma línea, también es posible observar los puntos en un problema de regresión, solamente que en este caso un eje corresponde a las entradas, i.e.  $x$, y el otro eje es la salida, i.e. $y$. La @fig-regresion muestra un ejemplo de regresión, donde se puede observar que la idea es una encontrar una función que pueda seguir de manera adecuada los puntos datos.</span>
<span id="cb9-296"><a href="#cb9-296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-299"><a href="#cb9-299" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb9-300"><a href="#cb9-300" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-regresion</span></span>
<span id="cb9-301"><a href="#cb9-301" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Problema de regresión"</span></span>
<span id="cb9-302"><a href="#cb9-302" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb9-303"><a href="#cb9-303" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> pylab <span class="im">as</span> plt</span>
<span id="cb9-304"><a href="#cb9-304" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb9-305"><a href="#cb9-305" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb9-306"><a href="#cb9-306" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb9-307"><a href="#cb9-307" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-308"><a href="#cb9-308" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">100</span>)</span>
<span id="cb9-309"><a href="#cb9-309" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> <span class="fl">12.3</span> <span class="op">*</span> x<span class="op">**</span><span class="dv">2</span> <span class="op">-</span> <span class="fl">3.2</span> <span class="op">*</span> x <span class="op">+</span> <span class="fl">1.2</span></span>
<span id="cb9-310"><a href="#cb9-310" aria-hidden="true" tabindex="-1"></a>ym <span class="op">=</span> np.random.normal(loc<span class="op">=</span><span class="dv">0</span>, scale<span class="op">=</span><span class="fl">0.2</span>, size<span class="op">=</span>x.shape[<span class="dv">0</span>]) <span class="op">+</span> y</span>
<span id="cb9-311"><a href="#cb9-311" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(<span class="bu">dict</span>(x<span class="op">=</span>x, y<span class="op">=</span>y, ym<span class="op">=</span>ym))</span>
<span id="cb9-312"><a href="#cb9-312" aria-hidden="true" tabindex="-1"></a><span class="co">#&nbsp;sns.lineplot(data=df, x='x', y='y', legend=False, color='k')</span></span>
<span id="cb9-313"><a href="#cb9-313" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> sns.scatterplot(data<span class="op">=</span>df, x<span class="op">=</span><span class="st">'x'</span>, y<span class="op">=</span><span class="st">'ym'</span>, legend<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb9-314"><a href="#cb9-314" aria-hidden="true" tabindex="-1"></a>fig.tick_params(bottom<span class="op">=</span><span class="va">False</span>, top<span class="op">=</span><span class="va">False</span>, </span>
<span id="cb9-315"><a href="#cb9-315" aria-hidden="true" tabindex="-1"></a>                left<span class="op">=</span><span class="va">False</span>, right<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb9-316"><a href="#cb9-316" aria-hidden="true" tabindex="-1"></a>                labelbottom<span class="op">=</span><span class="va">False</span>, labelleft<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb9-317"><a href="#cb9-317" aria-hidden="true" tabindex="-1"></a>fig.<span class="bu">set</span>(xlabel<span class="op">=</span><span class="st">'x'</span>, ylabel<span class="op">=</span><span class="st">'y'</span>)</span>
<span id="cb9-318"><a href="#cb9-318" aria-hidden="true" tabindex="-1"></a>plt.grid()</span>
<span id="cb9-319"><a href="#cb9-319" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-320"><a href="#cb9-320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-321"><a href="#cb9-321" aria-hidden="true" tabindex="-1"></a>El problema de regresión es muy conocido y seguramente ya se imaginaron que la respuesta sería encontrar los parámetros de una parábola. La @fig-regresion-2 muestra una visualización del regresor, mostrado en color negro y los datos de entrenamiento en color azul.</span>
<span id="cb9-322"><a href="#cb9-322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-325"><a href="#cb9-325" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb9-326"><a href="#cb9-326" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-regresion-2</span></span>
<span id="cb9-327"><a href="#cb9-327" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Problema de regresión con función con función estimada"</span></span>
<span id="cb9-328"><a href="#cb9-328" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb9-329"><a href="#cb9-329" aria-hidden="true" tabindex="-1"></a>sns.lineplot(data<span class="op">=</span>df, x<span class="op">=</span><span class="st">'x'</span>, y<span class="op">=</span><span class="st">'y'</span>, legend<span class="op">=</span><span class="va">False</span>, color<span class="op">=</span><span class="st">'k'</span>)</span>
<span id="cb9-330"><a href="#cb9-330" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> sns.scatterplot(data<span class="op">=</span>df, x<span class="op">=</span><span class="st">'x'</span>, y<span class="op">=</span><span class="st">'ym'</span>, legend<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb9-331"><a href="#cb9-331" aria-hidden="true" tabindex="-1"></a>fig.tick_params(axis<span class="op">=</span><span class="st">"both"</span>, which<span class="op">=</span><span class="st">"both"</span>, bottom<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb9-332"><a href="#cb9-332" aria-hidden="true" tabindex="-1"></a>                top<span class="op">=</span><span class="va">False</span>, left<span class="op">=</span><span class="va">False</span>, right<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb9-333"><a href="#cb9-333" aria-hidden="true" tabindex="-1"></a>                labelbottom<span class="op">=</span><span class="va">False</span>, labelleft<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb9-334"><a href="#cb9-334" aria-hidden="true" tabindex="-1"></a>fig.<span class="bu">set</span>(xlabel<span class="op">=</span><span class="st">'x'</span>, ylabel<span class="op">=</span><span class="st">'y'</span>)</span>
<span id="cb9-335"><a href="#cb9-335" aria-hidden="true" tabindex="-1"></a>plt.grid()</span>
<span id="cb9-336"><a href="#cb9-336" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-337"><a href="#cb9-337" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-338"><a href="#cb9-338" aria-hidden="true" tabindex="-1"></a>Al igual que en aprendizaje no supervisado, este ejercicio de visualización no es posible en todos los problemas de aprendizaje supervisado, pero si permite ganar intuición sobre la forma en que trabajan estos algoritmos.</span>
<span id="cb9-339"><a href="#cb9-339" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-340"><a href="#cb9-340" aria-hidden="true" tabindex="-1"></a><span class="fu">## Definiciones de Aprendizaje Supervisado {#sec-definiciones-aprendizaje-supervisado}</span></span>
<span id="cb9-341"><a href="#cb9-341" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-342"><a href="#cb9-342" aria-hidden="true" tabindex="-1"></a>El primer paso es empezar a definir los diferentes conjuntos con los que se trabaja en aprendizeje computacional. Todo inicia con el **conjunto de entrenamiento** identificado en este documento como $\mathcal T$. Este conjunto se utiliza para estimar los parámetros o en general buscar un algoritmo que tenga el comportamiento esperado.</span>
<span id="cb9-343"><a href="#cb9-343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-344"><a href="#cb9-344" aria-hidden="true" tabindex="-1"></a>Se puede asumir que existe una función $f$ que genera la relación entrada salida mostrada en $\mathcal T$, es decir, idealmente se tiene que $\forall_{(x, y) \in \mathcal D} f(x) = y$. En este contexto, aprendizaje supervisado se entiende como el proceso de encontrar una función $h^*$ que se comporta similar a $f$.</span>
<span id="cb9-345"><a href="#cb9-345" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-346"><a href="#cb9-346" aria-hidden="true" tabindex="-1"></a>Para encontrar $h^*$, se utiliza $\mathcal T$; el conjunto de hipótesis (funciones), $\mathcal H$, que se considera puede aproximar $f$; una función de error, $L$; y el error empírico $E(h \mid \mathcal T) = \sum_{(x, y) \in \mathcal T} L(y, h(x))$. Utilizando estos elementos la función buscada es: $h^* = \textsf{argmin}_{h \in \mathcal{H}} E(h \mid \mathcal T)$.</span>
<span id="cb9-347"><a href="#cb9-347" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-348"><a href="#cb9-348" aria-hidden="true" tabindex="-1"></a>El encontrar la función $h^*$ no resuelve el problema de aprendizaje en su totalidad, además se busca una función que sea capaz de generalizar, es decir, que pueda predecir correctamente instancias no vistas. Considerando que se tiene un **conjunto de prueba**, $\mathcal G=\{(x_i, y_i)\}$ para $i=1 \ldots M$, donde $\mathcal T \cap \mathcal G = \emptyset$ y $\mathcal T \cup \mathcal G = \mathcal D.$ La idea es que el error empírico sea similar en el conjunto de entrenamiento y prueba. Es decir $E(h^* \mid \mathcal T) \approx E(h^* \mid \mathcal G)$.</span>
<span id="cb9-349"><a href="#cb9-349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-350"><a href="#cb9-350" aria-hidden="true" tabindex="-1"></a><span class="fu">### Estilos de Aprendizaje</span></span>
<span id="cb9-351"><a href="#cb9-351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-352"><a href="#cb9-352" aria-hidden="true" tabindex="-1"></a>Utilizando $\mathcal T$ y $\mathcal G$ podemos definir **inductive learning** como el proceso de aprendizaje en donde solamente se utiliza $\mathcal T$ y el algoritmo debe de ser capaz de predecir cualquier instancia. Por otro lado, **transductive learning** es el proceso de aprendizaje donde se utilizar $\mathcal T \cup <span class="sc">\{</span> x \mid (x, y) \in \mathcal G <span class="sc">\}</span>$ para aprender y solamente es de interés el conocer la clase o variable dependiente del conjunto $\mathcal G$.</span>
<span id="cb9-353"><a href="#cb9-353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-354"><a href="#cb9-354" aria-hidden="true" tabindex="-1"></a><span class="fu">### Sobre-aprendizaje</span></span>
<span id="cb9-355"><a href="#cb9-355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-356"><a href="#cb9-356" aria-hidden="true" tabindex="-1"></a>Existen clases de algoritmos, $\mathcal H$, que tienen un mayor grado de libertad el cual se ve reflejado en una capacidad superior para aprender, pero por otro lado, existen problemas donde no se requiere tanta libertad, esta combinación se traduce en que el algoritmo no es capaz de generalizar y cuantitativamente se ve como $E(h^* \mid \mathcal T) \ll E(h^* \mid \mathcal G)$.</span>
<span id="cb9-357"><a href="#cb9-357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-358"><a href="#cb9-358" aria-hidden="true" tabindex="-1"></a>Para mostrar este caso hay que imaginar que se tiene un algoritmo que guarda el conjunto de entrenamiento y responde lo siguiente:</span>
<span id="cb9-359"><a href="#cb9-359" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-360"><a href="#cb9-360" aria-hidden="true" tabindex="-1"></a>$$h^*(x) = \begin{cases} y &amp; \text{si} (x, y) \in \mathcal T<span class="sc">\\</span> 0 &amp; \end{cases}$$</span>
<span id="cb9-361"><a href="#cb9-361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-362"><a href="#cb9-362" aria-hidden="true" tabindex="-1"></a>Es fácil observar que este algoritmo tiene $E(h^* \mid \mathcal T) = 0$ dado que se aprende todo el conjunto de entrenamiento.</span>
<span id="cb9-363"><a href="#cb9-363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-364"><a href="#cb9-364" aria-hidden="true" tabindex="-1"></a>La @fig-sobre-aprendizaje muestra el comportamiento de un algoritmo que sobre-aprende, el algoritmo se muestra en la línea naranja, la línea azul corresponde a una parábola (cuyos parámetros son identificados con los datos de entrenamiento) y los datos de entrenamiento no se muestran; pero se pueden visualizar dado que son datos generados por una parábola mas un error gaussiano. Entonces podemos ver que la línea naranja pasa de manera exacta por todos los datos de entrenamiento y da como resultado la línea naranja que claramente tiene un comportamiento mas complejo que el comportamiento de la parábola que generó los datos.</span>
<span id="cb9-365"><a href="#cb9-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-368"><a href="#cb9-368" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb9-369"><a href="#cb9-369" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-sobre-aprendizaje</span></span>
<span id="cb9-370"><a href="#cb9-370" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Sobre-aprendizaje en un problema de regresión"</span></span>
<span id="cb9-371"><a href="#cb9-371" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb9-372"><a href="#cb9-372" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> tree</span>
<span id="cb9-373"><a href="#cb9-373" aria-hidden="true" tabindex="-1"></a>arbol <span class="op">=</span> tree.DecisionTreeRegressor().fit(np.atleast_2d(x).T, ym)</span>
<span id="cb9-374"><a href="#cb9-374" aria-hidden="true" tabindex="-1"></a>hy <span class="op">=</span> arbol.predict(np.atleast_2d(x).T)</span>
<span id="cb9-375"><a href="#cb9-375" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'arbol'</span>] <span class="op">=</span> hy</span>
<span id="cb9-376"><a href="#cb9-376" aria-hidden="true" tabindex="-1"></a>sns.lineplot(data<span class="op">=</span>df, x<span class="op">=</span><span class="st">'x'</span>, y<span class="op">=</span><span class="st">'arbol'</span>, legend<span class="op">=</span><span class="va">False</span>, color<span class="op">=</span><span class="st">'k'</span>)</span>
<span id="cb9-377"><a href="#cb9-377" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> sns.scatterplot(data<span class="op">=</span>df, x<span class="op">=</span><span class="st">'x'</span>, y<span class="op">=</span><span class="st">'y'</span>, legend<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb9-378"><a href="#cb9-378" aria-hidden="true" tabindex="-1"></a>fig.tick_params(bottom<span class="op">=</span><span class="va">False</span>, top<span class="op">=</span><span class="va">False</span>, </span>
<span id="cb9-379"><a href="#cb9-379" aria-hidden="true" tabindex="-1"></a>                left<span class="op">=</span><span class="va">False</span>, right<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb9-380"><a href="#cb9-380" aria-hidden="true" tabindex="-1"></a>                labelbottom<span class="op">=</span><span class="va">False</span>, labelleft<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb9-381"><a href="#cb9-381" aria-hidden="true" tabindex="-1"></a>fig.<span class="bu">set</span>(xlabel<span class="op">=</span><span class="st">'x'</span>, ylabel<span class="op">=</span><span class="st">'y'</span>)</span>
<span id="cb9-382"><a href="#cb9-382" aria-hidden="true" tabindex="-1"></a>plt.grid()</span>
<span id="cb9-383"><a href="#cb9-383" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-384"><a href="#cb9-384" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-385"><a href="#cb9-385" aria-hidden="true" tabindex="-1"></a><span class="fu">### Sub-aprendizaje</span></span>
<span id="cb9-386"><a href="#cb9-386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-387"><a href="#cb9-387" aria-hidden="true" tabindex="-1"></a>Por otro lado existen problemas donde el conjunto de algoritmos $\mathcal H$ no tienen los grados de libertad necesarios para aprender, dependiendo de la medida de error esto se refleja como $E(h^* \mid \mathcal T) \gg 0$. La @fig-sub-aprendizaje muestra un problema de regresión donde el algoritmo de aprendizaje presenta el problema de sub-aprendizaje. </span>
<span id="cb9-388"><a href="#cb9-388" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-391"><a href="#cb9-391" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb9-392"><a href="#cb9-392" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-sub-aprendizaje</span></span>
<span id="cb9-393"><a href="#cb9-393" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Sub-aprendizaje en un problema de regresión"</span></span>
<span id="cb9-394"><a href="#cb9-394" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb9-395"><a href="#cb9-395" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> tree</span>
<span id="cb9-396"><a href="#cb9-396" aria-hidden="true" tabindex="-1"></a>arbol <span class="op">=</span> tree.DecisionTreeRegressor(max_depth<span class="op">=</span><span class="dv">2</span>).fit(np.atleast_2d(x).T, ym)</span>
<span id="cb9-397"><a href="#cb9-397" aria-hidden="true" tabindex="-1"></a>hy <span class="op">=</span> arbol.predict(np.atleast_2d(x).T)</span>
<span id="cb9-398"><a href="#cb9-398" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'arbol'</span>] <span class="op">=</span> hy</span>
<span id="cb9-399"><a href="#cb9-399" aria-hidden="true" tabindex="-1"></a>sns.lineplot(data<span class="op">=</span>df, x<span class="op">=</span><span class="st">'x'</span>, y<span class="op">=</span><span class="st">'arbol'</span>, legend<span class="op">=</span><span class="va">False</span>, color<span class="op">=</span><span class="st">'k'</span>)</span>
<span id="cb9-400"><a href="#cb9-400" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> sns.scatterplot(data<span class="op">=</span>df, x<span class="op">=</span><span class="st">'x'</span>, y<span class="op">=</span><span class="st">'y'</span>, legend<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb9-401"><a href="#cb9-401" aria-hidden="true" tabindex="-1"></a>fig.tick_params(bottom<span class="op">=</span><span class="va">False</span>, top<span class="op">=</span><span class="va">False</span>, </span>
<span id="cb9-402"><a href="#cb9-402" aria-hidden="true" tabindex="-1"></a>                left<span class="op">=</span><span class="va">False</span>, right<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb9-403"><a href="#cb9-403" aria-hidden="true" tabindex="-1"></a>                labelbottom<span class="op">=</span><span class="va">False</span>, labelleft<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb9-404"><a href="#cb9-404" aria-hidden="true" tabindex="-1"></a>fig.<span class="bu">set</span>(xlabel<span class="op">=</span><span class="st">'x'</span>, ylabel<span class="op">=</span><span class="st">'y'</span>)</span>
<span id="cb9-405"><a href="#cb9-405" aria-hidden="true" tabindex="-1"></a>plt.grid()</span>
<span id="cb9-406"><a href="#cb9-406" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
</code><button title="Copiar al portapapeles" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
<p><a href="http://creativecommons.org/licenses/by-sa/4.0/"><img src="https://i.creativecommons.org/l/by-sa/4.0/80x15.png" class="img-fluid"></a> <br> Esta obra está bajo una <a href="http://creativecommons.org/licenses/by-sa/4.0/">Licencia Creative Commons Atribución-CompartirIgual 4.0 Internacional</a></p>
</div>
  </div>
</footer>




</body></html>