[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Aprendizaje Computacional",
    "section": "",
    "text": "Prefacio\nEste curso ha evolucionado de las clases de Aprendizaje Computacional impartidas en la Maestría en Ciencia de Datos e Información (MCDI) de INFOTEC y de Aprendizaje Computacional en la Maestría en Métodos para el Análisis de Políticas Públicas del CIDE.\nEn la MCDI compartí el curso con la Dra. Claudia N. Sánchez y parte de este material, en particular algunas figuras, fueron generadas por la Dra. Sánchez.\nEl curso trata de ser auto-contenido, es decir, no debería de ser necesario leer otras fuentes para poder entenderlo y realizar las actividades. De cualquier manera es importante comentar que el curso está basado en los siguientes libros de texto:",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#notación",
    "href": "index.html#notación",
    "title": "Aprendizaje Computacional",
    "section": "Notación",
    "text": "Notación\nLa Tabla 1 muestra la notación que se seguirá en este documento.\n\n\n\nTabla 1: Notación\n\n\n\n\n\n\n\n\n\nSímbolo\nSignificado\n\n\n\n\n\\(x\\)\nVariable usada comunmente como entrada\n\n\n\\(y\\)\nVariable usada comunmente como salida\n\n\n\\(\\mathbb R\\)\nNúmeros reales\n\n\n\\(\\mathbf x\\)\nVector Columna \\(\\mathbf x \\in \\mathbb R^d\\)\n\n\n\\(\\lVert \\mathbf x \\rVert\\)\nNorma Euclideana\n\n\n\\(d\\)\nDimensión\n\n\n\\(\\mathbf w \\cdot \\mathbf x\\)\nProducto punto donde \\(\\mathbf w\\) y \\(\\mathbf x \\in \\mathbb R^d\\)\n\n\n\\(\\mathcal D\\)\nConjunto de datos\n\n\n\\(\\mathcal T\\)\nConjunto de entrenamiento\n\n\n\\(\\mathcal V\\)\nConjunto de validación\n\n\n\\(\\mathcal G\\)\nConjunto de prueba\n\n\n\\(N\\)\nNúmero de ejemplos\n\n\n\\(K\\)\nNúmero de clases\n\n\n\\(\\mathbb P(\\cdot)\\)\nProbabilidad\n\n\n\\(\\mathcal X, \\mathcal Y\\)\nVariables aleatorías\n\n\n\\(\\mathcal N(\\mu, \\sigma^2)\\)\nDistribución Normal con parámetros \\(\\mu\\) y \\(\\sigma^2\\)\n\n\n\\(f_{\\mathcal X}\\)\nFunción de densidad de probabilidad de \\(\\mathcal X\\)\n\n\n\\(\\mathbb 1(e)\\)\nFunción para indicar; \\(1\\) si \\(e\\) es verdadero\n\n\n\\(\\Omega\\)\nEspacio de búsqueda\n\n\n\\(\\mathbb V\\)\nVarianza\n\n\n\\(\\mathbb E\\)\nEsperanza",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#licencia",
    "href": "index.html#licencia",
    "title": "Aprendizaje Computacional",
    "section": "Licencia",
    "text": "Licencia\n\nEsta obra está bajo una Licencia Creative Commons Atribución-CompartirIgual 4.0 Internacional",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "capitulos/01Introduccion.html",
    "href": "capitulos/01Introduccion.html",
    "title": "1  Introducción",
    "section": "",
    "text": "1.1 Aprendizaje Computacional\nEl objetivo de la unidad es explicar el área de aprendizaje computacional, los diferentes tipos de aprendizaje que la componen, la metodología general del área y su relación con otras áreas del conocimiento.\nUtilizando la descripción de Langley (1986), se puede definir el aprendizaje computacional como una rama de la Inteligencia Artificial (IA) que estudia los enfoques computacionales capaces de aprender y mejorar su rendimiento con el paso del tiempo. En sus inicios, el campo estaba enfocado al desarrollo de representaciones simbólicas, de la misma manera que la IA, sin prohibir las representaciones numéricas. Actualmente, el campo ha cambiado de dirección privilegiando las representaciones numéricas a las simbólicas, en particular, este documento se enfoca solamente a representaciones numéricas.\nDe acuerdo a Breiman (2001), existen dos metas al analizar datos donde es posible identificar valores de entrada y su respuesta. Estos objetivos son el predecir la respuesta de futuros eventos y el segundo es extraer conocimiento del proceso o fenómeno. Estas metas han dado origen a dos culturas en el modelado de los datos: la cultura del modelado de datos y la cultura del modelado de algoritmos.\nEn la cultura del modelado de datos, se asume que los datos provienen de una función que dependen de los valores de entrada, un conjunto de parámetros y ruido. Utilizando los datos se estiman los parámetros y si los datos cumplen con las condiciones impuestas a la función, entonces se conoce el procedimiento que genera los datos y se está en la posición de obtener conocimiento del sistema, es decir se atacó la segunda meta. Dado que se tienen los parámetros y la estructura de la función es factible hacer predicciones de futuros eventos (primera meta).\nEn la cultura del modelado del algoritmo, no se asume ninguna estructura al sistema que genera los datos, el procedimiento es diseñar un algoritmo que replique la respuesta dada las entradas. Considerando que no se está asumiendo ningún modelo particular entonces el obtener conocimiento del sistema no es un prioridad. Por otro lado, es una prioridad encontrar el algoritmo que mejor se reproduzca los datos y por lo tanto se desarrollan diferentes estrategias para medir el rendimiento del algoritmo y poder estimar su comportamiento en diferentes escenarios. El área de aprendizaje computacional se encuentra en esta segunda cultura.\nExisten diferentes tipos de aprendizaje computacional, los mas comunes son: aprendizaje supervisado, aprendizaje no-supervisado y aprendizaje por refuerzo. En aprendizaje supervisado se crean modelos partiendo de un conjunto de pares, entrada y salida, donde el objetivo es encontrar un modelo que logra aprender esta relación y predecir ejemplos no vistos en el proceso, en particular a esto se le conoce como inductive learning. Complementando este tipo de aprendizaje supervisado se tiene lo que se conoce como transductive learning, en el cual se cuenta con un conjunto de pares y solamente se requiere conocer la salida en otro conjunto de datos. En este segundo tipo de aprendizaje todos los datos son conocidos en el proceso de aprendizaje.\nAprendizaje no-supervisado es aquel donde se tiene un conjunto de entradas y se busca aprender alguna relación de estas entradas, por ejemplo, generando grupos o utilizando estas entradas para hacer una transformación o encontrar un patrón.\nFinalmente aprendizaje por refuerzo es aquel donde se tiene un agente que tiene que aprender como interactuar con un ambiente. La interacción es tomando una acción en cada diferente estado del ambiente. Por ejemplo, el agente puede ser un jugador virtual en un juego de ajedrez entonces la acción es identificar y mover una pieza en el tablero, el objetivo de ganar la partida. La característica de aprendizaje por refuerzo es que el agente va a recibir una recompensa al final de la interacción con el ambiente, e.g., final del juego y el objetivo es optimizar las acciones para que la recompensa sea la mayor posible.\nEl área de aprendizaje computacional ha tenido un crecimiento importante en los últimos años, algunos ejemplos del impacto de área se pueden encontrar en artículos publicados en la revista de la editorial Nature. Por ejemplo, en el área médica en específico en Cardiología Hannun et al. (2019) propone una metodología para detectar arritmias o en dermatología Esteva et al. (2017) propone un algoritmo para la detección de cancer.\nCabe mencionar que los tres tipos de aprendizaje no son excluyentes uno del otro, comúnmente para resolver un problema complejo se combinan diferentes tipos de aprendizaje y otras tecnologías de IA para encontrar una solución aceptable. Probablemente una de las pruebas más significativas de lo que puede realizarse con aprendizaje automático es lo realizado por AlphaGo descrito por Silver et al. (2016) y en Silver et al. (2017) se quitan una de las restricciones originales, la cual consiste en contar con un conjunto de jugadas realizadas por expertos.\nEn el área de aprendizaje, hay una tendencia de utilizar plataformas donde diferentes empresas u organismos gubernamentales o sin fines de lucro, ponen un problema e incentivan al publico en general a resolver este problema. La plataforma sirve de mediador en este proceso. Ver por ejemplo https://www.kaggle.com.\nEn el ámbito científico también se han generado este tipo de plataformas aunque su objetivo es ligeramente diferente, lo que se busca es tener una medida objetiva de diferentes soluciones y en algunos casos facilitar la reproducibilidad de las soluciones. Ver por ejemplo http://codalab.org.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "capitulos/01Introduccion.html#aprendizaje-computacional",
    "href": "capitulos/01Introduccion.html#aprendizaje-computacional",
    "title": "1  Introducción",
    "section": "",
    "text": "Actividad\n\n\n\n\n\nLeer la carta editorial de Langley (1986) para conocer la visión que se tenía de aprendizaje computacional en esa época y contrastarla con la visión actual.\n\n\n\n\n\n\n\n\n\n\n\n\nActividad\n\n\n\n\n\nLeer el artículo de Breiman (2001) para profundizar en las ventajas y desventajas de cada una de las culturas y como estas influyen en la forma de abordar un problema. En este momento no es necesario detenerse en la parte técnica de los algoritmos descritos en el artículo.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "capitulos/01Introduccion.html#sec-metodologia-general",
    "href": "capitulos/01Introduccion.html#sec-metodologia-general",
    "title": "1  Introducción",
    "section": "1.2 Metodología General en Aprendizaje Supervisado y No Supervisado",
    "text": "1.2 Metodología General en Aprendizaje Supervisado y No Supervisado\nAntes de continuar con la descripción de los diferentes tipos de aprendizaje es importante mencionar la metodología que se sigue en los problemas de aprendizaje supervisado y no supervidado\n\nTodo empieza con un conjunto de datos \\(\\mathcal D\\) que tiene la información del fenómeno de interés.\nSe selecciona el conjunto de entrenamiento \\(\\mathcal T \\subseteq \\mathcal D\\).\nSe diseña un algoritmo, \\(f\\), utilizando \\(\\mathcal T\\).\nSe utiliza \\(f\\) para estimar las características modeladas.\nSe mide el rendimiento de \\(f\\).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "capitulos/01Introduccion.html#sec-aprendizaje-no-supervisado",
    "href": "capitulos/01Introduccion.html#sec-aprendizaje-no-supervisado",
    "title": "1  Introducción",
    "section": "1.3 Aprendizaje No Supervisado",
    "text": "1.3 Aprendizaje No Supervisado\nIniciamos la descripción de los diferentes tipos de aprendizaje computacional con aprendizaje no-supervisado; el cual inicia con un conjunto de elementos. Estos tradicionalmente se puede transformar en conjunto de vectores, i.e. \\(\\mathcal D = \\{ x_1, \\ldots, x_N \\}\\), donde \\(x_i \\in \\mathbb R^d\\). Durante este curso asumiremos que esta transformación existe y en algunos casos se hará explícito el algoritmo de transformación.\nEl objetivo en aprendizaje no supervisado es desarrollar algoritmos capaces de encontrar patrones en los datos, es decir, en \\(\\mathcal D\\). Existen diferentes tareas que se pueden considerar dentro de este tipo de aprendizaje. Por ejemplo, el agrupamiento puede servir para segmentar clientes o productos, en otra línea también cabría el análisis del carrito de compras (Market Basket Analysis); donde el objetivo es encontrar la co-ocurrencias de productos, es decir, se quiere estimar la probabilidad de que habiendo comprado un determinado artículo también se compre otro artículo. Con esta descripción ya se podrá estar imaginando la cantidad de aplicaciones en las que este tipo de algoritmos es utilizado en la actualidad.\nRegresando a la representación vectorial, existen casos donde se pueden visualizar los elementos de \\(\\mathcal D\\), lo cuales están representados como puntos que se muestran en la Figura 1.1. Claramente esto solo es posible si \\(x_i \\in \\mathbb R^2\\) o si se hace algún tipo de transformación \\(f: \\mathbb R^d \\rightarrow \\mathbb R^2\\), como se realizó en la figura.\n\n\nCódigo\nfrom sklearn import decomposition\nfrom sklearn.datasets import load_iris\nfrom matplotlib import pylab as plt\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\n\n\nD, y = load_iris(return_X_y=True)\npca = decomposition.PCA(n_components=2).fit(D)\nDn = pca.transform(D)\nDn = np.concatenate((Dn, np.atleast_2d(y).T), axis=1)\ndf = pd.DataFrame(Dn, columns=['x', 'y', 'Clase'])\nfig = sns.relplot(data=df, kind='scatter',\n                  x='x', y='y')\nfig.tick_params(bottom=False, top=False, \n                left=False, right=False,\n                labelbottom=False, labelleft=False)\nfig.set(xlabel=None, ylabel=None)\nplt.grid()\n\n\n\n\n\n\n\n\nFigura 1.1: Proyección de los datos del Iris en dos dimensiones\n\n\n\n\n\nEn la Figura 1.1 se pueden observar dos o tres grupos de puntos, entonces el objetivo sería crear el algoritmo que dado \\(\\mathcal D\\) regrese un identificador por cada elemento, dicho identificador representa el grupo al que pertenece el elemento en cuestión. Esta tarea se le conoce como agrupamiento (Clustering). Asumiendo que se aplica un algoritmo de agrupamiento a los datos anteriores; entonces, dado que podemos visualizar los datos, es factible representar el resultado del algoritmo si a cada punto se le asigna un color dependiendo de la clase a la que pertenece. La Figura 1.2 muestra el resultado de este procedimiento.\n\n\nCódigo\nfrom sklearn.cluster import KMeans\nfrom sklearn import decomposition\nfrom sklearn.datasets import load_iris\nfrom matplotlib import pylab as plt\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\n\n\nD, y = load_iris(return_X_y=True)\nm = KMeans(n_clusters=3, n_init='auto').fit(D)\ncl = m.predict(D)\npca = decomposition.PCA(n_components=2).fit(D)\nDn = pca.transform(D)\nDn = np.concatenate((Dn, np.atleast_2d(y).T,\n                     np.atleast_2d(cl).T), axis=1)\ndf = pd.DataFrame(Dn, columns=['x', 'y', 'Clase', 'Grupo'])\nfig = sns.relplot(data=df, kind='scatter',\n                  x='x', y='y', hue='Grupo')\nfig.tick_params(bottom=False, top=False, \n                left=False, right=False,\n                labelbottom=False, labelleft=False)\nfig.set(xlabel=None, ylabel=None)\nplt.grid()\n\n\n\n\n\n\n\n\nFigura 1.2: Proyección de agrupar los datos del Iris usando K-medias\n\n\n\n\n\nSe puede observar en la figura anterior, el algoritmo de agrupamiento separa los puntos en tres grupos, representados por los colores diferentes colores. Cabe mencionar que utilizando algún otro criterio de optimización se hubiera podido encontrar dos grupos, el primero de ellos sería el grupo de los puntos que se encuentran a la izquierda de la figura y el segundo sería el grupo formado por los grupos que se encuentran en el centro y a la derecha de la figura. Es importante recalcar que no es necesario visualizar los datos para aplicar un algoritmo de agrupamiento. En particular el ejercicio de visualización de datos y del resultado de agrupamiento que se muestra en la figuras anteriores tiene el objetivo de generar una intuición de lo que está haciendo un algoritmo de agrupamiento.\n\n\n\n\n\n\nActividad\n\n\n\n\n\nGenerar la figura anterior para el conjunto de datos de Breast Cancer Wisconsin (Sección B.3.1). Es necesario considerar que ese problema solamente tiene dos clases y el problema del Iris (Sección B.3.2) tiene tres clases, entonces se tienen que hacer las modificaciones para atender este cambio.\nEl procedimiento desarrollado debe de generar una figura similar a la mostrada en la Figura 1.3\n\n\n\n\n\n\n\n\nFigura 1.3: Proyección de agrupar los datos de Breast Cancer Wisconsin usando K-medias",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "capitulos/01Introduccion.html#sec-aprendizaje-supervisado",
    "href": "capitulos/01Introduccion.html#sec-aprendizaje-supervisado",
    "title": "1  Introducción",
    "section": "1.4 Aprendizaje Supervisado",
    "text": "1.4 Aprendizaje Supervisado\nAprendizaje supervisado inicia con un conjunto de pares, entrada y salida; la Figura 1.4 ilustra el mecanismo que genera estos pares, del lado izquierdo se tiene las variables medibles que entran al proceso o fenómeno que se desconoce y del lado derecho se mide la(s) variable(s) respuesta, es decir, la(s) salida(s) del sistema. En otras palabras se tiene \\(\\mathcal D = \\{ (x_1, y_1), \\ldots, (x_N, y_N )\\}\\), donde \\(x_i \\in \\mathbb R^d\\) corresponde a la \\(i\\)-ésima entrada y \\(y_i\\) es la salida asociada a esa entrada.\n\n\n\n\n\n\nflowchart LR\n    Entrada([Entradas]) --&gt;  Proceso[Proceso / Fenómeno]\n    Proceso --&gt; Salidas([Salidas])\n\n\n\n\nFigura 1.4: Datos de Aprendizaje Supervisado\n\n\n\n\n\nConsiderando que se desconoce el modelo del proceso o fenómeno que generó la respuesta y además que pueden existir variables de entrada que no son medibles, se puede definir el objetivo de aprendizaje supervisado como encontrar un algoritmo o función, \\(f\\), capaz de regresar la salida, \\(y\\), dada una entrada \\(x\\).\nLos posibles fines de desarrollar la función \\(f\\) es por un lado predecir la salida dada una nueva entrada \\(x\\) y por el otro lado extraer conocimiento del proceso que asocia la respuesta de las variables de entrada (ver Breiman (2001)). Estos dos metas se pueden contraponer, es decir, extraer conocimiento implica una reducción en la calidad de la predicción y viceversa mejorar la calidad de predicción en general trae consigo una menor capacidad para entender el fenómeno generador de datos.\nExiste una gran variedad de problemas que se puede categorizar como tareas de aprendizaje supervisado, solamente hay que recordar que en todos los casos se inicia con un conjunto \\(\\mathcal D\\) de pares entrada y salida. En ocasiones la construcción del conjunto es directa, por ejemplo en el caso de que se quiera identificar si una persona será sujeta a un crédito, entonces el conjunto a crear esta compuesto por las características de las personas que se les ha otorgado un crédito y el estado final de crédito, es decir, si el crédito fue pagado o no fue pagado. En otro ejemplo, suponiendo que se quiere crear un algoritmo capaz de identificar si un texto dado tiene una polaridad positiva o negativa, entonces el conjunto se crea recolectando textos y a cada texto un conjunto de personas decide si el texto dado es positivo o negativo y la polaridad final es el consenso de varias opiniones; a este problema en general se le conoce como análisis de sentimientos.\nLa cantidad de problema que se pueden poner en términos de aprendizaje supervisado es amplia, un problema tangible en esta época y relacionado a la pandemia del COVID-19 sería el crear un algoritmo que pudiera predecir cuántos serán los casos positivos el día de mañana dando como entradas las restricciones en las actividades; por ejemplo escuelas cerradas, restaurantes al 30% de capacidad entre otras.\nLos ejemplos anteriores corresponden a dos de las clases de problemas que se resuelven en aprendizaje supervisado estas son problemas de clasificación y regresión. Definamos de manera formal estos dos problemas. Cuando \\(y \\in \\{0, 1\\}\\) se dice que es un problema de clasificación binaria, por otro lado cuando \\(y \\in \\{0, 1\\}^K\\) se encuentra uno en clasificación multi-clase o multi-etiqueta y finalmente si \\(y \\in \\mathbb R\\) entonces es un problema de regresión.\nHaciendo la liga entre los ejemplos y las definiciones anteriores, podemos observar que el asignar un crédito o la polaridad a un texto es un problema de clasificación binaria, dado que se puede asociar 0 y 1 a la clase positivo y negativo; y en el otro caso a pagar o no pagar el crédito. Si el problema tiene mas categorías, supongamos que se desea identificar positivo, negativo o neutro, entonces se estaría en el problema de clasificación multi-clase. Por otro lado el problema de predecir el número de casos positivos se puede considerar como un problema de regresión, dado que el valor a predecir difícilmente se podría considerar como una categoría.\nAl igual que en aprendizaje no supervisado, en algunos casos es posible visualizar los elementos de \\(\\mathcal D\\), el detalle adicional es que cada objeto tiene asociado una clase, entonces se selecciona un color para representar cada clase. En la Figura 1.5 se muestra el resultado donde los elementos de \\(\\mathcal D\\) se encuentra en \\(\\mathbb R^2\\) y el color representa cada una de la clases de este problema de clasificación binaria.\n\n\nCódigo\nfrom sklearn.cluster import KMeans\nfrom sklearn import decomposition\nfrom sklearn.datasets import load_iris\nfrom matplotlib import pylab as plt\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\n\n\nD, y = load_iris(return_X_y=True)\nmask = y &lt;= 1\nD = D[mask]\ny = y[mask]\npca = decomposition.PCA(n_components=2).fit(D)\nDn = pca.transform(D)\ndf = pd.DataFrame(Dn, columns=['x', 'y'])\ndf['Clase'] = ['P' if i else 'N' for i in y]\nfig = sns.relplot(data=df, kind='scatter',\n                  x='x', y='y', hue='Clase')\nfig.tick_params(bottom=False, top=False, \n                left=False, right=False,\n                labelbottom=False, labelleft=False)\nfig.set(xlabel=None, ylabel=None)\nplt.grid()\n\n\n\n\n\n\n\n\nFigura 1.5: Proyección del Iris mostrando dos clases linealmente separables\n\n\n\n\n\n\n\n\n\n\n\nActividad\n\n\n\n\n\nGenerar la figura anterior para el conjunto de datos de Breast Cancer Wisconsin (Sección B.3.1). Como se mencionó, el problema tiene dos clases entonces no se necesita ningún tipo de transformación en el número de clases como se hizo en el ejemplo anterior. La Figura 1.6 muestra el resultado de la actividad.\n\n\n\n\n\n\n\n\nFigura 1.6: Proyección de los datos de Breast Cancer Wisconsin.\n\n\n\n\n\n\n\n\nUsando esta representación es sencillo imaginar que el problema de clasificación se trata en encontrar una función que separe los puntos naranjas de los puntos azules, como se pueden imagina una simple línea recta podría separar estos puntos. La Figura 1.7 muestra un ejemplo de lo que haría un clasificador representado por la línea; la clase es dada por el signo de \\(ax + by + c\\), donde \\(a\\), \\(b\\) y \\(c\\) son parámetros identificados a partir de \\(\\mathcal D\\).\n\n\nCódigo\nfrom sklearn.cluster import KMeans\nfrom sklearn.svm import LinearSVC\nfrom sklearn import decomposition\nfrom sklearn.datasets import load_iris\nfrom matplotlib import pylab as plt\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\n\n\nD, y = load_iris(return_X_y=True)\nmask = y &lt;= 1\nD = D[mask]\ny = y[mask]\npca = decomposition.PCA(n_components=2).fit(D)\nDn = pca.transform(D)\nlinear = LinearSVC(dual=False).fit(Dn, y)\nw_1, w_2 = linear.coef_[0]\nw_0 = linear.intercept_[0]\ndf = pd.DataFrame(Dn, columns=['x1', 'x2'])\ndf['Clase'] = ['N' if i else 'P' for i in y]\ng_0 = [dict(x1=x, x2=y, tipo='g(x)=0')\n       for x, y in zip(Dn[:, 0], (-w_0 - w_1 * Dn[:, 0]) / w_2)]\ng = pd.DataFrame(g_0)\ng['Tipo'] = 'g(x)=0'\ndf = pd.concat((df, g))\nax = sns.scatterplot(data=df, x='x1', y='x2', hue='Clase', legend=True)\nsns.lineplot(data=df, x='x1', y='x2', ax=ax, hue='Tipo', palette=['k'], legend=True)\nax.tick_params(axis=\"both\", which=\"both\", bottom=False,\n                top=False, left=False, right=False,\n                labelbottom=False, labelleft=False)\nax.set(xlabel=None, ylabel=None)\nplt.grid()\n\n\n\n\n\n\n\n\nFigura 1.7: Proyección del Iris mostrando dos clases linealmente separables\n\n\n\n\n\nSiguiendo en esta misma línea, también es posible observar los puntos en un problema de regresión, solamente que en este caso un eje corresponde a las entradas, i.e. \\(x\\), y el otro eje es la salida, i.e. \\(y\\). La Figura 1.8 muestra un ejemplo de regresión, donde se puede observar que la idea es una encontrar una función que pueda seguir de manera adecuada los puntos datos.\n\n\nCódigo\nfrom matplotlib import pylab as plt\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\n\nx = np.linspace(-1, 1, 100)\ny = 12.3 * x**2 - 3.2 * x + 1.2\nym = np.random.normal(loc=0, scale=0.2, size=x.shape[0]) + y\ndf = pd.DataFrame(dict(x=x, y=y, ym=ym))\n# sns.lineplot(data=df, x='x', y='y', legend=False, color='k')\nfig = sns.scatterplot(data=df, x='x', y='ym', legend=False)\nfig.tick_params(bottom=False, top=False, \n                left=False, right=False,\n                labelbottom=False, labelleft=False)\nfig.set(xlabel='x', ylabel='y')\nplt.grid()\n\n\n\n\n\n\n\n\nFigura 1.8: Problema de regresión\n\n\n\n\n\nEl problema de regresión es muy conocido y seguramente ya se imaginaron que la respuesta sería encontrar los parámetros de una parábola. La Figura 1.9 muestra una visualización del regresor, mostrado en color negro y los datos de entrenamiento en color azul.\n\n\nCódigo\nsns.lineplot(data=df, x='x', y='y', legend=False, color='k')\nfig = sns.scatterplot(data=df, x='x', y='ym', legend=False)\nfig.tick_params(axis=\"both\", which=\"both\", bottom=False,\n                top=False, left=False, right=False,\n                labelbottom=False, labelleft=False)\nfig.set(xlabel='x', ylabel='y')\nplt.grid()\n\n\n\n\n\n\n\n\nFigura 1.9: Problema de regresión con función con función estimada\n\n\n\n\n\nAl igual que en aprendizaje no supervisado, este ejercicio de visualización no es posible en todos los problemas de aprendizaje supervisado, pero si permite ganar intuición sobre la forma en que trabajan estos algoritmos.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "capitulos/01Introduccion.html#sec-definiciones-aprendizaje-supervisado",
    "href": "capitulos/01Introduccion.html#sec-definiciones-aprendizaje-supervisado",
    "title": "1  Introducción",
    "section": "1.5 Definiciones de Aprendizaje Supervisado",
    "text": "1.5 Definiciones de Aprendizaje Supervisado\nEl primer paso es empezar a definir los diferentes conjuntos con los que se trabaja en aprendizeje computacional. Todo inicia con el conjunto de entrenamiento identificado en este documento como \\(\\mathcal T\\). Este conjunto se utiliza para estimar los parámetros o en general buscar un algoritmo que tenga el comportamiento esperado.\nSe puede asumir que existe una función \\(f\\) que genera la relación entrada salida mostrada en \\(\\mathcal T\\), es decir, idealmente se tiene que \\(\\forall_{(x, y) \\in \\mathcal D} f(x) = y\\). En este contexto, aprendizaje supervisado se entiende como el proceso de encontrar una función \\(h^*\\) que se comporta similar a \\(f\\).\nPara encontrar \\(h^*\\), se utiliza \\(\\mathcal T\\); el conjunto de hipótesis (funciones), \\(\\mathcal H\\), que se considera puede aproximar \\(f\\); una función de error, \\(L\\); y el error empírico \\(E(h \\mid \\mathcal T) = \\sum_{(x, y) \\in \\mathcal T} L(y, h(x))\\). Utilizando estos elementos la función buscada es: \\(h^* = \\textsf{argmin}_{h \\in \\mathcal{H}} E(h \\mid \\mathcal T)\\).\nEl encontrar la función \\(h^*\\) no resuelve el problema de aprendizaje en su totalidad, además se busca una función que sea capaz de generalizar, es decir, que pueda predecir correctamente instancias no vistas. Considerando que se tiene un conjunto de prueba, \\(\\mathcal G=\\{(x_i, y_i)\\}\\) para \\(i=1 \\ldots M\\), donde \\(\\mathcal T \\cap \\mathcal G = \\emptyset\\) y \\(\\mathcal T \\cup \\mathcal G = \\mathcal D.\\) La idea es que el error empírico sea similar en el conjunto de entrenamiento y prueba. Es decir \\(E(h^* \\mid \\mathcal T) \\approx E(h^* \\mid \\mathcal G)\\).\n\n1.5.1 Estilos de Aprendizaje\nUtilizando \\(\\mathcal T\\) y \\(\\mathcal G\\) podemos definir inductive learning como el proceso de aprendizaje en donde solamente se utiliza \\(\\mathcal T\\) y el algoritmo debe de ser capaz de predecir cualquier instancia. Por otro lado, transductive learning es el proceso de aprendizaje donde se utilizar \\(\\mathcal T \\cup \\{ x \\mid (x, y) \\in \\mathcal G \\}\\) para aprender y solamente es de interés el conocer la clase o variable dependiente del conjunto \\(\\mathcal G\\).\n\n\n1.5.2 Sobre-aprendizaje\nExisten clases de algoritmos, \\(\\mathcal H\\), que tienen un mayor grado de libertad el cual se ve reflejado en una capacidad superior para aprender, pero por otro lado, existen problemas donde no se requiere tanta libertad, esta combinación se traduce en que el algoritmo no es capaz de generalizar y cuantitativamente se ve como \\(E(h^* \\mid \\mathcal T) \\ll E(h^* \\mid \\mathcal G)\\).\nPara mostrar este caso hay que imaginar que se tiene un algoritmo que guarda el conjunto de entrenamiento y responde lo siguiente:\n\\[h^*(x) = \\begin{cases} y & \\text{si} (x, y) \\in \\mathcal T\\\\ 0 & \\end{cases}\\]\nEs fácil observar que este algoritmo tiene \\(E(h^* \\mid \\mathcal T) = 0\\) dado que se aprende todo el conjunto de entrenamiento.\nLa Figura 1.10 muestra el comportamiento de un algoritmo que sobre-aprende, el algoritmo se muestra en la línea naranja, la línea azul corresponde a una parábola (cuyos parámetros son identificados con los datos de entrenamiento) y los datos de entrenamiento no se muestran; pero se pueden visualizar dado que son datos generados por una parábola mas un error gaussiano. Entonces podemos ver que la línea naranja pasa de manera exacta por todos los datos de entrenamiento y da como resultado la línea naranja que claramente tiene un comportamiento mas complejo que el comportamiento de la parábola que generó los datos.\n\n\nCódigo\nfrom sklearn import tree\narbol = tree.DecisionTreeRegressor().fit(np.atleast_2d(x).T, ym)\nhy = arbol.predict(np.atleast_2d(x).T)\ndf['arbol'] = hy\nsns.lineplot(data=df, x='x', y='arbol', legend=False, color='k')\nfig = sns.scatterplot(data=df, x='x', y='y', legend=False)\nfig.tick_params(bottom=False, top=False, \n                left=False, right=False,\n                labelbottom=False, labelleft=False)\nfig.set(xlabel='x', ylabel='y')\nplt.grid()\n\n\n\n\n\n\n\n\nFigura 1.10: Sobre-aprendizaje en un problema de regresión\n\n\n\n\n\n\n\n1.5.3 Sub-aprendizaje\nPor otro lado existen problemas donde el conjunto de algoritmos \\(\\mathcal H\\) no tienen los grados de libertad necesarios para aprender, dependiendo de la medida de error esto se refleja como \\(E(h^* \\mid \\mathcal T) \\gg 0\\). La Figura 1.11 muestra un problema de regresión donde el algoritmo de aprendizaje presenta el problema de sub-aprendizaje.\n\n\nCódigo\nfrom sklearn import tree\narbol = tree.DecisionTreeRegressor(max_depth=2).fit(np.atleast_2d(x).T, ym)\nhy = arbol.predict(np.atleast_2d(x).T)\ndf['arbol'] = hy\nsns.lineplot(data=df, x='x', y='arbol', legend=False, color='k')\nfig = sns.scatterplot(data=df, x='x', y='y', legend=False)\nfig.tick_params(bottom=False, top=False, \n                left=False, right=False,\n                labelbottom=False, labelleft=False)\nfig.set(xlabel='x', ylabel='y')\nplt.grid()\n\n\n\n\n\n\n\n\nFigura 1.11: Sub-aprendizaje en un problema de regresión\n\n\n\n\n\n\n\n\n\n\n\nBreiman, Leo. 2001. «Statistical modeling: The two cultures». Statistical science 16 (3): 199-231. https://doi.org/10.1214/ss/1009213726.\n\n\nEsteva, Andre, Brett Kuprel, Roberto A. Novoa, Justin Ko, Susan M. Swetter, Helen M. Blau, y Sebastian Thrun. 2017. «Dermatologist-level classification of skin cancer with deep neural networks». Nature 542 (7639): 115-18. https://doi.org/10.1038/nature21056.\n\n\nHannun, Awni Y., Pranav Rajpurkar, Masoumeh Haghpanahi, Geoffrey H. Tison, Codie Bourn, Mintu P. Turakhia, y Andrew Y. Ng. 2019. «Cardiologist-level arrhythmia detection and classification in ambulatory electrocardiograms using a deep neural network». Nature Medicine 25 (1): 65-69. https://doi.org/10.1038/s41591-018-0268-3.\n\n\nLangley, Pat. 1986. «Machine learning: An editorial». Maching Learning 1: 5-10. https://doi.org/10.1023/A:1022687019898.\n\n\nSilver, David, Aja Huang, Chris J. Maddison, Arthur Guez, Laurent Sifre, George van den Driessche, Julian Schrittwieser, et al. 2016. «Mastering the game of Go with deep neural networks and tree search». Nature 529 (7587): 484-89. https://doi.org/10.1038/nature16961.\n\n\nSilver, David, Julian Schrittwieser, Karen Simonyan, Ioannis Antonoglou, Aja Huang, Arthur Guez, Thomas Hubert, et al. 2017. «Mastering the game of Go without human knowledge». Nature 550 (7676): 354-59. https://doi.org/10.1038/nature24270.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "capitulos/02Teoria_Decision.html",
    "href": "capitulos/02Teoria_Decision.html",
    "title": "2  Teoría de Decisión Bayesiana",
    "section": "",
    "text": "Paquetes usados\nEl objetivo de la unidad es analizar el uso de la teoría de la probabilidad para la toma de decisiones. En particular el uso del teorema de Bayes para resolver problemas de clasificación y su uso para tomar la decisión que reduzca el riesgo.\nfrom scipy.stats import multivariate_normal\nfrom matplotlib import pylab as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Teoría de Decisión Bayesiana</span>"
    ]
  },
  {
    "objectID": "capitulos/02Teoria_Decision.html#sec-intro-02",
    "href": "capitulos/02Teoria_Decision.html#sec-intro-02",
    "title": "2  Teoría de Decisión Bayesiana",
    "section": "2.1 Introducción",
    "text": "2.1 Introducción\nAl diseñar una solución a un problema particular lo mejor que uno puede esperar es tener una certeza absoluta sobre la respuesta dada. Por ejemplo, si uno diseña un algoritmo que ordene un conjunto de números uno esperan que ese algoritmo siempre regrese el orden correcto independientemente de la entrada dada, es mas un algoritmo de ordenamiento que en ocasiones se equivoca se consideraría de manera estricta erróneo.\nSin embargo, existen problemas cuyas características, como incertidumbre en la captura de los datos, variables que no se pueden medir, entre otros factores hacen que lo mejor que se puede esperar es un algoritmo exacto y preciso. Todos los problemas que trataremos en Aprendizaje Computacional caen dentro del segundo escenario. El lenguaje que nos permite describir de manera adecuada este tipo de ambiente, que se caracteriza por variables aleatorios es el de la probabilidad.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Teoría de Decisión Bayesiana</span>"
    ]
  },
  {
    "objectID": "capitulos/02Teoria_Decision.html#sec-teoria-decision-probabilidad",
    "href": "capitulos/02Teoria_Decision.html#sec-teoria-decision-probabilidad",
    "title": "2  Teoría de Decisión Bayesiana",
    "section": "2.2 Probabilidad",
    "text": "2.2 Probabilidad\nEn Sección 1.4 se describió que el punto de inicio de aprendizaje supervisado es el conjunto \\(\\mathcal D = \\{ (x_1, y_1), \\ldots, (x_N, y_N )\\}\\), donde \\(x_i \\in \\mathbb R^d\\) corresponde a la \\(i\\)-ésima entrada y \\(y_i\\) es la salida asociada a esa entrada; este conjunto tiene el objetivo de guiar un proceso de búsqueda para encontrar una método que capture de la relación entre \\(x\\) y \\(y\\).\nSe pueden tratar la variables \\(x\\) y \\(y\\) de \\(\\mathcal D\\) como dos variables aleatorías \\(\\mathcal X\\) y \\(\\mathcal Y\\), respectivamente; en este dominio el problema de identificar la respuesta (\\(\\mathcal Y\\)) dada la entrada (\\(\\mathcal X\\)) se puede describir como encontrar la probabilidad de observar \\(\\mathcal Y\\) habiendo visto \\(\\mathcal X\\), es decir, \\(\\mathbb P(\\mathcal Y \\mid \\mathcal X)\\).\n\n2.2.1 Ejemplos\nPor ejemplo, en un problema de clasificación binaria se tiene que la respuesta tiene dos posibles valores, e.g., \\(\\mathcal Y=\\{0, 1\\}\\). Entonces el problema es saber si dada una entrada \\(x\\) el valor de la respuesta es \\(1\\) o \\(0\\). Utilizando probabilidad la pregunta quedaría como conocer la probabilidad de que \\(\\mathcal Y=1\\) o \\(\\mathcal Y=0\\) cuando se observa \\(\\mathcal X=x\\), es decir, encontrar \\(\\mathbb P(\\mathcal Y=1 \\mid \\mathcal X=x)\\) y compararlo contra \\(\\mathbb P(\\mathcal Y=0 \\mid \\mathcal X=x)\\). Tomando en cuenta estos valores de probabilidad se puede concluir el valor de la salida dado que \\(\\mathcal X=x\\). También está el caso que las probabilidades sean iguales, e.g., si \\(\\mathbb P(\\mathcal Y=1 \\mid \\mathcal X=x)=\\mathbb P(\\mathcal Y=0 \\mid \\mathcal X=x)=0.5\\) o que su diferencia sea muy pequeña y entonces se toma la decisión de desconocer el valor de la salida.\nPara el caso de regresión (\\(y \\in \\mathbb R\\)), el problema se puede plantear asumiendo que \\(\\mathcal Y\\) proviene de una distribución particular cuyos parámetros están dados por la entrada \\(\\mathcal X\\). Por ejemplo, en regresión lineal se asume que \\(\\mathcal Y\\) proviene de una distribución Gausiana con parámetros dados por \\(\\mathcal X\\), es decir, \\(\\mathbb P(\\mathcal Y \\mid \\mathcal X=x) = \\mathcal N(g(x) + \\epsilon, \\sigma^2),\\) donde los parámetros de la función \\(g\\) son identificados mediante \\(\\mathcal X\\) y \\(\\epsilon \\sim \\mathcal N(0, \\sigma^2)\\) es el error con media cero y desviación estándar \\(\\sigma\\). Con estas condiciones la salida \\(y\\) es \\(\\mathbb E[\\mathcal Y \\mid \\mathcal X=x];\\) asumiendo que se esa variable se distribuye como una normal entonces \\(\\mathbb E[\\mathcal Y \\mid \\mathcal X=x]= \\mathbb E[g(x) + \\epsilon]=g(x) + \\mathbb E[\\epsilon]=g(x).\\)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Teoría de Decisión Bayesiana</span>"
    ]
  },
  {
    "objectID": "capitulos/02Teoria_Decision.html#teorema-de-bayes",
    "href": "capitulos/02Teoria_Decision.html#teorema-de-bayes",
    "title": "2  Teoría de Decisión Bayesiana",
    "section": "2.3 Teorema de Bayes",
    "text": "2.3 Teorema de Bayes\nEl problema se convierte en cómo calcular \\(\\mathbb P(\\mathcal Y \\mid \\mathcal X)\\), lo cual se puede realizar mediante el Teorema de Bayes el cual se deriva a continuación.\nLa probabilidad conjunta se puede expresar como \\(\\mathbb P(\\mathcal X, \\mathcal Y)\\), esta probabilidad es conmutativa por lo que \\(\\mathbb P(\\mathcal X, \\mathcal Y)=\\mathbb P(\\mathcal Y, \\mathcal X).\\) En este momento se puede utilizar la definición de probabilidad condicional que es \\(\\mathbb P(\\mathcal Y, \\mathcal X)=\\mathbb P(\\mathcal Y \\mid \\mathcal X) \\mathbb P(\\mathcal X).\\) Utilizando estas ecuaciones el Teorema de Bayes queda como\n\\[\n\\mathbb P(\\mathcal Y \\mid \\mathcal X) = \\frac{ \\mathbb P(\\mathcal X \\mid \\mathcal Y) \\mathbb P(\\mathcal Y)}{\\mathbb P(\\mathcal X)},\n\\tag{2.1}\\]\ndonde al término \\(\\mathbb P(\\mathcal X \\mid \\mathcal Y)\\) se le conoce como verosimilitud, \\(\\mathbb P(\\mathcal Y)\\) es la probabilidad a priori y \\(\\mathbb P(\\mathcal X)\\) es la evidencia.\nEs importante mencionar que la evidencia se puede calcular mediante la probabilidad total, es decir:\n\\[\n\\mathbb P(\\mathcal X) = \\sum_{y \\in \\mathcal Y} \\mathbb P(\\mathcal X \\mid \\mathcal Y=y) \\mathbb P(\\mathcal Y=y).\n\\tag{2.2}\\]\n\n2.3.1 Problema Sintético\nCon el objetivo de entender el funcionamiento del Teorema de Bayes, esta sección presenta un problema sintético. El procedimiento es el siguiente, primero se generarán los datos, los cuales van a ser tres nubes de puntos generadas mediantes tres distribuciones gausianas multivariadas. Con estas tres nubes de puntos, se utilizará el Teorema de Bayes (Ecuación 2.1) para clasificar todos los puntos generados.\nEl primer paso es definir las tres distribuciones gausianas multivariadas, para este objetivo se usa la clase multivariate_normal como se muestra a continuación.\n\np1 = multivariate_normal(mean=[5, 5],\n                         cov=[[4, 0], [0, 2]])\np2 = multivariate_normal(mean=[1.5, -1.5],\n                         cov=[[2, 1], [1, 3]])\np3 = multivariate_normal(mean=[12.5, -3.5], \n                         cov=[[2, 3], [3, 7]])\n\nLos parámetros de la distribución son el vector de medías y la matriz de covarianza, para la primera distribución estos corresponden a \\(\\mathbf \\mu = [5, 5]^\\intercal\\) y\n\\[\n\\Sigma = \\begin{pmatrix}\n            4 & 0 \\\\\n            0 & 2 \\\\\n         \\end{pmatrix}.\n\\]\nUna vez definidas las distribuciones podemos generar números aleatoreos de las mismas, en el siguiente código se generar 1000 vectores aleatorios de las tres distribuciones.\n\nX_1 = p1.rvs(size=1000)\nX_2 = p2.rvs(size=1000)\nX_3 = p3.rvs(size=1000)\n\nPara graficar estas tres nubes de puntos se puede hacer uso del siguiente código, donde se hace uso de la librería pandas y seaborn para la generar la gráfica.\n\nD = np.concatenate((X_1, X_2, X_3))\nclase = [1] * 1000 + [2] * 1000 + [3] * 1000\nD = np.concatenate((D, np.atleast_2d(clase).T), axis=1)\ndf = pd.DataFrame(D, columns=['x', 'y', 'clase'])\nsns.set_style('whitegrid')\n_ = sns.relplot(data=df, kind='scatter', x='x',\n                y='y', hue='clase')     \n\n\n\n\n\n\n\nFigura 2.1: Muestras de 3 distribuciones Gausianas\n\n\n\n\n\nEl resultado del código anterior se muestra en la Figura 2.1, donde se puede visualizar las tres nubes de puntos, donde el color indica la clase.\n\n\n\n\n\n\nActividad\n\n\n\n\n\nGenerar una nube de puntos similar a la que se muestra en la Figura 2.2. Observar que ambos ejes de la figura están en el rango \\([-20, 20].\\)\n\n\n\n\n\n\n\n\nFigura 2.2: Distribución Gausiana\n\n\n\n\n\n\n\n\n\n\n2.3.2 Predicción\nEn esta sección se describe el primer ejemplo del paso 4 de la metodología general (ver Sección 1.2) de los algoritmos de aprendizaje supervisado. El algoritmo \\(f\\) mencionado en la metodología corresponde en este ejemplo al uso del Teorema de Bayes y las distribuciones p1, p2 y p3 y los correspondientes priors.\nQuitando la evidencia del Teorema de Bayes (Ecuación 2.1) se observa que \\(\\mathbb P(\\mathcal Y \\mid \\mathcal X) \\propto \\mathbb P(\\mathcal X \\mid \\mathcal Y) \\mathbb P(\\mathcal Y)\\). En el ejemplo creado se observa que \\(\\mathbb P(\\mathcal Y=1) = \\frac{1000}{3000},\\) las otras probabilidades a priori tienen el mismo valor, es decir, \\(\\mathbb P(\\mathcal Y=2) = \\mathbb P(\\mathcal Y=3) = \\frac{1}{3}.\\)\nLa verosimilitud está definida en las variables p1, p2 y p3; en particular en la función pdf, es decir, \\(\\mathbb P(\\mathcal X \\mid \\mathcal Y=1)\\) es p1.pdf, \\(\\mathbb P(\\mathcal X \\mid \\mathcal Y=2)\\) corresponde a p2.pdf y equivalentemente p3.pdf es la verosimilitud cuando \\(\\mathcal Y=3.\\)\nUtilizando esta información \\(\\mathbb P(\\mathcal X \\mid \\mathcal Y) \\mathbb P(\\mathcal Y)\\) se calcula de la siguiente manera.\n\nX = np.concatenate((X_1, X_2, X_3))\nposterior = (np.vstack([p1.pdf(X),\n                        p2.pdf(X), \n                        p3.pdf(X)]) * 1 / 3).T\n\nLa evidencia (Ecuación 2.2) es un factor normalizador que hace que las probabilidad sume a uno, el siguiente código calcula la evidencia, \\(\\mathbb P(\\mathcal X)\\)\n\nevidencia = posterior.sum(axis=1)\n\nFinalmente, \\(\\mathbb P(\\mathcal Y \\mid \\mathcal X)\\) se obtiene normalizando \\(\\mathbb P(\\mathcal X \\mid \\mathcal Y) \\mathbb P(\\mathcal Y)\\) que se puede realizar de la siguiente manera.\n\nposterior = posterior / np.atleast_2d(evidencia).T\n\nLa clase corresponde a la probabilidad máxima, en este caso se compara la probabilidad de \\(\\mathbb P(\\mathcal Y=1 \\mid \\mathcal X),\\) \\(\\mathbb P(\\mathcal Y=2 \\mid \\mathcal X)\\) y \\(\\mathbb P(\\mathcal Y=3 \\mid \\mathcal X)\\); y la clase es aquella que tenga mayor probabilidad. El siguiente código muestra este procedimiento, donde el primer paso es crear un arreglo para mapear el índice a la clase. El segundo paso es seleccionar la probabilidad máxima y después transformar el índice de la probabilidad máxima a la clase.\n\nclase = np.array([1, 2, 3])\nindice = posterior.argmax(axis=1)\nprediccion = clase[indice]\n\nEn la variable prediccion se tienen las predicciones de las clases, ahora se analizará si estas predicciones corresponden con la clase original que fue generada. Por la forma en que se generó X se sabe que los primero 1000 elementos pertenecen a la clase \\(1\\), los siguientes 1000 a la clase \\(2\\) y los restantes a la clase \\(3\\). A continuación se muestra el arreglo y que tiene esta estructura.\n\ny = np.array([1] * 1000 + [2] * 1000 + [3] * 1000)\n\nTeniendo las predicciones y los valores de reales de las clases, lo que se busca es visualizar los ejemplos que no fueron clasificados de manera correcta, el siguiente código muestra este procedimiento.\n\n_ = [dict(x=x, y=y, error=error) \n     for (x, y), error in zip(X, y != prediccion)]\ndf_error = pd.DataFrame(_)\nsns.set_style('whitegrid')\n_ = sns.relplot(data=df_error, kind='scatter',\n                x='x', y='y', hue='error')\n\n\n\n\n\n\n\nFigura 2.3: Error en problema de clasificación\n\n\n\n\n\nLa Figura 2.3 muestra todos los datos generados, en color azul se muestran aquellos datos que fueron correctamente clasificados y en color naranja (error igual a True) se muestran aquellos ejemplos donde el proceso de clasificación cometió un error.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Teoría de Decisión Bayesiana</span>"
    ]
  },
  {
    "objectID": "capitulos/02Teoria_Decision.html#sec-error-clasificacion",
    "href": "capitulos/02Teoria_Decision.html#sec-error-clasificacion",
    "title": "2  Teoría de Decisión Bayesiana",
    "section": "2.4 Error de Clasificación",
    "text": "2.4 Error de Clasificación\nEste ejemplo ayuda a ilustrar el caso donde, aun teniendo el modelo perfecto, este produce errores al momento de usarlo para clasificar. Se podía asumir que este error en clasificación iba a ocurrir desde el momento que las nubes de puntos de la clase 1 y 2 se traslapan como se observa en la Figura 2.1.\nEl ejemplo sirve también para ilustrar el 5 paso de la metodología general (ver Sección 1.2) de los algoritmos de aprendizaje supervisado que corresponde a medir el rendimiento de un modelo. Primero se empieza por medir el error promedio utilizando el siguiente código; donde el error es \\(0.0110\\).\n\nerror = (y != prediccion).mean()\n\nLa siguiente siguiente pregunta es conocer cuánto varia este error si se vuelve a realizar el muestreo de las distribuciones p1, p2 y p3. Una manera de conocer esta variabilidad de la medición del error es calculando su error estándar.\nEl error estándar (ver Sección A.1) está definido como \\(\\sqrt{\\mathbb V(\\hat \\theta)}\\) donde \\(\\hat \\theta\\) es el valor estimado, en este caso el error. El error es una variable aleatoria que sigue una distribución de Bernoulli, dado que para cada ejemplo tiene dos valores \\(1\\) que indica que en ese ejemplo el clasificador se equivocó y \\(0\\) cuando se predice la clase correcta. El parámetro de la distribución Bernoulli, \\(p\\), se estima como la media entonces el error estandar de \\(p\\) corresponde al error estándar de la media (ver Sección A.1.1), i.e., \\(\\sqrt{\\mathbb V(\\hat p)} = \\sqrt{\\frac{\\hat p (1 - \\hat p)}{N}},\\) dado que la varianza \\(\\sigma^2\\) de una distribución Bernoulli con parámetro \\(p\\) es \\(p (1 - p)\\). Para el ejemplo analizado el error estándar se calcula con la siguiente instrucción; teniendo un valor de \\(0.0019\\).\n\nse_formula = np.sqrt(error * (1 - error) / 3000)\n\nAunque el error estándar del parámetro \\(p\\) de la distribución Bernoulli si se puede calcular analíticamente, se usará la técnica de Bootstrap (ver Sección A.2) para ejemplificar aquellas estadísticas donde no se puede. Esta técnica requiere generar \\(B\\) muestras de \\(N\\) elementos con remplazo de los datos. En este caso los datos son los errores entre y y prediccion. Siguiendo el método presentado en la Sección A.2 se generan los índices para generar la muestra como se observa en la primera línea del siguiente código. En la segunda línea se hacen las \\(B\\) repeticiones las cuales consisten en calcular \\(\\hat p\\). Se puede observar como se usa directamente y y prediccion junto con el arreglo de índices s para calcular la media del error. Finalmente se calcula la desviación estándar de B (tercera línea) y ese valor corresponde al error estándar.\n\nS = np.random.randint(y.shape[0], size=(500, y.shape[0]))\nB = [(y[s] != prediccion[s]).mean() for s in S]\nse = np.std(B)\n\nEl error estándar, se, calculado es \\(0.0020\\).\nEl error estándar corresponde a la distribución que tiene la estimación del parámetro de interés, mediante Boostrap se simulo está distribución y con el siguiente código se puede observar su histograma, donde los datos estimados se encuentran en la lista B.\n\nsns.set_style('whitegrid')\n_ = sns.displot(B, kde=True)\n\n\n\n\n\n\n\nFigura 2.4: Distribución del error de clasificación\n\n\n\n\n\nLa Figura 2.4 muestra el histograma de la estimación del error en el ejemplo analizado.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Teoría de Decisión Bayesiana</span>"
    ]
  },
  {
    "objectID": "capitulos/02Teoria_Decision.html#riesgo",
    "href": "capitulos/02Teoria_Decision.html#riesgo",
    "title": "2  Teoría de Decisión Bayesiana",
    "section": "2.5 Riesgo",
    "text": "2.5 Riesgo\nComo es de esperarse, existen aplicaciones donde el dar un resultado equivocado tiene un mayor impacto dependiendo de la clase. Por ejemplo, en un sistema de autentificación, equivocarse dándole acceso a una persona que no tiene permisos, es mucho mas grave que no dejar entrar a una persona con los privilegios adecuados.\nUna manera de incorporar el costo de equivocarse en el proceso de selección de la clase es modelarlo como una función de riesgo, es decir, seleccionar la clase que tenga el menor riesgo. Para realizar este procedimiento es necesario definir \\(\\alpha_i\\) como la acción que se toma al seleccionar la clase \\(\\mathcal Y=i\\). Entonces el riesgo esperado por tomar la acción \\(\\alpha_i\\) está definido por:\n\\[R(\\alpha_i \\mid x) = \\sum_k \\lambda_{ik} \\mathbb P(\\mathcal Y=k \\mid \\mathcal X=x),\\]\ndonde \\(\\lambda_{ik}\\) es el costo de tomar la acción \\(i\\) en la clase \\(k\\).\nSuponiendo una función de costo \\(0/1\\), donde el escoger la clase correcta tiene un costo \\(0\\) y el equivocarse en cualquier caso tiene un costo \\(1\\) se define como:\n\\[\n\\lambda_{ik} = \\begin{cases} 0 \\text{ si } i = k\\\\ 1 \\text{ de lo contrario} \\end{cases}.\n\\]\nUsando la función de costo \\(0/1\\) el riesgo se define de la siguiente manera:\n\\[\n\\begin{split}\nR(\\alpha_i \\mid x) &= \\sum_k \\lambda_{ik} \\mathbb P(\\mathcal Y=k \\mid \\mathcal X=x) \\\\\n&= \\sum_{k\\neq i} \\mathbb P(\\mathcal Y=k \\mid \\mathcal X=x) \\\\\n&= 1 - \\mathbb P(\\mathcal Y_i \\mid \\mathcal X=x).\n\\end{split}\n\\]\nRecordando que \\(\\sum_k \\mathbb P(\\mathcal Y=k \\mid \\mathcal X=x) = 1\\). Por lo tanto en el caso de costo \\(0/1\\) se puede observar que mínimo riesgo corresponde a la clase más probable.\n\n2.5.1 Acción nula\nEn algunas ocasiones es importante diseñar un procedimiento donde la acción a tomar sea el avisar que no se puede tomar una acción de manera automática y que se requiere una intervención manual.\nLa primera idea podría ser incrementar el número de clases y asociar una clase a la intervención manual, sin embargo en este procedimiento estaríamos incrementando la complejidad del problema. Un procedimiento mas adecuado sería incrementar el número de acciones, \\(\\alpha\\) de tal manera que la acción \\(\\alpha_{K+1}\\) corresponda a la intervención esperada, esto para cualquier problema de \\(K\\) clases.\nLa extensión del costo \\(0/1\\) para este caso estaría definida como:\n\\[\n\\lambda_{ik} = \\begin{cases} 0 \\text{ si } i = k\\\\ \\lambda \\text{ si } i = K + 1 \\\\ 1 \\text{ de lo contrario} \\end{cases},\n\\]\ndonde \\(0 &lt; \\lambda &lt; 1\\).\nUsando la definición de riesgo, el riesgo de tomar la acción \\(\\alpha_{K+1}\\) es\n\\[\n\\begin{split}\nR(\\alpha_{K+1} \\mid x) &= \\sum_k^K\\lambda_{(K+1)k} \\mathbb P(\\mathcal Y=k \\mid \\mathcal X=x)\\\\ &= \\sum_k^K \\lambda \\mathbb P(\\mathcal Y=k \\mid \\mathcal X=x)\\\\\n&= \\lambda \\sum_k^K \\mathbb P(\\mathcal Y=k \\mid \\mathcal X=x) = \\lambda.\n\\end{split}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Teoría de Decisión Bayesiana</span>"
    ]
  },
  {
    "objectID": "capitulos/02Teoria_Decision.html#sec-seleccion-accion-nula",
    "href": "capitulos/02Teoria_Decision.html#sec-seleccion-accion-nula",
    "title": "2  Teoría de Decisión Bayesiana",
    "section": "2.6 Seleccionando la acción",
    "text": "2.6 Seleccionando la acción\nTomando en cuenta lo que hemos visto hasta el momento y usando como base el costo \\(0/1\\) que incluye la acción nula, se puede observar que el riesgo de seleccionar una clase está dado por \\(R(\\alpha_i \\mid x) = 1 - \\mathbb P(\\mathcal Y=i \\mid \\mathcal X=x)\\) y el riesgo de la acción nula es \\(R(\\alpha_{K+1} \\mid x) = \\lambda\\).\nEn esta circunstancias se selecciona la clase \\(\\hat y\\) si es la clase con la probabilidad máxima (i.e., \\(\\hat y = \\textsf{arg max}_k \\mathbb P(\\mathcal Y=k \\mid \\mathcal X=x)\\)) y además \\(\\mathbb P(\\mathcal Y=\\hat y \\mid \\mathcal X=x) &gt; 1 - \\lambda.\\)\n\n2.6.1 Ejemplo\nEl siguiente ejemplo ilustra el comportamiento de seleccionar la clase considerando que se tiene un riesgo en la acción nula. Lo primero es generar dos conjuntos de datos uno para la clase positiva y otro para la negativa, tal y como lo indica el siguiente código. p1 y p1 son distribuciones Gausianas, los elementos generados por p1 serán asociados a la clase positiva y los generados por p2 a la clase negativa.\n\np1 = multivariate_normal(mean=[5, 5],\n                              cov=[[20, -5],\n                                   [-5, 2]])\np2 = multivariate_normal(mean=[-5, 0],\n                              cov=[[20, 5],\n                                   [5, 2]])\nX1 = p1.rvs(size=1000)\nX2 = p2.rvs(size=1000)\nX = np.concatenate((X1, X2))\ny = np.array(['P'] * 1000 + ['N'] * 1000)\n\nLa Figura 2.5 muestra el conjunto de datos donde se realizará el ejemplo de seleccionar la clase considerando el riesgo.\n\n\nCódigo\ndf = pd.DataFrame(X, columns=['x', 'y'])\ndf['Clase'] = y\nsns.set_style('whitegrid')\nfig = sns.relplot(data=df, kind='scatter', x='x',\n                y='y', hue='Clase')\n# fig.ax.set_xlim(-20, 20)\n# fig.ax.set_ylim(-20, 20)\n\n\n\n\n\n\n\n\nFigura 2.5: Dos distribución Gausianas asociadas a dos clases\n\n\n\n\n\nPara no introducir ningún error adicional con la estimación de parámetros, se utilizan los parámetros con los que se generaron los datos para calcular \\(\\mathbb P(\\mathcal Y \\mid \\mathcal X)\\) tal y como lo muestra el siguiente código.\n\nposterior = np.c_[p1.pdf(X), p2.pdf(X)] * 1 / 2\nevidencia = posterior.sum(axis=1)\nposterior = posterior / np.c_[evidencia]\n\nHabiendo calculado la probabilidad de cada clase en todos los elementos de X, es momento de predecir la clase y calcular el error del proceso de clasificación.\n\nm = {0: 'P', 1: 'N'}\nhy = np.array([m[i]\n               for i in posterior.argmax(axis=1)])\nerror = (y != hy).mean()\n\nEl error que se tiene corresponde a 0.0105. El siguiente paso es definir un riesgo para la clase nula, e.g. \\(\\lambda = 0.2\\) y utilizarlo para saber cuales son los elementos que cumplen con la condición \\(\\mathbb P(\\mathcal Y=\\hat y \\mid \\mathcal X=x) &gt; 1 - \\lambda.\\) Estos elementos se guardan en la variable valid como muestra el siguiente código.\n\nriesgo = 0.20\nvalid = posterior.max(axis=1) &gt; 1 - riesgo\n\nUtilizando valid se puede calcular el error de aquellos elementos los cuales tiene una clase positiva o negativa. El siguiente código calcula el error.\n\nerror = (y[valid] != hy[valid]).mean()\n\nEl error obtenido con los elementos válidos es \\(0.0041\\), se puede observar que este error es menor que el error estimado con todos los elementos. El número de elementos válidos es 1966.\nPara completar el ejemplo, la Figura 2.6 muestra el conjunto de datos original, con las respectivas clases y se añade una etiqueta adicional para observar aquellos elementos que fueron incorrectamente clasificados. En la figura de la derecha se presentan solamente aquellos elementos para los cuales no se seleccionó la acción nula. Se pueden observar que todavía existen errores en la predicción y que la frontera entre la clase positiva y negativa es más explícita quitando los elementos asociados a la clase nula.\n\n\nCódigo\ny_error = y.copy()\ny_error[y != hy] = 'E'\ndf = pd.DataFrame(X, columns=['x', 'y'])\ndf['Clase'] = y_error\ndf['Conjunto'] = 'Original'\ndf2 = pd.DataFrame(X[valid], columns=['x', 'y'])\ndf2['Clase'] = y_error[valid]\ndf2['Conjunto'] = 'Reducido'\ncolor=sns.color_palette()\npalette = dict(P=color[0], N=color[1], E=color[3])\n\nsns.set_style('whitegrid')\nfig = sns.relplot(data=pd.concat((df, df2)), kind='scatter', x='x',\n                  palette=palette,\n                  y='y', hue='Clase', col='Conjunto')\n\n\n\n\n\n\n\n\nFigura 2.6: Predicción del conjunto original y el conjunto que elimina aquellos elementos que se asocian a la clase nula\n\n\n\n\n\n\n\n\n\n\n\nActividad\n\n\n\n\n\nUtilizando los siguientes parámetros \\(\\mathbf \\mu = [5, 5]^\\intercal = \\mu_1 = \\mu_2\\), \\(\\Sigma_1 = \\begin{pmatrix} 20 & -5 \\\\ -5 & 2 \\\\ \\end{pmatrix}\\) y \\(\\Sigma_2 = \\begin{pmatrix} 20 & -5 \\\\ -5 & 2 \\\\ \\end{pmatrix}\\), generar 1,000 muestras de las siguientes distribuciones \\(\\mathcal N_1(\\mu, \\Sigma_1)\\) y \\(\\mathcal N_2(\\mu, \\Sigma_2)\\). Asociar, a los datos generados por la primera distribución, la clase positiva y los elementos negativos corresponden a los 1,000 elementos generados mediante \\(\\mathcal N_2\\).\nLa actividad corresponde en calcular el error y el número de elementos que no están asociados a la clase nula cuando \\(\\lambda = 0.2\\). La Figura 2.7 muestra los datos generados y los datos válidos considerando el nivel de riesgo solicitado así como los errores en la predicción.\n\n\n\n\n\n\n\n\nFigura 2.7: Predicción del conjunto original y el conjunto que elimina aquellos elementos que se asocian a la clase nula",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Teoría de Decisión Bayesiana</span>"
    ]
  },
  {
    "objectID": "capitulos/03Parametricos.html",
    "href": "capitulos/03Parametricos.html",
    "title": "3  Métodos Paramétricos",
    "section": "",
    "text": "Paquetes usados\nEl objetivo de la unidad es conocer las características de los modelos paramétricos y aplicar máxima verosimilitud para estimar los parámetros del modelo paramétrico en problemas de regresión y clasificación.\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets import load_breast_cancer,\\\n                             load_diabetes\nfrom scipy.stats import norm, multivariate_normal\nfrom scipy.special import logsumexp\nfrom matplotlib import pylab as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Métodos Paramétricos</span>"
    ]
  },
  {
    "objectID": "capitulos/03Parametricos.html#sec-intro-03",
    "href": "capitulos/03Parametricos.html#sec-intro-03",
    "title": "3  Métodos Paramétricos",
    "section": "3.1 Introducción",
    "text": "3.1 Introducción\nExisten diferentes tipos de algoritmos que se puede utilizar para resolver problemas de aprendizaje supervisado y no supervisado. En particular, esta unidad se enfoca en presentar las técnicas que se pueden caracterizar como métodos paramétricos.\nLos métodos paramétricos se identifican por asumir que los datos provienen de una distribución de la cual se desconocen los parámetros y el procedimiento es encontrar los parámetros de la distribución que mejor modelen los datos. Una vez obtenidos los parámetros se cuenta con todos los elementos para utilizar el modelo y predecir la característica para la cual fue entrenada.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Métodos Paramétricos</span>"
    ]
  },
  {
    "objectID": "capitulos/03Parametricos.html#sec-metodologia-met-parametricos",
    "href": "capitulos/03Parametricos.html#sec-metodologia-met-parametricos",
    "title": "3  Métodos Paramétricos",
    "section": "3.2 Metodología",
    "text": "3.2 Metodología\nHasta el momento se han presentado ejemplos de los pasos 4 y 5 de la metodología general (ver Sección 1.2); esto fue en la Sección 2.3.2 y en la Sección 2.4. Esta sección complementa los ejemplos anteriores al utilizar todos pasos de la metodología general de aprendizaje supervisado (ver Sección 1.2). En particular se enfoca al paso 3 que corresponde al diseño del algoritmo \\(f\\) que modela el fenómeno de interés utilizando los datos \\(\\mathcal T \\subset \\mathcal D.\\)\nEl algoritmo \\(f\\) corresponde a asumir que los datos \\(\\mathcal D\\) provienen de una distribución \\(F\\) la cual tiene una serie de parámetros \\(\\theta\\) que son identificados con \\(\\mathcal T.\\)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Métodos Paramétricos</span>"
    ]
  },
  {
    "objectID": "capitulos/03Parametricos.html#sec-estimacion-parametros-gnal",
    "href": "capitulos/03Parametricos.html#sec-estimacion-parametros-gnal",
    "title": "3  Métodos Paramétricos",
    "section": "3.3 Estimación de Parámetros",
    "text": "3.3 Estimación de Parámetros\nSe inicia la descripción de métodos paramétricos presentando el procedimiento general para estimar los parámetros de una distribución. Se cuenta con un conjunto \\(\\mathcal D\\) donde los elementos \\(x \\in \\mathcal D\\) son \\(x \\in \\mathbb R^d\\). Los elementos \\(x \\in \\mathcal D\\) tienen un distribución \\(F\\), i.e., \\(x \\sim F\\), son independientes y \\(F\\) está definida por la función de densidad de probabilidad \\(f_{\\theta}\\), que a su vez está definida por \\(\\theta\\) parámetros. Utilizando \\(\\mathcal D\\) el objetivo es identificar los parámetros \\(\\theta\\) que hacen observar a \\(\\mathcal D\\) lo más probable.\n\n3.3.1 Verosimilitud\nUna solución para maximizar el observar \\(\\mathcal D\\) es maximizando la verosimilitud. La verosimilitud es la función distribución conjunta de los elementos en \\(\\mathcal D\\), i.e., \\(f_\\theta(x_1, x_2, \\ldots, x_N).\\) Considerando que la muestras son independientes entonces \\(f_\\theta(x_1, x_2, \\ldots, x_N) = \\prod_{x \\in \\mathcal D} f_\\theta (x).\\) La función de verosimilitud considera la ecuación anterior como una función de los parámetros \\(\\theta,\\) es decir,\n\\[\n\\mathcal L(\\theta) = \\prod_{x \\in \\mathcal D} f_\\theta (x),\n\\]\nsiendo el logaritmo de la verosimilitud\n\\[\n\\ell(\\theta) = \\log \\mathcal L(\\theta) = \\sum_{x \\in \\mathcal D} \\log f_\\theta (x).\n\\]\n\n\n3.3.2 Distribución de Bernoulli\nLa verosimilitud se ejemplifica con la identificación del parámetro \\(p\\) de una distribución Bernoulli. Una distribución Bernoulli modela dos estados, por un lado se tiene la clase negativa identificada por \\(0\\); identificando la clase positiva como \\(1\\). Entonces, la probabilidad de observar \\(1\\) es \\(\\mathbb P(X=1) = p\\) y \\(\\mathbb P(X=0) = 1 - p\\). Estas ecuaciones se pueden combinar para definir \\(f_\\theta(x) = p^x (1 - p)^{1-x}.\\)\nUtilizando el logaritmo de la verosimilitud se tiene:\n\\[\n\\ell(p) = \\sum_{i=1}^N \\log p^{x_i} (1 - p)^{1-x_i} = \\sum_{i=1}^N x_i \\log p + (1-x_i) \\log (1 - p).\n\\]\nRecordando que el máximo de \\(\\ell(\\mathcal p)\\) se obtiene cuando \\(\\frac{d}{dp} \\ell(\\mathcal p) = 0\\), entonces estimar \\(p\\) corresponde a resolver lo siguiente:\n\\[\n\\begin{split}\n\\frac{d}{dp} \\ell(\\mathcal p) &= 0 \\\\\n\\frac{d}{dp} [ \\sum_{i=1}^N x_i \\log p + (1-x_i) \\log (1 - p)] &= 0 \\\\\n\\frac{d}{d p} [ \\sum_{i=1}^N x_i \\log p + \\log (1 - p) (N - \\sum_{i=1}^N x_i) ] &= 0\\\\\n\\sum_{i=1}^N x_i \\frac{d}{d p} \\log \\mathcal p + (N - \\sum_{i=1}^N x_i) \\frac{d}{d p} \\log (1 - \\mathcal p) &= 0\\\\\n\\sum_{i=1}^N x_i \\frac{1}{p} + (N - \\sum_{i=1}^N x_i) \\frac{-1}{(1 - p)} &= 0\\\\\n\\end{split}\n\\]\nRealizando algunas operaciones algebraicas se obtiene:\n\\[\n\\hat p = \\frac{1}{N}\\sum_{i=1}^N x_i.\n\\]\n\n\n3.3.3 Ejemplo: Distribución Gausiana\nEsta sección sigue un camino práctico, presentando el código para estimar los parámetros de una distribución Gausiana donde se conocen todos los parámetros. La distribución se usa para generar 1000 muestras y después de esta población se estiman los parámetros; de estas manera se tienen todos los elementos para comparar los parámetros reales \\(\\theta\\) de los parámetros estimados \\(\\hat \\theta.\\)\nLa distribución que se usará se utilizó para generar un problema sintético (ver Sección 2.3.1) de tres clases. Los parámetros de la distribución son: \\(\\mathbf \\mu = [5, 5]^\\intercal\\) y \\(\\Sigma = \\begin{pmatrix} 4 & 0 \\\\ 0 & 2 \\\\ \\end{pmatrix}.\\) La siguiente instrucción se puede utilizar para generar 1000 muestras de esa distribución.\n\nD = multivariate_normal(mean=[5, 5], \n                        cov=[[4, 0], \n                             [0, 2]]).rvs(size=1000)\n\nLa media estimada de los datos en D se calcula usando la función np.mean de la siguiente manera\n\nmu = np.mean(D, axis=0)\n\n\n\ndonde el eje de operación es el primero que corresponde al índice \\(0.\\) La media estimada es: \\(\\hat \\mu = [5.0411, 5.0338]^\\intercal\\) con un error estándar (se) de \\([0.0644, 0.0467]^\\intercal\\) que se calcula con el siguiente código.\n\n\n\nse = np.std(D, axis=0) / np.sqrt(1000)\n\nHasta el momento se ha estimado \\(\\mu\\), falta por estimar \\(\\Sigma\\), que se puede realizar con la siguiente instrucción\n\ncov = np.cov(D, rowvar=False)\n\n\n\ndonde el parámetro rowvar indica la forma en que están proporcionados los datos. La estimación da los siguientes valores \\(\\hat \\Sigma = \\begin{pmatrix} 4.1524&0.0465 \\\\ 0.0465&2.1854 \\\\ \\end{pmatrix};\\) se puede observar que son similares al parámetro con que se simularon los datos.\n\n\nSiguiendo con la inercia de presentar el error estándar de cada estimación, en las siguientes instrucciones se presenta el error estándar de \\(\\hat \\Sigma\\), el cual se calcula utilizando la técnica de bootstrap (ver Sección A.2) implementada en el siguiente código.\n\nS = np.random.randint(D.shape[0],\n                      size=(500, D.shape[0]))\nB = [np.cov(D[s], rowvar=False) for s in S]\nse = np.std(B, axis=0)\n\n\n\nSe puede observar que la función np.cov se ejecuta utilizando la muestra indicada en la variable s. El error estándar (se) de \\(\\hat \\Sigma\\) corresponde a \\(\\begin{pmatrix} 0.1765&0.0910 \\\\ 0.0910&0.0955 \\\\ \\end{pmatrix}.\\) Se observa que los elementos fuera de la diagonal tienen un error estándar tal que el cero se encuentra en el intervalo \\(\\hat \\Sigma \\pm se;\\) lo cual indica que el cero es un valor factible. Lo anterior se puede verificar tomando en cuenta que se conoce \\(\\Sigma\\) y que el parámetro real es \\(0\\) para aquellos elementos fuera de la diagonal.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Métodos Paramétricos</span>"
    ]
  },
  {
    "objectID": "capitulos/03Parametricos.html#metodología-de-clasificación",
    "href": "capitulos/03Parametricos.html#metodología-de-clasificación",
    "title": "3  Métodos Paramétricos",
    "section": "3.4 Metodología de Clasificación",
    "text": "3.4 Metodología de Clasificación\nHabiendo descrito el proceso para estimar los parámetros de una distribución, por un lado se presentó de manera teórica con la distribución Bernoulli (ver Sección 3.3.2) y de manera práctica con una distribución Gausiana (ver Sección 3.3.3), se está en la posición de usar todos estos elementos para presentar el proceso completo de clasificación. La metodología general de aprendizaje supervisado (ver Sección 1.2) está definida por cinco pasos, estos pasos se especializan para el problema de clasificación y regresión, utilizando modelos paramétricos, de la siguiente manera.\n\nTodo empieza con un conjunto de datos \\(\\mathcal D\\) que tiene la información del fenómeno de interés.\nSe selecciona el conjunto \\(\\mathcal T \\subset \\mathcal D,\\) el procedimiento se describe en la Sección 3.5.\nSe diseña un algoritmo, \\(f\\), el cual se basa en un modelo (ver Sección 3.6) y la estimación de sus parámetros (ver Sección 3.6.1) utilizando \\(\\mathcal T.\\)\nEn la Sección 3.6.2 se describe el uso de \\(f\\) para predecir.\nLa Sección 3.6.3 muestra el procedimiento para medir el rendimiento utilizando un conjunto de prueba (ver Sección 3.5).\n\nLa metodología de clasificación se ilustra utilizando el problema sintético (ver Sección 2.3.1) de tres clases que se presentó en el Capítulo 2.\n\n\n\n\n\n\nProblema sintético\n\n\n\n\n\nCódigo\nseed = 0\np1 = multivariate_normal(mean=[5, 5],\n                         cov=[[4, 0], [0, 2]],\n                         seed=seed)\np2 = multivariate_normal(mean=[1.5, -1.5],\n                         cov=[[2, 1], [1, 3]],\n                         seed=seed)\np3 = multivariate_normal(mean=[12.5, -3.5], \n                         cov=[[2, 3], [3, 7]],\n                         seed=seed)\nX_1 = p1.rvs(size=1000)\nX_2 = p2.rvs(size=1000)\nX_3 = p3.rvs(size=1000)                         \n\n\n\n\nEspecíficamente, las entradas que definían a cada clase están en la variables X_1, X_2 y X_3. Entonces las clases se pueden colocar en la variable y tal como se indica a continuación.\n\nX = np.concatenate((X_1, X_2, X_3))\ny = np.array([1] * 1000 + [2] * 1000 + [3] * 1000)\n\nLas variables X y y contiene la información del conjunto \\(\\mathcal D = (\\mathcal X, \\mathcal Y)\\) donde cada renglón de X es una realización de la variable aleatoria \\(\\mathcal X\\) y equivalentemente cada elemento en y es una realización de \\(\\mathcal Y.\\)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Métodos Paramétricos</span>"
    ]
  },
  {
    "objectID": "capitulos/03Parametricos.html#sec-conjunto-entre-prueba",
    "href": "capitulos/03Parametricos.html#sec-conjunto-entre-prueba",
    "title": "3  Métodos Paramétricos",
    "section": "3.5 Conjunto de Entrenamiento y Prueba",
    "text": "3.5 Conjunto de Entrenamiento y Prueba\nEn la Sección 3.3.3 se había utilizado a \\(\\mathcal D\\) en el procedimiento de maximizar la verosimilitud, esto porque el objetivo en ese procedimiento era estimar los parámetros de la distribución. Pero el objetivo en aprendizaje supervisado es diseñar un algoritmo (función en este caso) que modele la relación entre \\(\\mathcal X\\) y \\(\\mathcal Y\\). Para conocer esto es necesario medir el rendimiento del algoritmo en instancias que no han sido vistas en el entrenamiento.\nEn consecuencia, se requieren contar con datos para medir el rendimiento, a este conjunto de datos se le conoce como el conjunto de prueba, \\(\\mathcal G\\). \\(\\mathcal G\\) se crea a partir de \\(\\mathcal D\\) de tal manera que \\(\\mathcal G \\cap \\mathcal T = \\emptyset\\) y \\(\\mathcal D =  \\mathcal G \\cup \\mathcal T.\\) La siguiente instrucción se puede utilizar para dividir la generación de estos conjuntos a partir de \\(\\mathcal D.\\)\n\nT, G, y_t, y_g = train_test_split(X, y,\n                                  test_size=0.2,\n                                  random_state=seed)\n\nEl parámetro test_size indica la proporción del tamaño de conjunto \\(\\mathcal G\\) en relación con el conjunto \\(\\mathcal D.\\)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Métodos Paramétricos</span>"
    ]
  },
  {
    "objectID": "capitulos/03Parametricos.html#sec-model-clasificacion",
    "href": "capitulos/03Parametricos.html#sec-model-clasificacion",
    "title": "3  Métodos Paramétricos",
    "section": "3.6 Clasificador",
    "text": "3.6 Clasificador\nEl inicio de métodos paramétricos es el Teorema de Bayes (Ecuación 2.1) \\(\\mathbb P(\\mathcal Y \\mid \\mathcal X) = \\frac{ \\mathbb P(\\mathcal X \\mid \\mathcal Y) \\mathbb P(\\mathcal Y)}{\\mathbb P(\\mathcal X)}\\) donde se usa la verosimilitud \\(\\mathbb P(\\mathcal X \\mid \\mathcal Y)\\) y el prior \\(\\mathbb P(\\mathcal Y)\\) para definir la probabilidad a posteriori \\(\\mathbb P(\\mathcal Y \\mid \\mathcal X)\\). En métodos paramétricos se asume que se puede modelar la verosimilitud con una distribución particular, que por lo generar es una distribución Gausiana multivariada. Es decir, la variable aleatoria \\(\\mathcal X\\) dado \\(\\mathcal Y\\) (i.e., \\(\\mathcal X_{\\mid \\mathcal Y}\\)) es \\(\\mathcal X_{\\mid \\mathcal Y} \\sim \\mathcal N(\\mu_{\\mathcal Y}, \\Sigma_{\\mathcal Y}),\\) donde se observa que los parámetros de la distribución Gausiana dependen de la variable aleatoria \\(\\mathcal Y\\) y estos pueden ser identificados cuando \\(\\mathcal Y\\) tiene un valor específico.\n\n3.6.1 Estimación de Parámetros\nDado que por definición del problema (ver Sección 2.3.1) se conoce que la verosimilitud para cada clase proviene de una Gausiana, i.e., \\(\\mathcal X_{\\mid \\mathcal Y} \\sim \\mathcal N(\\mu_{\\mathcal Y}, \\Sigma_{\\mathcal Y}),\\) en esta sección se estimarán los parámetros utilizando este conocimiento.\nEl primer paso en la estimación de parámetros es calcular el prior \\(\\mathbb P(\\mathcal Y)\\), el cual corresponde a clasificar el evento sin observar el valor de \\(\\mathcal X.\\) Esto se puede modelar mediante una distribución Categórica con parámetros \\(p_i\\) donde \\(\\sum_i^K p_i = 1\\). Estos parámetros se pueden estimar utilizando la función np.unique de la siguiente manera\n\nlabels, counts = np.unique(y_t, return_counts=True)\nprior = counts / counts.sum()\n\nLa variable prior contiene en el primer elemento \\(\\mathbb P(\\mathcal Y=1) = 0.3179,\\) en el segundo \\(\\mathbb P(\\mathcal Y=2) = 0.3387\\) y en el tercero \\(\\mathbb P(\\mathcal Y=3) = 0.3433\\) que es aproximadamente \\(\\frac{1}{3}\\) el cual es el valor real del prior.\nSiguiendo los pasos en estimación de parámetros de una Gausiana (Sección 3.3.3) se pueden estimar los parámetros para cada Gausiana dada la clase. Es decir, se tiene que estimar los parámetros \\(\\mu\\) y \\(\\Sigma\\) para la clase \\(1\\), \\(2\\) y \\(3.\\) El algoritmo de clasificación que estima \\(\\mu\\) y \\(\\Sigma\\) para cada clase se le conoce como Analizador Discriminante Cuadrático implementando en la clase QuadraticDiscriminantAnalysis.\nUna implementación directa para la estimación de los parámetros se puede realizar iterando por las etiquetas contenidas en la variable labels y seleccionando los datos en T que corresponden a la clase analizada, ver el uso de la variable mask en el slice de la línea 4 y 5. Después se inicializa una instancia de la clase multivariate_normal para ser utilizada en el cómputo de la función de densidad de probabilidad. El paso final es guardar las instancias de las distribuciones en la lista likelihood.\n\nlikelihood = []\nfor k in labels:\n    mask = y_t == k\n    mu = np.mean(T[mask], axis=0)\n    cov = np.cov(T[mask], rowvar=False)\n    likelihood_k = multivariate_normal(mean=mu, cov=cov)\n    likelihood.append(likelihood_k)\n\n\n\nLos valores estimados para la media, en cada clase son: \\(\\hat \\mu_1 = [5.0267, 4.9626]^\\intercal,\\) \\(\\hat \\mu_2 = [1.5687, -1.4642]^\\intercal\\) y \\(\\hat \\mu_3 = [12.5188, -3.4715]^\\intercal\\). Para las matrices de covarianza, los valores estimados corresponden a \\(\\hat \\Sigma_1 = \\begin{pmatrix} 3.8108 & -0.0363\\\\-0.0363 & 1.9319 \\\\ \\end{pmatrix},\\) \\(\\hat \\Sigma_2 = \\begin{pmatrix} 1.8221 & 0.8862\\\\0.8862 & 2.8153 \\\\ \\end{pmatrix}\\) y \\(\\hat \\Sigma_3 = \\begin{pmatrix} 1.9043 & 2.8677\\\\2.8677 & 6.7392 \\\\ \\end{pmatrix}.\\)\n\n\nEstas estimaciones se pueden comparar con los parámetros reales (Sección 2.3.1). También se puede calcular su error estándar para identificar si el parámetro real, \\(\\theta\\), se encuentra en el intervalo definido por \\(\\hat \\theta - 2\\hat{se} \\leq \\hat \\theta \\leq \\hat \\theta + 2 \\hat{se}\\) que corresponde aproximadamente al 95% de confianza asumiendo que la distribución de la estimación del parámetro es Gausiana.\n\n\n\n\n\n\nNota\n\n\n\nEl código anterior tiene el fin de explicar el procedimiento para estimar los parámetros, la clase QuadraticDiscriminantAnalysis implementa diferentes métodos de estimación y se puede utilizar con el siguiente código.\n\nqda = QuadraticDiscriminantAnalysis(store_covariance=True).fit(T, y_t)\n\nLos parámetros \\(\\mu\\) se encuentran en el siguiente atributo. Se puede observar que los valores estimados por el método explicado y el implementado en QDA es el mismo.\n\nqda.means_\n\narray([[ 5.0267,  4.9626],\n       [ 1.5687, -1.4642],\n       [12.5188, -3.4715]])\n\n\nLos parámetros estimados para \\(\\Sigma_1\\) se pueden obtener en el siguiente atributo\n\nqda.covariance_[0]\n\narray([[ 3.8108, -0.0363],\n       [-0.0363,  1.9319]])\n\n\nSe observa que los valores son equivalentes entre los dos procedimientos, es importante mencionar que estos parámetros solamente están disponibles si la clase se inicializa con el parámetro store_covariance en verdadero.\n\n\n\n\n3.6.2 Predicción\nUna vez que se tiene la función que modela los datos, se está en condiciones de utilizarla para predecir (ver Sección 2.3.2) nuevos datos.\nEn esta ocasión se organiza el procedimiento de predicción en diferentes funciones, la primera función recibe los datos a predecir X y los componentes del modelo, que son la verosimilitud (likelihood) y el prior. La función calcula \\(\\mathbb P(\\mathcal Y=y \\mid \\mathcal X=x)\\) que es la probabilidad de cada clase dada la entrada \\(x\\). Se puede observar en la primera línea que se usa la función de densidad de probabilidad (pdf) para cada clase y esta se multiplica por el prior y en la tercera línea se calcula la evidencia. Finalmente, se regresa el a posteriori.\n\ndef predict_prob(X, likelihood, prior):\n    likelihood = [m.pdf(X) for m in likelihood]\n    posterior = np.vstack(likelihood).T * prior\n    evidence = posterior.sum(axis=1)\n    return posterior / np.atleast_2d(evidence).T\n\nLa función predict_proba se utiliza como base para predecir la clase, para la cual se requiere el mapa entre índices y clases que se encuentra en la variable labels. Se observa que se llama a la función predict_proba y después se calcula el argumento que tiene la máxima probabilidad regresando la etiqueta asociada.\n\ndef predict(X, likelihood, prior, labels):\n    _ = predict_prob(X, likelihood, prior)\n    return labels[np.argmax(_, axis=1)]\n\n\n\n\n\n\n\nNota\n\n\n\nLa predicción en la clase QuadraticDiscriminantAnalysis se puede realizar invocando al siguiente método tal y como se muestra en la siguiente linea.\n\nqda_hy = qda.predict(G)\n\nLa probabilidad se puede obtener utilizando el método predict_proba.\n\nqda_prob = qda.predict_proba(G)\n\n\n\n\n\n3.6.3 Rendimiento\nEl rendimiento del algoritmo se mide en el conjunto de prueba G, utilizando como medida el error de clasificación (Sección 2.4). El primer paso es predecir las clases de los elementos en G, utilizando la función predict que fue diseñada anteriormente. Después se mide el error, con la instrucción de la segunda línea.\n\nhy = predict(G, likelihood, prior, labels)\nerror = (y_g != hy).mean()\n\nEl error que tiene el algoritmo en el conjunto de prueba es \\(0.0117\\).\n\n\n\n\n\n\nNota\n\n\n\nEl error utilizado qda_hy corresponde a \\(0.0117.\\)\n\n\n\n\n\n\n\n\nActividad\n\n\n\n\n\nUtilizando la probabilidad en el conjunto de prueba, que se tiene en la variable qda_prob, calcular la variación del número de elementos que son asociados a la acción nula cuando se varía el nivel de riesgo (ver Sección 2.6), incluir en la figura o en una figura adicional, la dinámica del error en el conjunto de prueba para los elementos válidos. La Figura 3.1 muestra el resultado de este proceso. Se observa como van disminuyendo el número de elementos asociados a la acción nula cuando el riesgo se incrementa y al mismo tiempo como el error aumenta.\n\n\n\n\n\n\n\n\nFigura 3.1: Variación del número de elementos que seleccionan la acción nula y el error en el conjunto de prueba respecto al riesgo\n\n\n\n\n\n\n\n\nPara calcular el error estándar se utiliza el siguiente código\n\nse_formula = np.sqrt(error * (1 - error) / y_g.shape[0])\n\ndando un valor de \\(0.0044.\\)\n\n\n\n\n\n\nActividad\n\n\n\n\n\nGenerar la distribución del error utilizando el método de Bootstrap (ver Sección A.2), tal y como se muestra en la Figura 3.2.\n\n\n\n\n\n\n\n\nFigura 3.2: Distribución del error\n\n\n\n\n\nEl error estándar calculado con los datos mostrados en la figura anterior es \\(0.0045\\)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Métodos Paramétricos</span>"
    ]
  },
  {
    "objectID": "capitulos/03Parametricos.html#sec-cl-bayesiano-ingenuo",
    "href": "capitulos/03Parametricos.html#sec-cl-bayesiano-ingenuo",
    "title": "3  Métodos Paramétricos",
    "section": "3.7 Clasificador Bayesiano Ingenuo",
    "text": "3.7 Clasificador Bayesiano Ingenuo\nUno de los clasificadores mas utilizados, sencillo de implementar y competitivo, es el clasificador Bayesiano Ingenuo. En la Sección 3.6 se asumió que la variable aleatoria \\(\\mathcal X = (\\mathcal X_1, \\mathcal X_2, \\ldots, \\mathcal X_d)\\) dado \\(\\mathcal Y\\) (\\(\\mathcal X_{\\mid \\mathcal Y}\\)) es \\(\\mathcal X_{\\mid \\mathcal Y} \\sim \\mathcal N(\\mu_{\\mathcal Y}, \\Sigma_{\\mathcal Y}),\\) donde \\(\\mu_{\\mathcal Y} \\in \\mathbb R^d\\), \\(\\Sigma_{\\mathcal Y} \\in \\mathbb R^{d \\times d}\\) y \\(f(\\mathcal X_1, \\mathcal X_2, \\ldots, \\mathcal X_d)\\) es la función de densidad de probabilidad conjunta.\nEn el clasificador Bayesiano Ingenuo se asume que las variables \\(\\mathcal X_i\\) y \\(\\mathcal X_j\\) para \\(i \\neq j\\) son independientes, esto trae como consecuencia que \\(f(\\mathcal X_1, \\mathcal X_2, \\ldots, \\mathcal X_d) = \\prod_i^d f(\\mathcal X_i).\\) Esto quiere decir que cada variable está definida como una Gausina donde se tiene que identificar \\(\\mu\\) y \\(\\sigma^2.\\)\nLa estimación de los parámetros de estas distribuciones se puede realizar utilizando un código similar siendo la única diferencia que en se calcula \\(\\sigma^2\\) de cada variable en lugar de la covarianza \\(\\Sigma\\), esto se puede observar en la quinta línea donde se usa la función np.var en el primer eje. El resto del código es equivalente al usado en la Sección 3.6.1.\n\nlikelihood = []\nfor k in labels:\n    mask = y_t == k\n    mu = np.mean(T[mask], axis=0)\n    var = np.var(T[mask], axis=0, ddof=1)\n    likelihood_k = multivariate_normal(mean=mu, cov=var)\n    likelihood.append(likelihood_k)\n\n\n\nLos parámetros estimados en la versión ingenua son equivalentes con respecto a las medias, i.e., \\(\\hat \\mu_1 = [5.0267, 4.9626]^\\intercal\\), \\(\\hat \\mu_2 = [1.5687, -1.4642] ^\\intercal\\) y \\(\\hat \\mu_3 = [12.5188, -3.4715]^\\intercal\\). La diferencia se puede observar en las varianzas, que a continuación se muestran como matrices de covarianza para resaltar la diferencia, i.e., \\(\\hat \\Sigma_1 = \\begin{pmatrix} 3.8108 & 0.0000\\\\0.0000 & 1.9319 \\\\ \\end{pmatrix}\\), \\(\\hat \\Sigma_2 = \\begin{pmatrix} 1.8221 & 0.0000\\\\0.0000 & 2.8153 \\\\ \\end{pmatrix}\\) y \\(\\hat \\Sigma_3 = \\begin{pmatrix} 1.9043 & 0.0000\\\\0.0000 & 6.7392 \\\\ \\end{pmatrix}\\) se observa como los elementos fuera de la diagonal son ceros, lo cual indica la independencia entra las variables de entrada.\n\n\nFinalmente, el código para predecir se utiliza el código descrito en la Sección 3.6.2 dado que el modelo está dado en las variables likelihood y prior.\n\n\nEl error del clasificador Bayesiano Ingenuo, en el conjunto de prueba, es de \\(0.01\\) y su error estándar (se_formula) es \\(0.0041.\\)\n\n\n\n\n\n\n\n\nNota\n\n\n\nEl código anterior tiene la finalidad de explicar la estimación de parámetros del Clasificador Bayesiano Ingenuo. Este procedimiento se encuentra en la clase GaussianNB, en ese paquete se pueden encontrar implementaciones con otras distribuciones.\nEl siguiente código muestra su uso.\n\nnaive = GaussianNB().fit(T, y_t)\n\nLos parámetros \\(\\mu\\) se encuentran se pueden consultar con la siguiente instrucción\n\nnaive.theta_\n\narray([[ 5.0267,  4.9626],\n       [ 1.5687, -1.4642],\n       [12.5188, -3.4715]])\n\n\ny \\(\\sigma^2\\) en\n\nnaive.var_\n\narray([[3.8058, 1.9293],\n       [1.8199, 2.8119],\n       [1.902 , 6.731 ]])",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Métodos Paramétricos</span>"
    ]
  },
  {
    "objectID": "capitulos/03Parametricos.html#sec-ejemplo-breast-cancer-wisconsin",
    "href": "capitulos/03Parametricos.html#sec-ejemplo-breast-cancer-wisconsin",
    "title": "3  Métodos Paramétricos",
    "section": "3.8 Ejemplo: Breast Cancer Wisconsin",
    "text": "3.8 Ejemplo: Breast Cancer Wisconsin\nEsta sección ilustra el uso del clasificador Bayesiano al generar dos modelos (Clasificador Bayesiano (mejor conocido como el algoritmo de Análisis Discriminante Cuadrático) y Bayesiano Ingenuo) del conjunto de datos de Breast Cancer Wisconsin. Estos datos se pueden obtener utilizando la función load_breast_cancer tal y como se muestra a continuación.\n\nX, y = load_breast_cancer(return_X_y=True)\n\nEl primer paso es contar con los conjuntos de entrenamiento y prueba para poder realizar de manera completa la evaluación del proceso de clasificación. Esto se realiza ejecutando la siguiente instrucción.\n\nT, G, y_t, y_g = train_test_split(X, y, test_size=0.2,\n                                  random_state=seed)\n\n\n3.8.1 Entrenamiento\nLos dos modelos que se utilizarán será el clasificador de Análisis Discriminante Cuadrático y Bayesiano Ingenuo, utilizando las clases QuadraticDiscriminantAnalysis y GaussianNB. Las siguientes dos instrucciones inicializan estos dos clasificadores.\n\nqda = QuadraticDiscriminantAnalysis().fit(T, y_t)\nnaive = GaussianNB().fit(T, y_t)\n\n\n\n3.8.2 Predicción\nHabiendo definido los dos clasificadores, las predicciones del conjunto de prueba se realiza de la siguiente manera.\n\nhy_qda = qda.predict(G)\nhy_naive = naive.predict(G)\n\n\n\n3.8.3 Rendimiento\nEl rendimiento de ambos clasificadores se calcula de la siguiente manera\n\nerror_qda = (y_g != hy_qda).mean()\nerror_naive = (y_g != hy_naive).mean()\n\nEl clasificador Bayesiano Gausiano tiene un error de \\(0.0439\\) y el error de Bayesiano Ingenuo es \\(0.0702.\\) Se ha visto que el error es una variable aleatoria, entonces la pregunta es saber si esta diferencia en rendimiento es significativa o es una diferencia que proviene de la aleatoriedad de los datos.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Métodos Paramétricos</span>"
    ]
  },
  {
    "objectID": "capitulos/03Parametricos.html#diferencias-en-rendimiento",
    "href": "capitulos/03Parametricos.html#diferencias-en-rendimiento",
    "title": "3  Métodos Paramétricos",
    "section": "3.9 Diferencias en Rendimiento",
    "text": "3.9 Diferencias en Rendimiento\nUna manera de ver si existe una diferencia en rendimiento es calcular la diferencia entre los dos errores de clasificación, esto es\n\nnaive = (y_g != hy_naive).mean()\ncompleto = (y_g != hy_qda).mean()\nif naive &gt; completo:\n    diff = naive - completo\nelse:\n    diff = completo - naive\n\nque tiene un valor de \\(0.0263\\). De la misma manera que se ha utilizado la técnica de bootstrap (Sección A.2) para calcular el error estándar de la media, se puede usar para estimar el error estándar de la diferencia en rendimiento. El siguiente código muestra el procedimiento para estimar este error estándar.\n\nS = np.random.randint(y_g.shape[0],\n                      size=(500, y_g.shape[0]))\nif naive &gt; completo:\n    diff_f = lambda s: (y_g[s] != hy_naive[s]).mean() -\\\n                       (y_g[s] != hy_qda[s]).mean()\nelse:\n    diff_f = lambda s: (y_g[s] != hy_qda[s]).mean() -\\\n                       (y_g[s] != hy_naive[s]).mean()\nB = [diff_f(s) for s in S]\nse = np.std(B, axis=0)\n\nEl error estándar de la diferencia de rendimiento es de \\(0.0190\\), una procedimiento simple para saber si la diferencia observada es significativa, es dividir la diferencia entre su error estándar dando un valor de \\(1.3821\\). En el caso que el valor absoluto fuera igual o superior a 2 se sabría que la diferencia es significativa con una confianza de al menos 95%, esto asumiendo que la diferencia se comporta como una distribución Gausiana.\nEl histograma de los datos que se tienen en la variable B se observa en la Figura 3.3. Se puede ver que la forma del histograma asemeja una distribución Gausiana y que el cero esta en el cuerpo de la Gausiana, tal y como lo confirmó el cociente que se calculado.\n\n\nCódigo\nsns.set_style('whitegrid')\nfig = sns.displot(B, kde=True)\n\n\n\n\n\n\n\n\nFigura 3.3: Diferencia entre Clasificadores Bayesianos\n\n\n\n\n\nSe puede conocer la probabilidad de manera exacta calculando el área bajo la curva a la izquierda del cero, este sería el valor \\(p\\), si este es menor a 0.05 quiere decir que se tiene una confianza mayor del 95% de que los rendimientos son diferentes. Para este ejemplo, el área se calcula con el siguiente código\n\ndist = norm(loc=diff, scale=se)\np_value = dist.cdf(0)\n\nteniendo el valor de \\(0.0835\\), lo que significa que se tiene una confianza del \\(91\\)% de que los dos algoritmos son diferentes considerando el error de clasificación como medida de rendimiento.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Métodos Paramétricos</span>"
    ]
  },
  {
    "objectID": "capitulos/03Parametricos.html#sec-regresion-ols",
    "href": "capitulos/03Parametricos.html#sec-regresion-ols",
    "title": "3  Métodos Paramétricos",
    "section": "3.10 Regresión",
    "text": "3.10 Regresión\nHasta este momento se han revisado métodos paramétricos en clasificación, ahora es el turno de abordar el problema de regresión. La diferencia entre clasificación y regresión como se describió en la Sección 1.4 es que en regresión \\(\\mathcal Y \\in \\mathbb R.\\)\nEl procedimiento de regresión que se describe en esta sección es regresión de Mínimos Cuadrados Ordinaria (OLS -Ordinary Least Squares-), en el cual se asume que \\(\\mathcal Y \\sim \\mathcal N(\\mathbf w \\cdot \\mathbf x + \\epsilon, \\sigma^2)\\), de tal manera que \\(y = \\mathbb E[\\mathcal N(\\mathbf w \\cdot \\mathbf x + \\epsilon, \\sigma^2)].\\)\nTrabajando con \\(y = \\mathbb E[\\mathcal N(\\mathbf w \\cdot \\mathbf x + \\epsilon, \\sigma^2)],\\) se considera lo siguiente \\(y = \\mathbb E[\\mathcal N(\\mathbf w \\cdot \\mathbf x, 0) + \\mathcal N(0, \\sigma^2)]\\) que implica que el error \\(\\epsilon\\) es independiente de \\(\\mathbf x\\), lo cual se transforma en \\(y = \\mathbf w \\cdot \\mathbf x + \\mathbb E[\\epsilon],\\) donde \\(\\mathbb E[\\epsilon]=0.\\) Por lo tanto \\(y = \\mathbf w \\cdot \\mathbf x.\\)\nLa función de densidad de probabilidad de una Gausiana corresponde a\n\\[\nf(\\alpha) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\exp{-\\frac{1}{2} (\\frac{\\alpha -  \\mu}{\\sigma})^2},\n\\]\ndonde \\(\\alpha\\), en el caso de regresión, corresponde a \\(\\mathbf w \\cdot \\mathbf x\\) (i.e., \\(\\alpha = \\mathbf w \\cdot \\mathbf x\\)).\nUtilizando el método de verosimilitud el cual corresponde a maximizar\n\\[\n\\begin{split}\n\\mathcal L(\\mathbf w, \\sigma) &= \\prod_{(\\mathbf x, y) \\in \\mathcal D} f(\\mathbf w \\cdot \\mathbf x) \\\\\n&= \\prod_{(\\mathbf x, y) \\in \\mathcal D} \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp{(-\\frac{1}{2} (\\frac{\\mathbf w \\cdot \\mathbf x -  y}{\\sigma})^2)} \\\\\n\\ell(\\mathbf w, \\sigma) &= \\sum_{(\\mathbf x, y) \\in \\mathcal D}\\log \\frac{1}{\\sigma \\sqrt{2\\pi}}  -\\frac{1}{2} (\\frac{\\mathbf w \\cdot \\mathbf x -  y}{\\sigma})^2 \\\\\n&= - \\frac{1}{2\\sigma^2}  \\sum_{(\\mathbf x, y) \\in \\mathcal D} (\\mathbf w \\cdot \\mathbf x -  y)^2 - N \\log \\frac{1}{\\sigma \\sqrt{2\\pi}}.\n\\end{split}\n\\]\nEl valor de cada parámetro se obtiene al calcular la derivada parcial con respecto al parámetro de interés, entonces se resuelven \\(d\\) derivadas parciales para cada uno de los coeficientes \\(\\mathbf w\\). En este proceso se observar que el término \\(N \\log \\frac{1}{\\sigma \\sqrt{2\\pi}}\\) no depende de \\(\\mathbf w\\) entonces no afecta el máximo siendo una constante en el proceso de derivación y por lo tanto se desprecia. Lo mismo pasa para la constante \\(\\frac{1}{2\\sigma^2}\\). Una vez obtenidos los parámetros \\(\\mathcal w\\) se obtiene el valor \\(\\sigma.\\)\nUna manera equivalente de plantear este problema es como un problema de algebra lineal, donde se tiene una matriz de observaciones \\(X\\) que se construyen con las variables \\(\\mathbf x\\) de \\(\\mathcal X,\\) donde cada renglón de \\(X\\) es una observación, y el vector dependiente \\(\\mathbf y\\) donde cada elemento es la respuesta correspondiente a la observación.\nViéndolo como un problema de algebra lineal lo que se tiene es\n\\[\nX \\mathbf w = \\mathbf y,\n\\]\ndonde para identificar \\(\\mathbf w\\) se pueden realizar lo siguiente\n\\[\nX^\\intercal X \\mathbf w = X^\\intercal \\mathbf y.\n\\]\nDespejando \\(\\mathbf w\\) se tiene\n\\[\n\\mathbf w = (X^\\intercal X)^{-1} X^\\intercal \\mathbf y.\n\\]\nPreviamente se ha presentado el error estándar de cada parámetro que se ha estimado, en caso de la regresión el error estándar (Sección A.1.3) de \\(\\mathcal w_j\\) es \\(\\sigma \\sqrt{(X^\\intercal X)^{-1}_{jj}}.\\)\n\n3.10.1 Ejemplo: Diabetes\nEsta sección ilustra el proceso de resolver un problema de regresión utilizando OLS. El problema a resolver se obtiene mediante la función load_diabetes de la siguiente manera\n\nX, y = load_diabetes(return_X_y=True)\n\nEl siguiente paso es generar los conjuntos de entrenamiento y prueba (Sección 3.5)\n\nT, G, y_t, y_g = train_test_split(X, y, test_size=0.2,\n                                  random_state=seed)\n\nCon el conjunto de entrenamiento T y y_t se estiman los parámetros de la regresión lineal tal y como se muestra a continuación\n\nm = LinearRegression().fit(T, y_t)\n\nLos primeros tres coeficientes de la regresión lineal son \\(\\mathbf w=[-35.55, -243.17, 562.76, \\ldots]\\) y \\(w_0=152.54\\) lo cual se encuentran en las siguientes variables\n\nw = m.coef_\nw_0 = m.intercept_\n\nLa pregunta es si estos coeficientes son estadísticamente diferentes de cero, esto se puede conocer calculando el error estándar de cada coeficiente. Para lo cual se requiere estimar \\(\\sigma\\) que corresponde a la desviación estándar del error tal y como se muestra en las siguientes instrucciones.\n\nerror = y_t - m.predict(T)\nstd_error = np.std(error)\n\nEl error estándar de \\(\\mathbf w\\) es\n\ndiag = np.arange(T.shape[1])\n_ = np.sqrt((np.dot(T.T, T)**(-1))[diag, diag])\nse = std_error * _\n\ny para saber si los coeficientes son significativamente diferente de cero se calcula el cociente m.coef_ entre se; teniendo los siguientes valores \\([-0.62, -4.17, 9.88, \\ldots]\\), para las tres primeras componentes. Se observa que hay varios coeficientes con valor absoluto menor que 2, lo cual significa que esas variables tiene un coeficiente que estadísticamente no es diferente de cero.\nLa predicción del conjunto de prueba se puede realizar con la siguiente instrucción\n\nhy = m.predict(G)\n\nFinalmente, la Figura 3.4 muestra las predicciones contra las mediciones reales. También se incluye la línea que ilustra el modelo ideal.\n\n\nCódigo\nsns.scatterplot(x=hy, y=y_g)\n_min = min(y_g.min(), hy.min())\n_max = max(y_g.max(), hy.max())\nsns.set_style('whitegrid')\nfig = sns.lineplot(x=[_min, _max], y=[_min, _max])\n\n\n\n\n\n\n\n\nFigura 3.4: Regresión Lineal\n\n\n\n\n\nComplementando el ejemplo anterior, se realiza un modelo que primero elimina las variables que no son estadísticamente diferentes de cero (primera línea) y después crea nuevas variables al incluir el cuadrado, ver las líneas dos y tres del siguiente código.\n\nmask = np.fabs(m.coef_ / se) &gt;= 2\nT = np.concatenate((T[:, mask], T[:, mask]**2), axis=1)\nG = np.concatenate((G[:, mask], G[:, mask]**2), axis=1)\n\nSe observa que la identificación de los coeficientes \\(\\mathbf w\\) sigue siendo lineal aun y cuando la representación ya no es lineal por incluir el cuadrado. Siguiendo los pasos descritos previamente, se inicializa el modelo y después se realiza la predicción.\n\nm2 = LinearRegression().fit(T, y_t)\nhy2 = m2.predict(G)\n\nEn este momento se compara si la diferencia entre el error cuadrático medio, del primer y segundo modelo, la diferencia es \\(8.9400\\) indicando que el primer modelo es mejor.\ndiff = ((y_g - hy2)**2).mean() -  ((y_g - hy)**2).mean()\nPara comprobar si esta diferencia es significativa se calcula el error estándar, utilizando bootstrap (Sección A.2) tal y como se muestra a continuación.\n\nS = np.random.randint(y_g.shape[0],\n                      size=(500, y_g.shape[0]))\nB = [((y_g[s] - hy2[s])**2).mean() -\n      ((y_g[s] - hy[s])**2).mean()\n     for s in S]\nse = np.std(B, axis=0)\n\nFinalmente, se calcula el área bajo la curva a la izquierda del cero, teniendo un valor de \\(0.4999\\) lo cual indica que los dos modelos son similares. En este caso se prefiere el modelo más simple porque se observar que incluir el cuadrado de las variables no contribuye a generar un mejor model. El área bajo la curva se calcula con el siguiente código.\n\ndist = norm(loc=diff, scale=se)\np_value = dist.cdf(0)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Métodos Paramétricos</span>"
    ]
  },
  {
    "objectID": "capitulos/04Rendimiento.html",
    "href": "capitulos/04Rendimiento.html",
    "title": "4  Rendimiento",
    "section": "",
    "text": "Paquetes usados\nEl objetivo es contrastar las características de diferentes medidas de rendimiento en aprendizaje supervisado así como simular un procedimiento de aprendizaje supervisado.\nfrom EvoMSA.model import GaussianBayes\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets import load_breast_cancer,\\\n                             load_diabetes\nfrom sklearn.metrics import recall_score\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn import metrics\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pylab as plt\nimport seaborn as sns",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Rendimiento</span>"
    ]
  },
  {
    "objectID": "capitulos/04Rendimiento.html#sec-intro-04",
    "href": "capitulos/04Rendimiento.html#sec-intro-04",
    "title": "4  Rendimiento",
    "section": "4.1 Introducción",
    "text": "4.1 Introducción\nEs importante conocer el rendimiento del algoritmo de aprendizaje computacional desarrollado. En aprendizaje supervisado la medición se hace mediante el conjunto de prueba, \\(\\mathcal G\\), mientras que en aprendizaje no supervisado es posible utilizar el conjunto de entrenamiento \\(\\mathcal T\\) o utilizar un conjunto de prueba. Es importante notar que aunque en el proceso de entrenamiento puede usar una función de rendimiento para estimar o encontrar el algoritmo que modela los datos, es importante complementar esta medición con otras funciones de rendimiento. Esta unidad describe algunas de las medidas más utilizadas para medir el rendimiento de algoritmos de clasificación y regresión.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Rendimiento</span>"
    ]
  },
  {
    "objectID": "capitulos/04Rendimiento.html#sec-clasificacion",
    "href": "capitulos/04Rendimiento.html#sec-clasificacion",
    "title": "4  Rendimiento",
    "section": "4.2 Clasificación",
    "text": "4.2 Clasificación\nEn clasificación existen diferentes medidas de rendimiento, algunas de ellas son exactitud (accuracy), precisión (precision), recall, y \\(F_1\\), entre otras. Sebastiani (2015) describe de manera axiomática algunas de estas medidas y se dan recomendaciones en general sobre medidas de rendimiento para clasificadores.\nVarias de las medidas de rendimiento toman como insume la Tabla de Confusión (Tabla 4.1), la cual contiene la información del proceso de clasificación. La siguiente tabla muestra la estructura de esta tabla para un problema binario, donde se tiene una clase positiva identificada con \\(p\\) y una clase negativa (\\(n\\)). La variable \\(\\mathcal Y\\) indica las clases reales y la variable \\(\\mathcal{\\hat Y}\\) representa la estimación (predicción) hecha por el clasificador. Adicionalmente, la tabla se puede extender a \\(K\\) clases siguiendo la misma estructura; la diagonal contienen los elementos correctamente identificados y los elementos fuera de la diagonal muestra los errores.\n\n\n\nTabla 4.1: Tabla de Confusión\n\n\n\n\n\n\n\\(\\mathcal{\\hat Y}=p\\)\n\\(\\mathcal{\\hat Y}=n\\)\n\n\n\n\n\\(\\mathcal Y=p\\)\nVerdaderos Pos.\nFalsos Neg.\n\n\n\\(\\mathcal Y=n\\)\nFalsos Pos.\nVerdaderos Neg.\n\n\n\n\n\n\nLa tabla se puede ver como valores nominales, es decir contar el número de ejemplos clasificados como verdaderos positivos o como proporción de tal manera que las cuatro celdas sumen \\(1\\). En esta descripción se asume que son proporcionen, esto porque se seguirá una interpretación probabilística descrita en este artículo para presentar las diferentes medidas de rendimiento.\nViendo la Tabla 4.1 como una proporción y combinando con la interpretación probabilística la tabla quedaría de la siguiente manera.\n\n\n\nTabla 4.2: Tabla de Confusión como Proporción\n\n\n\n\n\n\n\n\n\n\n\n\\(\\mathcal{\\hat Y}=p\\)\n\\(\\mathcal{\\hat Y}=n\\)\n\n\n\n\n\\(\\mathcal Y=p\\)\n\\(\\mathbb P(\\mathcal Y=p, \\mathcal{\\hat Y=p})\\)\n\\(\\mathbb P(\\mathcal Y=p, \\mathcal{\\hat Y=n})\\)\n\n\n\\(\\mathcal Y=n\\)\n\\(\\mathbb P(\\mathcal Y=n, \\mathcal{\\hat Y=p})\\)\n\\(\\mathbb P(\\mathcal Y=n, \\mathcal{\\hat Y=n})\\)\n\n\n\n\n\n\nPartiendo de la Tabla 4.2 se puede calcular la probabilidad marginal de cualquier variable y también las probabilidades condicionales, por ejemplo \\(\\mathbb P(\\mathcal Y=p) = \\sum_k \\mathbb P(\\mathcal Y=p, \\mathcal{\\hat Y=k})\\) que es la suma de los elementos del primer renglón de la tabla anterior.\n\n4.2.1 Error\nSe empieza la descripción con el error de clasificación (Sección 2.4) el cual es la proporción de errores y se puede definir como\n\\[\n\\textsf{error}(\\mathcal Y, \\mathcal{\\hat Y}) = 1 -  \\textsf{accuracy}(\\mathcal Y, \\mathcal{\\hat Y}).\n\\]\n\n\n4.2.2 Exactitud (Accuracy)\nEl error se define mediante la exactitud. La exactitud es la proporción de ejemplos correctamente clasificados, utilizando la notación de la tabla de confusión quedaría como:\n\\[\n\\textsf{accuracy}(\\mathcal Y, \\mathcal{\\hat Y}) = \\mathbb P(\\mathcal Y=p, \\mathcal{\\hat Y}=p) + \\mathbb P(\\mathcal Y=n, \\mathcal{\\hat Y}=n).\n\\]\nUna manera equivalente de ver la exactitud es utilizando la probabilidad condicional, es decir,\n\\[\n\\begin{split}\n\\textsf{accuracy}(\\mathcal Y, \\mathcal{\\hat Y}) &= \\mathbb P( \\mathcal{\\hat Y}=p \\mid \\mathcal Y=p)\\mathbb P(\\mathcal Y=p)\\\\\n&+ \\mathbb P(\\mathcal{\\hat Y}=n \\mid \\mathcal Y=n)\\mathbb P(\\mathcal Y=n).\n\\end{split}\n\\]\nEsta manera ayuda a entender el caso cuando se tiene una clase con muchos ejemplos, e.g., \\(\\mathbb P(\\mathcal Y=p) \\gg \\mathbb P(\\mathcal Y=n),\\) en ese caso se ve que la exactitud está dominado por el primer término, i.e., \\(\\mathbb P( \\mathcal{\\hat Y}=p \\mid \\mathcal Y=p)\\mathbb P(\\mathcal Y=p).\\) En este caso, la manera trivial de optimizar la exactitud es crear un clasificador que siempre regrese la clase \\(p.\\) Por esta razón la exactitud no es una medida adecuada cuando las clases son desbalanciadas, es buena medida cuando \\(\\mathbb P(\\mathcal Y=p) \\approx \\mathbb P(\\mathcal Y=n).\\)\n\n\n4.2.3 Coberturba (Recall)\nLa siguiente medida de rendimiento es el recall, este calcula la probabilidad de ejemplos correctamente clasificados como \\(p\\) dados todos los ejemplos que se tienen de la clase \\(p\\). En base a esta ecuación se puede observar que un algoritmo trivial con el máximo valor de recall solamente tiene que predecir como clase \\(p\\) todos los elementos.\nLa segunda ecuación ayuda a medir en base de la tabla de confusión.\n\\[\n\\begin{split}\n\\textsf{recall}_p(\\mathcal Y, \\mathcal{\\hat Y}) &= \\mathbb P(\\mathcal{\\hat Y}=p \\mid \\mathcal{Y}=p) \\\\\n&= \\frac{\\mathbb P(\\mathcal{\\hat Y}=p, \\mathcal{Y}=p)}{\\mathbb P(\\mathcal Y=p)}\n\\end{split}\n\\tag{4.1}\\]\n\n\n4.2.4 Precisión (Precision)\nLa precisión complementa el recall, al calcular la probabilidad de los ejemplos correctamente clasificados como \\(p\\) dadas las predicciones de los ejemplos. Es decir, en la probabilidad condicional se observa que se conocen las predicciones positivas y de esas predicciones se mide si estas son correctamente clasificadas. Basándose en esto, se puede ver que una manera de generar un algoritmo competitivo en esta media corresponde a predecir la clase solo cuando exista una gran seguridad de la clase.\n\\[\n\\begin{split}\n\\textsf{precision}_p(\\mathcal Y, \\mathcal{\\hat Y}) &= \\mathbb P(\\mathcal Y=p \\mid \\mathcal{\\hat Y}=p)\\\\\n&= \\frac{\\mathbb P(\\mathcal Y=p, \\mathcal{\\hat Y}=p)}{\\mathbb P(\\mathcal{\\hat Y}=p)}\n\\end{split}\n\\tag{4.2}\\]\n\n\n4.2.5 \\(F_\\beta\\)\nFinalmente, una manera de combinar el recall (Ecuación 4.1) con la precisión (Ecuación 4.2) es la medida \\(F_\\beta\\), es probable que esta medida se reconozca más cuando \\(\\beta=1\\). La idea de \\(\\beta\\) es ponderar el peso que se le quiere dar a la precisión con respecto al recall.\n\\[\nF^p_\\beta(\\mathcal Y, \\mathcal{\\hat Y}) = (1 + \\beta^2) \\frac{\\textsf{precision}_p(\\mathcal Y, \\mathcal{\\hat Y}) \\cdot \\textsf{recall}_p(\\mathcal Y, \\mathcal{\\hat Y})}{\\beta^2 \\cdot \\textsf{precision}_p(\\mathcal Y, \\mathcal{\\hat Y}) + \\textsf{recall}_p(\\mathcal Y, \\mathcal{\\hat Y})}\n\\tag{4.3}\\]\n\n\n4.2.6 Medidas Macro\nEn las definiciones de precisión (Ecuación 4.2), recall (Ecuación 4.1) y \\(F_\\beta\\) (Ecuación 4.3) se ha usado un subíndice y superíndice con la letra \\(p\\) esto es para indicar que la medida se está realizando con respecto a la clase \\(p\\). Esto ayuda también a ilustrar que en un problema de \\(K\\) clases se tendrán \\(K\\) diferentes medidas de precisión, recall y \\(F_\\beta;\\) cada una de esas medidas corresponde a cada clase.\nEn ocasiones es importante tener solamente una medida que englobe el rendimiento en el caso de los tres rendimientos que se han mencionado, se puede calcular su versión macro que es la media de la medida. Esto es para un problema de \\(K\\) clases la precisión, recall y \\(F_\\beta\\) se definen de la siguiente manera.\n\\[\n\\textsf{macro-precision}(\\mathcal Y, \\mathcal{\\hat Y}) =  \\frac{1}{K}\\sum_{k} \\textsf{precision}_k(\\mathcal Y, \\mathcal{\\hat Y}),\n\\]\n\\[\n\\textsf{macro-recall}(\\mathcal Y, \\mathcal{\\hat Y}) =  \\frac{1}{K}\\sum_{k} \\textsf{recall}_k(\\mathcal Y, \\mathcal{\\hat Y}),\n\\]\n\\[\n\\textsf{macro-}F_\\beta(\\mathcal Y, \\mathcal{\\hat Y}) =  \\frac{1}{K}\\sum_{k} F^k_\\beta(\\mathcal Y, \\mathcal{\\hat Y}).\n\\]\n\n\n4.2.7 Entropía Cruzada\nUna función de costo que ha sido muy utilizada en redes neuronales y en particular en aprendizaje profundo es la Entropía Cruzada (Cross Entropy) que para una distribución discreta se define como: \\(H(P, Q) = - \\sum_x P(x) \\log Q(x)\\).\nPara cada ejemplo \\(x\\) se tiene \\(\\mathbb P(\\mathcal Y=k \\mid \\mathcal X=x)\\) y el clasificador predice \\(\\mathbb{\\hat P}(\\mathcal Y=k \\mid \\mathcal X=x).\\) Utilizando estas definiciones se puede decir que \\(P=\\mathbb P\\) y \\(Q=\\mathbb{\\hat P}\\) en la definición de entropía cruzada; entonces\n\\[\n\\begin{split}\nH(\\mathbb P(\\mathcal Y \\mid \\mathcal X=x) &, \\mathbb{\\hat P}(\\mathcal Y \\mid \\mathcal X=x)) =\\\\\n&-\\sum_k^K \\mathbb P(\\mathcal Y=k \\mid \\mathcal X=x) \\log \\mathbb{\\hat P}(\\mathcal Y=k \\mid \\mathcal X=x).\n\\end{split}\n\\]\nFinalmente la medida de rendimiento quedaría como \\(\\sum_x H(\\mathbb P(\\mathcal Y \\mid \\mathcal X=x), \\mathbb{\\hat P}(\\mathcal Y \\mid \\mathcal X=x)).\\)\n\n\n4.2.8 Área Bajo la Curva ROC\nEl área bajo la curva ROC (Relative Operating Characteristic) es una medida de rendimiento que también está pasada en la probabilidad a posteriori \\(\\mathbb P(\\mathcal Y \\mid \\mathcal X)\\) con la característica de que la clase se selecciona en base a un umbral \\(\\rho\\). Es decir, dado un ejemplo \\(x\\), este ejemplo pertenece a la clase \\(p\\) si \\(\\mathbb P(\\mathcal Y=p \\mid \\mathcal X=x) \\geq \\rho.\\)\nSe observa que modificando el umbral \\(\\rho\\) se tienen diferentes tablas de confusión, para cada tabla de confusión posible se calcula la tasa de verdaderos positivos (TPR) que corresponde al recall (Sección 4.2.3), i.e., \\(\\mathbb P(\\mathcal{\\hat Y}=p \\mid \\mathcal Y=p),\\) y la tasa de falsos positivos (FPR) que es \\(\\mathbb P(\\mathcal{\\hat Y}=p \\mid \\mathcal Y=n).\\) Cada par de TPR y FPR representan un punto de la curva ROC. El rendimiento corresponde al área debajo de la curva delimitada por los pares TPR y FPR.\n\n\n4.2.9 Ejemplo\nEl ejemplo de Breast Cancer Wisconsin (Sección 3.8) se utiliza para ilustrar el uso de la medidas de rendimiento presentadas hasta el momento.\n\nD, y = load_breast_cancer(return_X_y=True)\nT, G, y_t, y_g = train_test_split(D, y, \n                                  random_state=0,  \n                                  test_size=0.2)\ngaussian = GaussianBayes().fit(T, y_t)\nhy_gaussian = gaussian.predict(G)\n\nEl clasificador Gausiano tiene un accuracy de \\(0.8947\\), el cual se puede calcular con el siguiente código.\n\naccuracy = metrics.accuracy_score(y_g, hy_gaussian)\n\nLas medidas de recall, precision y f1 se presentan en la Tabla 4.3, en la última columna se presenta el macro de cada una de las medidas.\n\nrecall = metrics.recall_score(y_g, hy_gaussian,\n                              average=None)\nprecision = metrics.precision_score(y_g, hy_gaussian,\n                                    average=None)\nf1 = metrics.f1_score(y_g, hy_gaussian,\n                      average=None)\n\n\n\n\n\nTabla 4.3: Rendimiento\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(\\mathcal Y=0\\)\n \\(\\mathcal Y=1\\)\nMacro\n\n\n\n\nrecall\n\\(0.8298\\)\n\\(0.9403\\)\n\\(0.8850\\)\n\n\nprecision\n\\(0.9070\\)\n\\(0.8873\\)\n\\(0.8972\\)\n\n\nf1\n\\(0.8667\\)\n\\(0.9130\\)\n\\(0.8899\\)\n\n\n\n\n\n\n\n\nPor otro lado la entropia cruzada es \\(2.1071\\) que se puede calcular con el siguiente código.\n\nprob = gaussian.predict_proba(G)\nentropia = metrics.log_loss(y_g, prob)\n\nComplementando la información de las medidas que se calculan mediante la posteriori se encuentra la curva ROC, la cual se puede calcular con el siguiente código y se muestra en la Figura 4.1\n\nfpr, tpr, thresholds = metrics.roc_curve(y_g, prob[:, 1])\ndf = pd.DataFrame(dict(FPR=fpr, TPR=tpr))\nsns.set_style('whitegrid')\nfig = sns.lineplot(df, x='FPR', y='TPR')\n\n\n\n\n\n\n\nFigura 4.1: ROC\n\n\n\n\n\nTeniendo un valor de área bajo la curva (auc_score) de \\(0.9540\\) que se obtuvo de la siguiente manera.\nauc_score = metrics.roc_auc_score(y_g, prob[:, 1])\n\n\n\n\n\n\nActividad\n\n\n\n\n\nMedir el rendimiento del Clasificador Gausiano Ingenuo (Sección 3.7) en el problema del del Iris (ver Sección B.3.2) utilizando la función \\(F_\\beta\\) (Sección 4.2.5) variando \\(\\beta\\) entre \\([0, 1],\\) tal y como se muestra en la Figura 4.2\n\n\n\n\n\n\n\n\nFigura 4.2: Rendimiento de un Clasificador Bayesiano Ingenuo en el problema del Iris estimado mediante una validación cruzada estratificada.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Rendimiento</span>"
    ]
  },
  {
    "objectID": "capitulos/04Rendimiento.html#sec-rendimiento-regresion",
    "href": "capitulos/04Rendimiento.html#sec-rendimiento-regresion",
    "title": "4  Rendimiento",
    "section": "4.3 Regresión",
    "text": "4.3 Regresión\nCon respecto a regresión las siguientes funciones son utilizadas como medidas de rendimiento.\nError cuadrático medio (Mean Square Error):\n\\[\n\\textsf{mse}(\\mathcal Y, \\mathcal{\\hat Y}) = \\frac{1}{N} \\sum_{i=1}^N (\\mathcal Y_i - \\mathcal{\\hat Y}_i)^2.\n\\tag{4.4}\\]\nError absoluto medio (Mean Absolute Error):\n\\[\n\\textsf{mae}(\\mathcal Y, \\mathcal{\\hat Y}) = \\frac{1}{N} \\sum_{i=1}^N \\mid \\mathcal Y_i - \\mathcal{\\hat Y}_i \\mid.\n\\tag{4.5}\\]\nMedia del porcentaje de error absoluto: \\[\n\\textsf{mape}(\\mathcal Y, \\mathcal{\\hat Y}) = \\frac{1}{N} \\sum_{i=1}^N \\mid \\frac{\\mathcal Y_i - \\mathcal{\\hat Y}_i}{\\mathcal Y_i}\\mid.\n\\tag{4.6}\\]\nLa proporción de la varianza explicada por el modelo:\n\\[\nR^2(\\mathcal Y, \\mathcal{\\hat Y}) = 1 - \\frac{\\sum_{i=1}^N (\\mathcal Y_i - \\mathcal{\\hat Y}_i)^2)}{\\sum_{i=1}^N (\\mathcal Y_i - \\mathcal{\\bar Y}_i)^2)}.\n\\tag{4.7}\\]\n\n4.3.1 Ejemplo\nLas medidas anteriores se ejemplifican utilizando el ejemplo de diabetes(#sec-diabetes) que se puede descargar y modelar mediante OLS (Sección 3.10) de la siguiente manera.\n\nX, y = load_diabetes(return_X_y=True)\nT, G, y_t, y_g = train_test_split(X, y,\n                                  random_state=0,  \n                                  test_size=0.2)\nm = LinearRegression().fit(T, y_t) \n\nLa predicción en el conjunto de prueba sería:\n\nhy = m.predict(G)\n\nLas diferentes medidas de rendimiento para problemas de regresión se puede calcular de la siguiente manera.\nEl error cuadrático medio (Ecuación 4.4), mse corresponde a\n\nmse = metrics.mean_squared_error(y_g, hy)\n\ny tienen un valor de \\(3424.2593\\).\nEl error absoluto medio (Ecuación 4.5), mae, tiene un valor de \\(46.1736\\) calculado de la siguiente manera\nmae = metrics.mean_absolute_error(y_g, hy)\nLa media del porcentaje de error absoluto (Ecuación 4.6), mape, es \\(0.3805\\) obtenido con el siguiente código\nmape = metrics.mean_absolute_percentage_error(y_g, hy)\nFinalmente, la varianza explicada por el modelo \\(R^2\\) (Ecuación 4.7), r2, es \\(0.3322\\)\nr2 = metrics.r2_score(y_g, hy)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Rendimiento</span>"
    ]
  },
  {
    "objectID": "capitulos/04Rendimiento.html#sec-validacion-cruzada",
    "href": "capitulos/04Rendimiento.html#sec-validacion-cruzada",
    "title": "4  Rendimiento",
    "section": "4.4 Conjunto de Validación y Validación Cruzada",
    "text": "4.4 Conjunto de Validación y Validación Cruzada\nAntes de inicia la descripción de otro algoritmo para la selección de características es necesario describir otro conjunto que se utiliza para optimizar los hiperparámetros del algoritmo de aprendizaje. Previamente se describieron los conjuntos de Entrenamiento y Prueba (Sección 3.5), i.e., \\(\\mathcal T\\) y \\(\\mathcal G\\). En particular estos conjuntos se definieron utilizando todos los datos \\(\\mathcal D\\) con lo que se especifica el problema.\nLa mayoría de algoritmos de aprendizaje tiene hiperparámetros que pueden ser ajustados para optimizar su comportamiento al conjunto de datos que se está analizando. Estos hiperparámetros pueden estar dentro del algoritmo o pueden ser modificaciones al conjunto de datos para adecuarlos al algoritmo. El segundo caso es el que se analizará en esta unidad. Es decir, se seleccionarán las variables que facilitan el aprendizaje.\nPara optimizar los parámetros es necesario medir el rendimiento del algoritmo, es decir, observar como se comporta el algoritmo en el proceso de predicción. La manera trivial sería utilizar el conjunto de prueba \\(\\mathcal G\\) para medir el rendimiento. Pero es necesario recordar que este conjunto no debe ser visto durante el aprendizaje y la optimización de los parámetros es parte de ese proceso. Si se usara \\(\\mathcal G\\) entonces dejaría de ser el conjunto de prueba y se tendría que seleccionar otro conjunto de prueba.\nEntonces para optimizar los parámetros del algoritmo se selecciona del conjunto de entrenamiento, i.e., \\(\\mathcal T\\), el conjunto de validación, \\(\\mathcal V\\). Este conjunto tiene la característica que \\(\\mathcal T \\cap \\mathcal V \\cap \\mathcal G = \\emptyset\\) y \\(\\mathcal T \\cup \\mathcal V \\cup \\mathcal G = \\mathcal D.\\) Una manera de realizar estos es seleccionar primeramente el conjunto de prueba \\(\\mathcal G\\) y de los datos restantes generar los conjuntos de entrenamiento \\(\\mathcal T\\) y validación \\(\\mathcal V.\\)\nPara ejemplificar esta idea se utiliza el ejemplo de Breast Cancer Wisconsin (Sección 3.8) utilizando un Clasificador Bayesiano donde el hiperparámetro es si se utilizar un Bayesiano Ingenuo o se estima la matriz de covarianza.\nEl primer paso es obtener los datos del problema, lo cual se muestra en la siguiente instrucción.\n\nD, y = load_breast_cancer(return_X_y=True)\n\nCon los datos \\(\\mathcal D\\) se genera el conjunto de prueba \\(\\mathcal G\\) y los datos para estimar los parámetros y optimizar los hiperparámetros del algoritmo. En la variable T se tiene los datos para encontrar el algoritmo y en G se tiene el conjunto de prueba.\n\nT, G, y_t, y_g = train_test_split(D, y,\n                                  random_state=0,\n                                  test_size=0.2)\n\nLos datos de entrenamiento y validación se generan de manera equivalente tal como se muestra en la siguiente instrucción. El conjunto de validación (\\(\\mathcal V\\)) se encuentra en la variable V y la variable dependiente en y_v.\n\nT, V, y_t, y_v = train_test_split(T, y_t,\n                                  random_state=0,\n                                  test_size=0.3)\n\nEn este momento ya se tienen todos los elementos para medir el rendimiento de cada hiperparámetro. Empezando por el clasificador con la matriz de covarianza completa. El recall en ambas clases es [0.9615, 0.8824].\n\ngaussian = GaussianBayes().fit(T, y_t)\nhy_gaussian = gaussian.predict(V)\nrecall = recall_score(y_v, hy_gaussian, average=None)\n\nLa segunda opción es utilizar un clasificador Bayesiano Ingenuo, el cual se especifica con el parámetro naive tal y como se muestra en las siguientes instrucciones. El recall en las dos clases es [0.8654, 0.9765].\n\ningenuo = GaussianBayes(naive=True).fit(T, y_t)\nhy_ingenuo = ingenuo.predict(V)\nscore = recall_score(y_v, hy_ingenuo, average=None)\n\nComparando el rendimiento de los dos hiperparámetros se observa cual de los dos modelos obtiene el mejor rendimiento. Con el fin de completar el ejemplo se describe calcular el rendimiento en \\(\\mathcal G\\) del algoritmo con la matriz de covarianza completa. Este algoritmo tiene un rendimiento de [0.8298, 0.9403] que se puede calcular con el siguiente código.\n\ngaussian = GaussianBayes().fit(np.concatenate((T, V)),\n                               np.concatenate((y_t, y_v)))\nhy_gaussian = gaussian.predict(G)\nscore = recall_score(y_g, hy_gaussian, average=None)\n\n\n4.4.1 k-Iteraciones de Validación Cruzada\nCuando se cuenta con pocos datos para medir el rendimiento del algoritmo es común utilizar la técnica de k-fold cross-validation la cual consiste en partir \\(k\\) veces el conjunto de entrenamiento para generar \\(k\\) conjuntos de entrenamiento y validación.\nLa idea se ilustra con la siguiente tabla, donde se asume que los datos son divididos en 5 bloques (\\(k=5\\)), cada columna de la tabla ilustra los datos de ese bloque. Si los datos se dividen en \\(k=5\\) bloques, entonces existen \\(k\\) iteraciones que son representadas por cada renglón de la siguiente tabla, quitando el encabezado de la misma. La letra en cada celda identifica el uso que se le dará a esos datos en la respectiva iteración, es decir, \\(\\mathcal T\\) representa que se usará como conjunto de entrenamiento y \\(\\mathcal V\\) se usa para identificar aquellos datos que se usarán como conjunto de validación.\nLa idea es entrenar y probar el rendimiento del algoritmo \\(k\\) veces usando las particiones en cada renglón. Es decir, la primera vez se usan los datos de la primera columna como el conjunto de validación, y el resto de columnas, \\([2, 3, 4, 5]\\), como conjunto de entrenamiento para estimar los parámetros del algoritmo. En la segunda iteración se usan los datos del segundo renglón donde se observa que los datos en la cuarta columna corresponden al conjunto de validación y los datos en las columnas \\([1, 2, 3, 5]\\) son usados como conjunto de prueba. Las iteraciones siguen hasta que todos los datos fueron utilizados en una ocasión como conjunto de validación.\n\n\n\n\n\n\n\n\n\n\n1\n2\n3\n4\n5\n\n\n\n\n\\(\\mathcal V\\)\n\\(\\mathcal T\\)\n\\(\\mathcal T\\)\n\\(\\mathcal T\\)\n\\(\\mathcal T\\)\n\n\n\\(\\mathcal T\\)\n\\(\\mathcal T\\)\n\\(\\mathcal T\\)\n\\(\\mathcal V\\)\n\\(\\mathcal T\\)\n\n\n\\(\\mathcal T\\)\n\\(\\mathcal T\\)\n\\(\\mathcal V\\)\n\\(\\mathcal T\\)\n\\(\\mathcal T\\)\n\n\n\\(\\mathcal T\\)\n\\(\\mathcal T\\)\n\\(\\mathcal T\\)\n\\(\\mathcal T\\)\n\\(\\mathcal V\\)\n\n\n\\(\\mathcal T\\)\n\\(\\mathcal V\\)\n\\(\\mathcal T\\)\n\\(\\mathcal T\\)\n\\(\\mathcal T\\)\n\n\n\nSe utiliza el mismo problema para medir el rendimiento del hiperparámetro del clasificador Gausiano. Lo primero es seleccionar el conjunto de prueba (\\(\\mathcal G\\)) que se realiza con el siguiente código.\n\nT, G, y_t, y_g = train_test_split(D, y,\n                                  random_state=0,  \n                                  test_size=0.2)\n\nLa validación cruzada con k-iteraciones se puede realizar con la clase KFold de la siguiente manera. La primera línea crear una variable para guardar el rendimiento. En la segunda línea se inicializa el procedimiento indicando que los datos sean tomados al azar. Después se realiza el ciclo con las \\(k\\) iteraciones, para cada iteración se genera un índice ts que indica cuales son los datos del conjunto de entrenamiento y vs que corresponde a los datos de validación. Se estiman los parámetros usando ts tal y como se observa en la cuarta línea. Habiendo estimado los parámetros se predicen los datos del conjunto de validación (5 línea), se mide el recall en todas las clases y se guarda en la lista perf. Al final se calcula la media de los \\(k\\) rendimientos medidos, teniendo un valor de [0.8903, 0.9174].\n\nperf = []\nkfold = KFold(shuffle=True, random_state=0)\nfor ts, vs in kfold.split(T):\n    gaussian = GaussianBayes().fit(T[ts], y_t[ts])\n    hy_gaussian = gaussian.predict(T[vs])\n    _ = recall_score(y_t[vs], hy_gaussian, average=None)    \n    perf.append(_)\nperf = np.mean(perf, axis=0)    \n\nUn procedimiento equivalente se realiza para el caso del clasificador Bayesiano Ingenuo tal y como se muestra a continuación. La media del recall en las clases es [0.8260, 0.9785] Se observa que el clasificador Bayesiano con la matriz de covarianza tiene un mejor rendimiento en validación que el clasificador Bayesiano Ingenuo. El último paso sería calcular el rendimiento en el conjunto \\(\\mathcal G\\) lo cual fue presentado anteriormente.\n\nperf = []\nkfold = KFold(shuffle=True)\nfor ts, vs in kfold.split(T):\n    gaussian = GaussianBayes(naive=True).fit(T[ts], y_t[ts])\n    hy_gaussian = gaussian.predict(T[vs])\n    _ = recall_score(y_t[vs], hy_gaussian, average=None)    \n    perf.append(_)\nperf = np.mean(perf, axis=0)  \n\n\n\n\n\n\n\nSebastiani, Fabrizio. 2015. «An Axiomatically Derived Measure for the Evaluation of Classification Algorithms». En Proceedings of the 2015 International Conference on The Theory of Information Retrieval, 11-20. ICTIR ’15. New York, NY, USA: Association for Computing Machinery. https://doi.org/10.1145/2808194.2809449.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Rendimiento</span>"
    ]
  },
  {
    "objectID": "capitulos/05ReduccionDim.html",
    "href": "capitulos/05ReduccionDim.html",
    "title": "5  Reducción de Dimensión",
    "section": "",
    "text": "Paquetes usados\nEl objetivo de la unidad es aplicar técnicas de reducción de dimensionalidad, para mejorar el aprendizaje y para visualizar los datos\nfrom scipy.stats import multivariate_normal, norm, kruskal\nfrom sklearn.datasets import load_diabetes,\\\n                             load_breast_cancer,\\\n                             load_iris,\\\n                             load_wine,\\\n                             load_digits\nfrom sklearn.feature_selection import f_regression,\\\n                                      SelectKBest,\\\n                                      SelectFromModel,\\\n                                      SequentialFeatureSelector\nfrom sklearn.model_selection import KFold, train_test_split\nfrom sklearn.metrics import recall_score, make_scorer, r2_score\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import decomposition\nfrom EvoMSA.model import GaussianBayes\nimport umap\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pylab as plt\nimport matplotlib as mpl\nimport seaborn as sns",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Reducción de Dimensión</span>"
    ]
  },
  {
    "objectID": "capitulos/05ReduccionDim.html#sec-intro-05",
    "href": "capitulos/05ReduccionDim.html#sec-intro-05",
    "title": "5  Reducción de Dimensión",
    "section": "5.1 Introducción",
    "text": "5.1 Introducción\nHabiendo descrito problemas de clasificación y regresión, podemos imaginar que existen ocasiones donde las variables que describen al problema no contribuyen dentro de la solución, o que su aporte está dado por otras componentes dentro de la descripción. Esto trae como consecuencia, en el mejor de los caso, que el algoritmo tenga un mayor costo computacional o en un caso menos afortunado que el algoritmo tenga un rendimiento menor al que se hubiera obtenido seleccionado las variables. Es pertinente mencionar que el caso contrario correspondiente al incremento del número de variables es también un escenario factible y se abordará en otra ocasión.\nExisten diferentes maneras para reducir la dimensión de un problema, es decir, transformar la representación original \\(x \\in \\mathbb R^d\\) a una representación \\(\\hat x \\in \\mathbb R^m\\) donde \\(m &lt; d\\). El objetivo es que la nueva representación \\(\\hat x\\) contenga la información necesaria para realizar la tarea de clasificación o regresión. También otro objetivo sería reducir a \\(\\mathbb R^2\\) o \\(\\mathbb R^3\\) de tal manera que se pueda visualizar el problema. En este último caso el objetivo es que se mantengan las características de los datos en \\(\\mathbb R^d\\) en la reducción.\nEsta descripción inicia con una metodología de selección basada en calcular estadísticas de los datos y descartar aquellas que no proporcionan información de acuerdo a la estadística.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Reducción de Dimensión</span>"
    ]
  },
  {
    "objectID": "capitulos/05ReduccionDim.html#sec-seleccion-var-estadistica",
    "href": "capitulos/05ReduccionDim.html#sec-seleccion-var-estadistica",
    "title": "5  Reducción de Dimensión",
    "section": "5.2 Selección de Variables basadas en Estadísticas",
    "text": "5.2 Selección de Variables basadas en Estadísticas\nSe utilizará el problema sintético (Sección 2.3.1) de tres clases para describir el algoritmo de selección. Este problema está definido por tres Distribuciones Gausianas donde se generan tres muestras de 1000 elementos cada una utilizando el siguiente código.\n\np1 = multivariate_normal(mean=[5, 5],\n                         cov=[[4, 0], [0, 2]])\np2 = multivariate_normal(mean=[1.5, -1.5],\n                         cov=[[2, 1], [1, 3]])\np3 = multivariate_normal(mean=[12.5, -3.5],\n                         cov=[[2, 3], [3, 7]])\nX_1 = p1.rvs(size=1000)\nX_2 = p2.rvs(size=1000)\nX_3 = p3.rvs(size=1000)\n\nEstas tres distribuciones representan el problema de clasificación para tres clases. El siguiente código une las tres matrices X_1, X_2 y X_3 y genera un arreglo y que representa la clase.\n\nD = np.concatenate((X_1, X_2, X_3), axis=0)\ny = np.array(['a'] * X_1.shape[0] +\n             ['b'] * X_2.shape[0] +\n             ['c'] * X_3.shape[0])\n\nPor construcción el problema está en \\(\\mathbb R^2\\) y se sabe que las dos componentes contribuyen a la solución del mismo, es decir, imagine que una de las variables se pierde, con la información restante se desarrollaría un algoritmo de clasificación con un rendimiento mucho menor a aquel que tenga toda la información.\nContinuando con el problema sintético, en está ocasión lo que se realiza es incluir en el problema una variable que no tiene relación con la clase, para esto se añade una variable aleatoria con una distribución Gausiana con \\(\\mu=2\\) y \\(\\sigma=3\\) tal como se muestra en el siguiente código.\n\nN = norm.rvs(loc=2, scale=3, size=3000)\nD = np.concatenate((D, np.atleast_2d(N).T), axis=1)\n\nEl objetivo es encontrar la variable que no está relacionada con la salida. Una manera de realizar esto es imaginar que si la media en las diferentes variables es la misma en todas las clases entonces esa variable no contribuye a discriminar la clase. En Sección 3.6.1 se presentó el procedimiento para obtener las medias que definen \\(\\mathbb P(\\mathcal X \\mid \\mathcal Y)\\) para cada clase. El siguiente código muestra el procedimiento para calcular las medías que son \\(\\mu_1=[4.9654, 5.0404, 2.0339]^\\intercal\\), \\(\\mu_2=[1.4865, -1.4709, 1.9807]^\\intercal\\) y \\(\\mu_3=[12.4537, -3.5654, 1.9212]^\\intercal\\).\n\nlabels = np.unique(y)\nmus = [np.mean(D[y==i], axis=0) for i in labels]\n\nSe observa que la media de la tercera variable es aproximadamente igual para las tres clases, teniendo un valor cercano a \\(2\\) tal y como fue generada. Entonces lo que se busca es un procedimiento que permita identificar que las muestras en cada grupo (clase) hayan sido originadas por la misma distribución. Es decir se busca una prueba que indique que las primeras dos variables provienen de diferentes distribuciones y que la tercera provienen de la misma distribución. Es pertinente comentar que este procedimiento no es aplicable para problemas de regresión.\nSi se puede suponer que los datos provienen de una Distribución Gausiana entonces la prueba a realizar es ANOVA, en caso contrario se puede utilizar su equivalente método no paramétrico como es la prueba Kruskal-Wallis. Considerando que de manera general se desconoce la distribución que genera los datos, entonces se presenta el uso de la segunda prueba.\nLa prueba Kruskal-Wallis identifica si un conjunto de muestras independientes provienen de la misma distribución. La hipótesis nula es que las muestras provienen de la misma distribución. La función kruskal implementa esta prueba y recibe tantas muestras como argumentos. En el siguiente código ilustra su uso, se observa que se llama a la función kruskal para cada columna en D y se calcula su valor \\(p\\). Los valores \\(p\\) obtenidos son: \\([0.0000, 0.0000, 0.4941]\\) lo cual indica que para las primeras dos variables la hipótesis nula se puede rechazar y por el otro lado la hipótesis nula es factible para la tercera variable con un valor \\(p=0.4941\\).\n\nres = [kruskal(*[D[y==l, i] for l in labels]).pvalue\n       for i in range(D.shape[1])]\n\nEn lugar de discriminar aquellas características que no aportan a modelar los datos, es más común seleccionar las mejores características. Este procedimiento se puede realizar utilizando los valores \\(p\\) de la prueba estadística o cualquier otra función que ordene la importancia de las características.\nEl procedimiento equivalente a la estadística de Kruskal-Wallis en regresión es calcular la estadística F cuya hipótesis nula es asumir que el coeficiente obtenido en una regresión lineal entre las variables independientes y la dependiente es zero. Esta estadística se encuentra implementada en la función f_regression. El siguiente código muestra su uso en el conjunto de datos de diabetes; el cual tiene \\(10\\) variables independientes. En la variable p_values se tienen los valores \\(p\\) se puede observar que el valor \\(p\\) correspondiente a la segunda variable tiene un valor de \\(0.3664\\), lo cual hace que esa variable no sea representativa para el problema que se está resolviendo.\n\nX, y = load_diabetes(return_X_y=True)\nf_statistics, p_values = f_regression(X, y)\n\nUn ejemplo que involucra la selección de las variables más representativas mediante una calificación que ordenan la importancia de las mismas se muestra en el siguiente código. Se puede observar que las nueve variables seleccionadas son: [0, 2, 3, 4, 5, 6, 7, 8, 9] descartando la segunda variable que tiene el máximo valor \\(p.\\)\n\nsel = SelectKBest(score_func=f_regression, k=9).fit(X, y)\nvars = sel.get_support(indices=True)\n\n\n5.2.1 Ventajas y Limitaciones\nLas técnicas vistas hasta este momento requieren de pocos recursos computacionales para su cálculo. Además están basadas en estadísticas que permite saber cuales son las razones de funcionamiento. Estas fortalezas también son origen a sus debilidades, estas técnicas observan en cada paso las variables independientes de manera aislada y no consideran que estas variables pueden interactuar. Por otro lado, la selección es agnóstica del algoritmo de aprendizaje utilizado.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Reducción de Dimensión</span>"
    ]
  },
  {
    "objectID": "capitulos/05ReduccionDim.html#selección-hacia-adelante",
    "href": "capitulos/05ReduccionDim.html#selección-hacia-adelante",
    "title": "5  Reducción de Dimensión",
    "section": "5.3 Selección hacia Adelante",
    "text": "5.3 Selección hacia Adelante\nUn procedimiento que pone en el centro del proceso de selección al algoritmo de aprendizaje utilizado es Selección hacia Adelante y su complemento que sería Selección hacia Atrás. El algoritmo de selección hacia adelante es un procedimiento iterativo que selecciona una variable a la vez guiada por el rendimiento de esta variable cuando es usada en el algoritmo de aprendizaje. Al igual que los procedimientos anteriores este no modifica las características del problema, solamente selecciona las que se consideran relevantes.\nEn selección hacia adelante y hacia atrás se inicia con el conjunto de entrenamiento \\(\\mathcal T = \\{(x_i, y_i)\\},\\) con una función \\(L\\) que mide el rendimiento del algoritmo de aprendizaje \\(\\mathcal H.\\) La idea es ir seleccionando de manera iterativa aquellas variables que generan un modelo con mejores capacidades de generalización. Para medir la generalización del algoritmo se pueden realizar de diferentes maneras, una es mediante la división de \\(\\mathcal X\\) en dos conjuntos: entrenamiento y validación; y la segunda manera corresponde a utilizar \\(k\\)-iteraciones de validación cruzada.\nSuponga un conjunto \\(\\pi \\subseteq \\{1, 2, \\ldots, d\\}\\) de tal manera que \\(\\mathcal T_\\pi\\) solamente cuenta con las variables identificadas en el conjunto \\(\\pi\\). Utilizando está notación el algoritmo se puede definir de la siguiente manera. Inicialmente $^0 = $, en el siguiente paso \\(\\pi^{j + 1} \\leftarrow \\pi^j \\cup \\textsf{arg max}_{\\{i \\mid i \\in \\{1, 2, \\ldots, d\\}, i \\notin \\pi^j\\}} \\mathcal P(\\mathcal H, \\mathcal T_{\\pi \\cup i}, L)\\), donde \\(\\mathcal P\\) representa el rendimiento del algoritmo \\(\\mathcal H\\) en el subconjunto \\({\\pi \\cup i}\\) usando la función de rendimiento \\(L\\). Este proceso continua si \\(\\mathcal P^{j+1} &gt; \\mathcal P^j\\) donde \\(\\mathcal P^0 = 0\\).\nEs importante mencionar que el algoritmo antes descrito es un algoritmo voraz y que el encontrar el óptimo de este problema de optimización no se garantiza con este tipo de algoritmos. Lo que quiere decir es que el algoritmo encontrará un óptimo local.\nIlustrando estos pasos en el conjunto de Breast Cancer Wisconsin (Sección 3.8).\n\nD, y = load_breast_cancer(return_X_y=True)\nT, G, y_t, y_g = train_test_split(D, y, test_size=0.2)\n\nEl primer paso es medir el rendimiento cuando solamente una variable interviene en el proceso. Como inicialmente $^0 = $ entonces solo es necesario generar un clasificador cuando sola una variable está involucrada. El rendimiento de cada variable se guarda en la variable perf, se puede observar que el primer ciclo (línea 3) itera por todas las variables en la representación, para cada una se seleccionan los datos solo con esa variable T1 = T[:, np.array([var])] después se hacen \\(k\\)-iteraciones de validación cruzada y finalmente se guarda el rendimiento. El rendimiento que se está calculando es macro-recall.\n\nperf = []\nkfold = KFold(shuffle=True)\nfor var in range(T.shape[1]):\n    T1 = T[:, np.array([var])]\n    perf_inner = []\n    for ts, vs in kfold.split(T1):\n        gaussian = GaussianNB().fit(T1[ts], y_t[ts])\n        hy_gaussian = gaussian.predict(T1[vs])\n        _ = recall_score(y_t[vs], hy_gaussian,\n                         average='macro')    \n        perf_inner.append(_)\n    perf.append(np.mean(perf_inner))\n\nLa Figura 5.1 muestra el rendimiento de las 30 variables, se observa como una gran parte de las variables proporcionan un rendimiento superior al \\(0.8\\) y la variable que tiene el mejor rendimiento es la que corresponde al índice \\(22\\) y valor \\(0.8924\\).\n\n\nCódigo\nsns.barplot(x=list(range(len(perf))), y=perf)\nplt.xlabel('Variable')\nfig = plt.ylabel('Macro-Recall')\n\n\n\n\n\n\n\n\nFigura 5.1: Rendimiento de las variables en la primera iteración del selección hacia adelante\n\n\n\n\n\nEl algoritmo de selección hacia atrás y adelante se implementa en la clase SequentialFeatureSelector y su uso se observa en las siguientes instrucciones.\n\nkfolds = list(KFold(shuffle=True).split(T))\nscoring = make_scorer(lambda y, hy: recall_score(y, hy,\n                                         average='macro'))\nseq = SequentialFeatureSelector(estimator=GaussianNB(),\n                                scoring=scoring,\n                                n_features_to_select='auto',\n                                cv=kfolds).fit(T, y_t)\n\nAl igual que en el algoritmo de SelectKBest las variables seleccionadas se pueden observar con la función get_support. En este caso las variables seleccionadas son: \\([1, 4, 8, 9, 11, 14, 15, 16, 17, 18, 19, 21, 23, 24, 27]\\).\nUtilizando el parámetro direction='backward' para utilizar selección hacia atrás en el mismo conjunto de datos, da como resultado la siguiente selección \\([0, 1, 11, 13, 16, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29]\\). Se puede observar que las variables seleccionadas por los métodos son diferentes. Esto es factible porque los algoritmos solo aseguran llegar a un máximo local y no está garantizado que el máximo local corresponda al máximo global.\n\n5.3.1 Ventajas y Limitaciones\nUna de las ventajas de la selección hacia atrás y adelante es que el algoritmo termina a lo más cuando se han analizado todas las variables, esto eso para un problema en \\(\\mathbb R^d\\) se analizarán un máximo de \\(d\\) variables. La principal desventaja es que estos algoritmos son voraces, es decir, toman la mejor decisión en el momento, lo cual tiene como consecuencia que sean capaces de garantizar llegar a un máximo local y en ocasiones este máximo local no corresponde al máximo global. Con el fin de complementar esta idea, en un problema \\(\\mathbb R^d\\) se tiene un espacio de búsqueda de \\(2^d - 1\\), es decir, se tiene esa cantidad de diferentes configuraciones que se pueden explorar. En los algoritmos de vistos se observa un máximo de \\(d\\) elementos de ese total.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Reducción de Dimensión</span>"
    ]
  },
  {
    "objectID": "capitulos/05ReduccionDim.html#sec-seleccion-por-modelo",
    "href": "capitulos/05ReduccionDim.html#sec-seleccion-por-modelo",
    "title": "5  Reducción de Dimensión",
    "section": "5.4 Selección mediante Modelo",
    "text": "5.4 Selección mediante Modelo\nExisten algoritmos de aprendizaje supervisado donde sus parámetros indican la importancia que tiene cada característica en el problema. Para ejemplificar esto se utilizará el problema de Diabetes que fue utilizado en la Sección 3.10.1. Los datos se obtienen con la siguiente instrucción, adicionalmente se normalizan las características para tener una media \\(0\\) y desviación estándar \\(1\\).\n\nD, y = load_diabetes(return_X_y=True)\nD = StandardScaler().fit_transform(D)\n\nEl siguiente paso se estiman los parámetros de una regresión lineal (Sección 3.10), también se muestran los valores de los primeros tres coeficientes de la regresión. Se puede observar que el valor absoluto de estos coeficientes está en diferentes rangos, el primer coeficiente es cercano a cero, el segundo está alrededor de 10 y el tercero es superior a 20. Considerando que los datos están normalizados, entonces el valor absoluto indica el efecto que tiene esa variable en el resultado final, en estos tres datos es puede concluir que el tercer coeficiente tiene una mayor contribución que los otros dos coeficientes.\n\nreg = LinearRegression().fit(D, y)\nreg.coef_[:3]\n\narray([ -0.47612079, -11.40686692,  24.72654886])\n\n\nLa clase SelectFromModel permite seleccionar las \\(d\\) características que el modelo considera más importante. En el siguiente ejemplo se selecciona las \\(d=4\\) características más importantes; dentro de estas características se encuentra la tercera (i.e., índice 2) cuyo coeficiente se había presentado previamente.\n\nsel = SelectFromModel(reg, max_features=4,\n                      threshold=-np.inf, prefit=True)\nnp.where(sel.get_support())[0]\n\narray([2, 4, 5, 8])\n\n\nHabiendo descrito el procedimiento para seleccionar aquellas características más importantes, es necesario encontrar cuál es el número de características que producen el mejor rendimiento. Para realizar esto, se realiza \\(k\\)-iteraciones de validación cruzada (Sección 4.4.1), donde se varía el número de características y en cada caso se mide el rendimiento utilizando la medida \\(R^2\\) (Sección 4.3).\n\nfolds = [x for x in KFold(shuffle=True).split(D, y)]\nperf = []\ndims = range(2, D.shape[1] + 1)\nfor dim in dims:\n    model = SelectFromModel(reg, max_features=dim,\n                            threshold=-np.inf, prefit=True)\n    hy = np.empty_like(y)\n    for tr, vs in folds:\n        Dt = model.transform(D)\n        m = LinearRegression().fit(Dt[tr], y[tr])\n        hy[vs] = m.predict(Dt[vs])\n    perf.append(dict(r2=r2_score(y, hy), numero=dim))\n\nLa Figura 5.2 muestra el rendimiento (\\(R^2\\)) para cada modelo generado, empezando cuando se usan las \\(2\\) características más importantes y terminando con el modelo que tiene todas las características. En la figura se puede observar que el rendimiento mejora considerablemente de \\(2\\) a \\(3\\) características, este sigue mejorando y llega un punto donde incluir más características tiene un impacto negativo en el rendimiento.\n\n\nCódigo\ndf = pd.DataFrame(perf)\nax = sns.relplot(df, x='numero', y='r2', kind='line')\n\n\n\n\n\n\n\n\nFigura 5.2: Rendimiento variando el número de características",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Reducción de Dimensión</span>"
    ]
  },
  {
    "objectID": "capitulos/05ReduccionDim.html#sec-pca",
    "href": "capitulos/05ReduccionDim.html#sec-pca",
    "title": "5  Reducción de Dimensión",
    "section": "5.5 Análisis de Componentes Principales",
    "text": "5.5 Análisis de Componentes Principales\nLos algoritmos de selección hacia atrás y adelante tiene la característica de requerir un conjunto de entrenamiento de aprendizaje supervisado, por lo que no podrían ser utilizados en problemas de aprendizaje no-supervisado. En esta sección se revisará el uso de Análisis de Componentes Principales (Principal Components Analysis - PCA) para la reducción de dimensión. PCA tiene la firma: \\(f: \\mathbb R^d \\rightarrow \\mathbb R^m\\) donde \\(m &lt; d\\)\nLa idea de PCA es buscar una matriz de proyección \\(W^\\intercal \\in \\mathbb R^{m \\times d}\\) tal que los elementos de \\(\\mathcal D = \\{x_i\\}\\) sea transformados utilizando \\(z = W^\\intercal x\\) donde \\(z \\in \\mathbb R^m\\). El objetivo es que la muestra \\(z_1\\) tenga la mayor variación posible. Es decir, se quiere observar en la primera característica de los elementos transformados la mayor variación; esto se puede lograr de la siguiente manera.\nSi suponemos que \\(\\mathbf x \\sim \\mathcal N_d(\\mu, \\Sigma)\\) y \\(\\mathbf w \\in \\mathbb R^d\\) entonces \\(\\mathbf w \\cdot \\mathbf x \\sim \\mathcal N(\\mathbf w \\cdot \\mu, \\mathbf w^\\intercal \\Sigma \\mathbf w)\\) y por lo tanto \\(\\textsf{Var} (\\mathbf w \\cdot \\mathbf x) = \\mathbf w^\\intercal \\Sigma \\mathbf w.\\)\nUtilizando esta información se puede describir el problema como encontrar \\(\\mathbf w_1\\) tal que \\(\\textsf{Var}(\\mathbf z_1)\\) sea máxima, donde \\(\\textsf{Var}(\\mathbf z_1) = \\mathbf w_1^\\intercal \\Sigma \\mathbf w_1.\\) Dado que en este problema de optimización tiene multiples soluciones, se busca además maximizar bajo la restricción de \\(\\mid\\mid \\mathbf w_1 \\mid\\mid = 1.\\) Escribiéndolo como un problema de Lagrange quedaría como: \\(\\max_{\\mathbf w_1} \\mathbf w_1^\\intercal \\Sigma \\mathbf w_1 - \\alpha (\\mathbf w_1 \\cdot \\mathbf w_1 - 1).\\) Derivando con respecto a \\(\\mathbf w_1\\) se tiene que la solución es: \\(\\Sigma \\mathbf w_i = \\alpha \\mathbf w_i\\) donde esto se cumple solo si \\(\\mathbf w_1\\) es un eigenvector de \\(\\Sigma\\) y \\(\\alpha\\) es el eigenvalor correspondiente. Para encontrar \\(\\mathbf w_2\\) se requiere \\(\\mid\\mid \\mathbf w_2 \\mid\\mid = 1\\) y que los vectores sean ortogonales, es decir, \\(\\mathbf w_2 \\cdot \\mathbf w_1 = 0.\\) Realizando las operaciones necesarias se encuentra que \\(\\mathbf w_2\\) corresponde al segundo eigenvector y así sucesivamente.\n\n5.5.1 Ejemplo - Visualización\nSupongamos que deseamos visualizar los ejemplos del problema del iris. Los ejemplos se encuetran en \\(\\mathbb R^4\\) entonces para poderlos graficar en \\(\\mathbb R^2\\) se requiere realizar una transformación como podría ser Análisis de Componentes Principales.\nEmpezamos por cargar los datos del problema tal y como se muestra en la siguiente instrucción, en la segunda linea se normalizan los datos para tener una media \\(0\\) y desviación estándar \\(1\\), este procedimiento es necesario cuando los valores de las características se encuentran en diferentes escalas.\n\nD, y = load_iris(return_X_y=True)\nD = StandardScaler().fit_transform(D)\n\nHabiendo importado los datos el siguiente paso es inicializar la clase de PCA, para esto requerimos especificar el parámetro que indica el número de componentes deseado, dado que el objetivo es representar en \\(\\mathbb R^2\\) los datos, entonces el ocupamos dos componentes. La primera línea inicializa la clase de PCA, después, en la segunda línea se hace la proyección.\n\npca = decomposition.PCA(n_components=2).fit(D)\nXn = pca.transform(D)\n\nEl siguiente código se utiliza para visualizar los datos. El resultado se muestra en la Figura 5.3, donde se observa en diferente color cada una de las clases.\n\n\nCódigo\ndata = pd.DataFrame([dict(x=x, y=y, clase=c)\n                     for (x, y), c in zip(Xn, y)])\nfig = sns.relplot(data, kind='scatter',\n                  x='x', y='y', hue='clase')\nfig.tick_params(bottom=False, top=False, \n                left=False, right=False,\n                labelbottom=False, labelleft=False)\nfig.set(xlabel=None, ylabel=None)\n\n\n\n\n\n\n\n\nFigura 5.3: Proyección mediante PCA del problema del Iris",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Reducción de Dimensión</span>"
    ]
  },
  {
    "objectID": "capitulos/05ReduccionDim.html#sec-umap-visualizacion",
    "href": "capitulos/05ReduccionDim.html#sec-umap-visualizacion",
    "title": "5  Reducción de Dimensión",
    "section": "5.6 UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction",
    "text": "5.6 UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction\nEn esta sección se presenta el uso de UMAP propuesto por McInnes, Healy, y Melville (2020). UMAP es una técnica no lineal para reducir la dimensión y que con dimensiones bajas (\\(d=2\\)) permite tener una visualización de los datos. El ejemplo que se realizará es visualizar mediante UMAP los datos del problema de Dígitos, estos datos se pueden obtener con la siguiente instrucción; en estas instrucciones también se normalizan los datos para tener una media \\(0\\) y desviación estándar \\(1.\\)\n\nD, y = load_digits(return_X_y=True)\nD = StandardScaler().fit_transform(D)\n\nCon el objetivo de ilustrar la diferencia entre una técnica de proyección lineal como PCA con respecto a una técnica no lineal, la Figura 5.4 presenta la proyección del conjunto de Dígitos utilizando PCA. Como se puede observar en la figura, esta proyección no da una separación clara entre grupos, aunque si se puede identificar una estructura, donde algunos números se encuentran en la perifería de la figura.\n\n\nCódigo\npal = mpl.cm.Paired\npca = decomposition.PCA(n_components=2).fit(D)\nXn = pca.transform(D)\ndf = pd.DataFrame(Xn, columns=['x', 'y'])\ndf['Clase'] = y\nfig = sns.relplot(df, kind='scatter',\n                  legend='full', palette=pal,\n                  x='x', y='y', hue='Clase')\nfig.tick_params(bottom=False, top=False, \n                left=False, right=False,\n                labelbottom=False, labelleft=False)\nfig.set(xlabel=None, ylabel=None)\n\n\n\n\n\n\n\n\nFigura 5.4: Proyección mediante PCA del problema de Dígitos\n\n\n\n\n\nUMAP genera una proyección que intuitivamente trata de preservar la distancia que existe entre los \\(K\\) vecinos cercanos en la dimensión original como en la dimensión destino. Por este motivo un parámetro importante de UMAP es la cantidad de vecinos, que se tiene el efecto de priorizar la estructura global o local de los datos. En el siguiente código se realiza una exploración de este parámetro generando una visualización para \\(K=[2, 4, 8, 16].\\) El código que realiza está exploración se muestra en las siguientes instrucciones.\n\ndf = pd.DataFrame()\nfor K in [2, 4, 8, 16]:\n    reducer = umap.UMAP(n_neighbors=K)\n    low_dim = reducer.fit_transform(D)\n    _ = pd.DataFrame(low_dim, columns=['x', 'y'])\n    _['Clase'] = y\n    _['K'] = K\n    df = pd.concat((df, _))\n\nLa Figura 5.5 muestra las diferentes visualizaciones cuando el número de vecinos de cambia en UMAP, se puede observar como para \\(K=2\\) la visualización no muestra ninguna estructura, pero partiendo de \\(K=4\\) se puede visualizar grupos que corresponden a los diferentes dígitos.\n\n\nCódigo\nfig = sns.relplot(df, kind='scatter', x='x', y='y',\n                  legend='full', palette=pal,\n                  hue='Clase', col='K')\nfig.tick_params(bottom=False, top=False, \n                left=False, right=False,\n                labelbottom=False, labelleft=False)\nfig.set(xlabel=None, ylabel=None)            \n\n\n\n\n\n\n\n\nFigura 5.5: Proyección mediante UMAP del problema de Dígitos variando el número de vecinos\n\n\n\n\n\nCon el objetivo de mostrar con mayor detalle los grupos encontrados, la Figura 5.6 muestra la visualización de \\(K=8\\) en ella se puede observar como los ejemplos se agrupan de acuerdo al dígito que representan, también se puede ver la similitud entre los diferentes dígitos y como algunos ejemplos están muy cerca a un grupo al cual no pertenecen.\n\n\nCódigo\nfig = sns.relplot(df[df.K==8], kind='scatter', \n                  legend='full', palette=pal,\n                  x='x', y='y', hue='Clase')\nfig.tick_params(bottom=False, top=False, \n                left=False, right=False,\n                labelbottom=False, labelleft=False)\nfig.set(xlabel=None, ylabel=None)\n\n\n\n\n\n\n\n\nFigura 5.6: Proyección mediante UMAP del problema de dígitos con ocho vecinos\n\n\n\n\n\n\n\n\n\n\n\nMcInnes, Leland, John Healy, y James Melville. 2020. «UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction». https://arxiv.org/abs/1802.03426.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Reducción de Dimensión</span>"
    ]
  },
  {
    "objectID": "capitulos/06Agrupamiento.html",
    "href": "capitulos/06Agrupamiento.html",
    "title": "6  Agrupamiento",
    "section": "",
    "text": "6.1 Paquetes usados\nEl objetivo de la unidad es conocer y aplicar el algoritmo de agrupamiento k-medias\nfrom sklearn.cluster import KMeans\nfrom sklearn.datasets import load_iris\nfrom sklearn import decomposition\nfrom sklearn import metrics\nfrom scipy import linalg\nfrom itertools import permutations\nfrom matplotlib import pylab as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Agrupamiento</span>"
    ]
  },
  {
    "objectID": "capitulos/06Agrupamiento.html#sec-intro-06",
    "href": "capitulos/06Agrupamiento.html#sec-intro-06",
    "title": "6  Agrupamiento",
    "section": "6.2 Introducción",
    "text": "6.2 Introducción\nEsta unidad trata el problema de agrupamiento, el cual es un problema de aprendizaje no supervisado (Sección 1.3), en el cual se cuenta con un conjunto \\(\\mathcal D = \\{ x_i \\mid i=1, \\ldots, N\\}\\) donde \\(x_i \\in \\mathbb R^d.\\) El objetivo de agrupamiento es separar los elementos de \\(\\mathcal D\\) en \\(K\\) grupos. Es decir asociar a \\(x_i \\in \\mathcal D\\) a un grupo \\(x_i \\in G_j\\) donde \\(\\cup_j^K G_j = \\mathcal D\\) y \\(G_j \\cap G_i = \\emptyset\\) para todo \\(i \\neq j.\\)\nPor supuesto existen diferentes algoritmos que se han desarrollado para generar esta partición, en particular, todos de ellos encuentran la participación optimizando una función objetivo que se considera adecuada para el problema que se está analizando. En particular, esta unidad se enfoca a describir uno de los algoritmos de agrupamiento más utilizados que es K-medias.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Agrupamiento</span>"
    ]
  },
  {
    "objectID": "capitulos/06Agrupamiento.html#sec-agrupamiento-k-medias",
    "href": "capitulos/06Agrupamiento.html#sec-agrupamiento-k-medias",
    "title": "6  Agrupamiento",
    "section": "6.3 K-medias",
    "text": "6.3 K-medias\nDe manera formal el objetivo de K-medias es encontrar la partición \\(G = \\{G_1, G_2, \\ldots, G_K \\}\\) que corresponda al \\(\\min \\sum_{i=1}^K \\sum_{x \\in G_i} \\mid\\mid x - \\mu_i \\mid\\mid,\\) donde \\(\\mu_i\\) es la media de todos los elementos que pertenecen a \\(G_i.\\)\nPara comprender la función objetivo (\\(\\min \\sum_{i=1}^K \\sum_{x \\in G_i} \\mid\\mid x - \\mu_i \\mid\\mid\\)) de k-medias se explican los dos componentes principales que son las medias \\(\\mu_i\\) y los grupos \\(G_i.\\)\nPara ilustrar tanto a \\(\\mu_i\\) como a \\(G_i\\) se utiliza el problema del iris (Sección 5.5.1) cuyos datos se pueden obtener de la siguiente manera.\n\nD, y = load_iris(return_X_y=True)\n\n\n6.3.1 \\(\\mu_i\\)\nComo se describió, \\(\\mu_i\\) es la media de los elementos que corresponden al grupo \\(G_i\\). Asumiendo que el grupo \\(1\\) (\\(G_1\\)) tiene \\(10\\) elementos seleccionados de manera aleatoria de \\(\\mathcal D\\) como se muestra a continuación.\n\nindex = np.arange(len(D))\nnp.random.shuffle(index)\nsel = index[:10]\nG_1 = D[sel]\n\nLa variable G_1 tiene los 10 elementos considerados como miembros de \\(G_1\\) entonces \\(\\mu_1\\) se calcula como la media de cada componente, lo cual se puede calcular con el siguiente código.\n\nmu_1 = G_1.mean(axis=0)\n\nLa Figura 6.1 muestra los elementos seleccionados (\\(x \\in G_1\\)) y la media (\\(\\mu_1\\)) del grupo. Los elementos se encuentran en \\(\\mathbb R^4\\) y para visualizarlos se transformaron usando PCA descrito en la Sección 5.5.1.\n\n\nCódigo\npca = decomposition.PCA(n_components=2).fit(D)\nXn = pca.transform(G_1)\nmu = pca.transform(np.atleast_2d(G_1.mean(axis=0)))[0]\ndata = pd.DataFrame(dict(x=Xn[:, 0], y=Xn[:, 1], tipo=['G_1'] * Xn.shape[0]))\ndata.loc[Xn.shape[0]] = dict(x=mu[0], y=mu[1], tipo='mu_1')\nsns.set_style('whitegrid')\nfig = sns.relplot(data, kind='scatter', hue='tipo', x='x', y='y')\nfig.tick_params(bottom=False, top=False, \n                left=False, right=False,\n                labelbottom=False, labelleft=False)\nfig.set(xlabel=None, ylabel=None)\n\n\n\n\n\n\n\n\nFigura 6.1: Elementos del primer grupo y su centro\n\n\n\n\n\n\n\n6.3.2 \\(G_i\\)\nEl complemento del procedimiento anterior es encontrar los elementos de \\(G_i\\) dando la \\(\\mu_i\\). El ejemplo consiste en generar dos medias, es decir, \\(K=2\\) y encontrar los elementos que corresponden a las medias generadas. Se puede utilizar cualquier procedimiento para generar dos vectores de manera aleatoria, pero en este ejemplo se asume que estos vectores corresponden a dos elementos de \\(\\mathcal D.\\) Estos elementos son los que se encuentran en los indices \\(50\\) y \\(100\\) tal y como se muestra en las siguientes instrucciones.\n\nmu_1 = D[50]\nmu_2 = D[100]\n\nEl elemento \\(x\\) pertenece al grupo \\(G_i\\) si el valor \\(\\mid\\mid x - \\mu_i\\mid\\mid\\) corresponde al \\(\\min_j \\mid\\mid x - \\mu_j\\mid\\mid.\\) Entonces se requiere calcular \\(\\mid\\mid x - \\mu_i\\mid\\mid\\) para cada elemento \\(x \\in \\mathcal D\\) y para cada una de las medias \\(\\mu_i\\). Esto se puede realizar con la siguiente instrucción\n\ndis = np.array([linalg.norm((D - np.atleast_2d(mu)),\n                            axis=1)\n                for mu in [mu_1, mu_2]]).T\n\ndonde se puede observar que el ciclo itera por cada una de las medias, i.e., mu_1 y mu_2. Después se calcula la norma utilizando la función linalg.norm y finalmente se regresa la transpuesta para tener una matriz de 150 renglones y dos columnas que corresponden al número de ejemplos en \\(\\mathcal D\\) y a las dos medias. Los valores de dis[50] y dis[100] son array([0. , 1.8439]) y array([1.8439, 0. ]) respectivamente. Tal y como se espera porque \\(\\mu_1\\) corresponde al índice 50 y \\(\\mu_2\\) es el índice 100. Estos dos ejemplos, array([0. , 1.8439]) y array([1.8439, 0. ]), permiten observar que el argumento mínimo de dis identifica al grupo del elemento, haciendo la consideración que el índice 0 representa \\(G_1\\) y el índice 1 es \\(G_2.\\) La siguiente instrucción muestra como se realiza esta asignación.\n\nG = dis.argmin(axis=1)\n\nLa Figura 6.2 muestra los grupos formados, el primer grupo G_1 se encuentra en azul y el segundo en naranja, también muestra los elementos que fueron usados como medias de cada grupo; estos elementos se observan en color verde.\n\n\nCódigo\npca = decomposition.PCA(n_components=2).fit(D)\nD_pca = pca.transform(D)\ndata = pd.DataFrame([dict(x=x, y=y, tipo=f'G_{g}') \n                     for (x, y), g in zip(D_pca, G)])\nmu = np.vstack((D_pca[50], D_pca[100]))\nmu_data = pd.DataFrame(dict(x=mu[:, 0], \n                            y=mu[:, 1],\n                            tipo=['mu'] * mu.shape[0]))\ndata = pd.concat((data, mu_data))\nsns.set_style('whitegrid')\nfig = sns.relplot(data, kind='scatter', hue='tipo', x='x', y='y')\nfig.tick_params(bottom=False, top=False, \n                left=False, right=False,\n                labelbottom=False, labelleft=False)\nfig.set(xlabel=None, ylabel=None)\n\n\n\n\n\n\n\n\nFigura 6.2: Proyección de los elementos del conjunto y sus centros\n\n\n\n\n\n\n\n6.3.3 Algoritmo\nHabiendo explicado \\(\\mu_i\\) y \\(G_i\\) se procede a describir el procedimiento para calcular los grupos utilizado por k-medias. Este es un procedimiento iterativo que consta de los siguientes pasos.\n\nSe generar \\(K\\) medias de manera aleatoria, donde \\(\\mu_i\\) corresponde a \\(G_i.\\)\nPara cada media, \\(\\mu_i\\), se seleccionan los elementos más cercanos, esto es, \\(x \\in G_i\\) si \\(\\mid\\mid x - \\mu_i\\mid\\mid\\) corresponde al \\(\\min_j \\mid\\mid x - \\mu_j\\mid\\mid.\\)\nSe actualizan las \\(\\mu_i\\) con los elementos de \\(G_i.\\)\nSe regresa al paso 2.\n\nEl procedimiento termina cuando se llega a un número máximo de iteraciones o que la variación de los \\(\\mu_i\\) es mínima, es decir, que los grupos no cambian.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Agrupamiento</span>"
    ]
  },
  {
    "objectID": "capitulos/06Agrupamiento.html#ejemplo-iris",
    "href": "capitulos/06Agrupamiento.html#ejemplo-iris",
    "title": "6  Agrupamiento",
    "section": "6.4 Ejemplo: Iris",
    "text": "6.4 Ejemplo: Iris\nEn el siguiente ejemplo se usará K-medias para encontrar 2 y 3 grupos en el conjunto del iris. La clase se inicializa primero con 2 grupos (primera línea). En la segunda instrucción se predice los grupos para todo el conjunto de datos. Las medias para cada grupo se encuentran en el atributo cluster_centers_.\n\nm = KMeans(n_clusters=2, n_init='auto').fit(D)\ncl = m.predict(D)\n\nLa Figura 6.3 muestra el resultado del algoritmo k-means en el conjunto del Iris, se muestran los dos grupos \\(G_1\\) y \\(G_2\\) y en color verde \\(\\mu_1\\) y \\(\\mu_2\\).\n\n\nCódigo\npca = decomposition.PCA(n_components=2).fit(D)\nD_pca = pca.transform(D)\nmu = pca.transform(m.cluster_centers_)\nmu_data = pd.DataFrame(dict(x=mu[:, 0],\n                            y=mu[:, 1],\n                            tipo=['mu'] * mu.shape[0]))\ndata = pd.DataFrame(dict(x=D_pca[:, 0],\n                         y=D_pca[:, 1],\n                         tipo=[f'G_{x+1}' for x in cl]))\ndata = pd.concat((data, mu_data))\nsns.set_style('whitegrid')\nfig = sns.relplot(data, kind='scatter', hue='tipo', x='x', y='y')\nfig.tick_params(bottom=False, top=False, \n                left=False, right=False,\n                labelbottom=False, labelleft=False)\nfig.set(xlabel=None, ylabel=None)\n\n\n\n\n\n\n\n\nFigura 6.3: Proyección de k-means usando dos grupos\n\n\n\n\n\nUn procedimiento equivalente se puede realizar para generar tres grupos, el único cambio es el parámetro n_clusters en la clase KMeans de la siguiente manera.\n\nm = KMeans(n_clusters=3, n_init='auto').fit(D)\ncl = m.predict(D)\n\nLa Figura 6.4 muestra los tres grupos y con sus tres respectivas medias en color rojo.\n\n\nCódigo\npca = decomposition.PCA(n_components=2).fit(D)\nD_pca = pca.transform(D)\nmu = pca.transform(m.cluster_centers_)\nmu_data = pd.DataFrame(dict(x=mu[:, 0],\n                            y=mu[:, 1],\n                            tipo=['mu'] * mu.shape[0]))\ndata = pd.DataFrame(dict(x=D_pca[:, 0],\n                         y=D_pca[:, 1],\n                         tipo=[f'G_{x+1}' for x in cl]))\ndata = pd.concat((data, mu_data))\nsns.set_style('whitegrid')\nfig = sns.relplot(data, kind='scatter', hue='tipo', x='x', y='y')\nfig.tick_params(bottom=False, top=False, \n                left=False, right=False,\n                labelbottom=False, labelleft=False)\nfig.set(xlabel=None, ylabel=None)\n\n\n\n\n\n\n\n\nFigura 6.4: Proyección de k-means usando tres grupos",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Agrupamiento</span>"
    ]
  },
  {
    "objectID": "capitulos/06Agrupamiento.html#rendimiento",
    "href": "capitulos/06Agrupamiento.html#rendimiento",
    "title": "6  Agrupamiento",
    "section": "6.5 Rendimiento",
    "text": "6.5 Rendimiento\nRecordando que en aprendizaje no supervisado no se tiene una variable dependiente que predecir. En este caso particular se utilizó un problema de clasificación para ilustrar el procedimiento de k-medias, entonces se cuenta con una clase para cada elemento \\(x \\in \\mathcal D\\). Además se sabe que el problema del iris tiene tres clases, entonces utilizando los tres grupos obtenidos previamente podemos medir que tanto se parecen estos tres grupos a las clases del iris. Es decir, se puede saber si el algoritmo de k-medias agrupa los elementos de tal manera que cada grupo corresponda a una clase del iris.\nLos grupos generados se encuentran en la lista cl y las clases se encuentran en y. La lista y tiene organizada las clases de la siguiente manera: los primeros 50 elementos son la clase \\(0\\), los siguientes \\(50\\) son clase \\(1\\) y los últimos son la clase \\(2\\). Dado que K-medias no conoce los clases y genera los grupos empezando de manera aleatoria, entonces es probable que los grupos sigan una numeración diferente al problema del iris. Los grupos en cl están organizados de la siguiente manera aproximadamente los \\(50\\) primeros elementos son del grupo \\(1\\), los siguientes son grupo \\(0\\) y finalmente los últimos son grupo \\(2\\). Entonces se puede hacer una transformación usando la variable perm con la siguiente información array([0, 2, 1]).\nUtilizando perm se calcula la exactitud (Sección 4.2.2) utilizando la siguiente instrucción. Se obtiene una exactitud de \\(0.8867\\) que significa que la mayoría de los datos se agrupan en un conjunto que corresponde a la clase del conjunto del iris.\n\nacc = metrics.accuracy_score(y, perm[cl])\n\nEn general en agrupamiento no se cuenta con la composición de los grupos, es más, se desconocen cuántos grupos modela el problema. Para estas ocasiones es imposible medir el accuracy o cualquier otra medida de agrupamiento que requiera la composición de real de los grupos.\nUna medida que no requiere conocer los grupos es el Silhouette Coefficient; el cual mide la calidad de los grupos, mientras mayor sea el valor significa una mejor calidad en los grupos. Este coeficiente se basa en la siguiente función:\n\\[\ns = \\frac{b - a}{\\max(a, b)},\n\\]\ndonde \\(a\\) corresponde a la distancia media entre un elemento y todos las objetos del mismo grupo; y \\(b\\) es la distancia media entre la muestra y todos los elementos del grupo más cercano.\nPor ejemplo, en el problema del Iris \\(s\\) tiene un valor de \\(0.5512\\) calculado con la siguiente instrucción.\n\nsil = metrics.silhouette_score(D, cl, metric='euclidean')\n\nOtra medida de la calidad de los grupos es índice de Calinski-Harabasz que mide la dispersión entre grupos y dentro del grupo, al igual que Silhouette, mientras mayor sea la estadística mejor es el agrupamiento. Para el problema del Iris el índice de Calinski-Harabasz tiene un valor de \\(561.5937\\) obtenido con la siguiente instrucción.\ncal_har = metrics.calinski_harabasz_score(D, cl)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Agrupamiento</span>"
    ]
  },
  {
    "objectID": "capitulos/06Agrupamiento.html#número-de-grupos",
    "href": "capitulos/06Agrupamiento.html#número-de-grupos",
    "title": "6  Agrupamiento",
    "section": "6.6 Número de Grupos",
    "text": "6.6 Número de Grupos\nUtilizando una medida de rendimiento de agrupamiento se analizar cual sería el número adecuado de grupos para un problema dado. El procedimiento es variar el número de grupos y medir el rendimiento para cada grupo y quedarse con aquel que da el mejor rendimiento considerando también el número de grupos.\nPor ejemplo, el siguiente instrucción calcula el coeficiente de Silhouette y el índice de Calinski-Harabasz en el problema del Iris.\n\nS1 = []\nS2 = []\nfor k in range(2, 11):\n    m = KMeans(n_clusters=k, n_init='auto').fit(D)\n    cl = m.predict(D)\n    _ = metrics.silhouette_score(D, cl, metric='euclidean')\n    S1.append(_)\n    _ = metrics.calinski_harabasz_score(D, cl)\n    S2.append(_)\n\nEstas dos estadísticas se pueden observar en la Figura 6.5. En color azul se observa el coeficiente de Silhouette; donde el mejor resultado es cuando \\(K=2\\). En color naranja se muestra el índice Calinski-Harabasz done el mejor resultado se tiene cuando \\(K=3\\). Considerando que se está trabajando con el problema del Iris se conoce que la mejor agrupación es para \\(K=3\\) dado que son tres clases.\n\n\nCódigo\ndata = pd.DataFrame([{'Calinski-Harabasz': b,  'Silhouette': a, 'K': k + 2} \n                     for k, (a, b) in enumerate(zip(S1, S2))])\ndata.set_index('K', inplace=True)\nsns.set_style('whitegrid')\nsns.lineplot(data=data.Silhouette, color=sns.color_palette()[0])\nax2 = plt.twinx()\nfig = sns.lineplot(data=data['Calinski-Harabasz'], \n                   color=sns.color_palette()[1], ax=ax2)\n\n\n\n\n\n\n\n\nFigura 6.5: Rendimiento variando el número de grupos",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Agrupamiento</span>"
    ]
  },
  {
    "objectID": "capitulos/07NoParametricos.html",
    "href": "capitulos/07NoParametricos.html",
    "title": "7  Métodos No Paramétricos",
    "section": "",
    "text": "7.1 Paquetes usados\nEl objetivo de la unidad es conocer las características de diferentes métodos no paramétricos y aplicarlos para resolver problemas de regresión y clasificación.\nfrom sklearn.neighbors import NearestNeighbors,\\\n                              KNeighborsClassifier,\\\n                              KNeighborsRegressor\nfrom sklearn.metrics import pairwise_distances\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets import load_digits, load_diabetes\nfrom scipy.stats import norm\nfrom collections import Counter\nfrom matplotlib import pylab as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Métodos No Paramétricos</span>"
    ]
  },
  {
    "objectID": "capitulos/07NoParametricos.html#sec-intro-07",
    "href": "capitulos/07NoParametricos.html#sec-intro-07",
    "title": "7  Métodos No Paramétricos",
    "section": "7.2 Introducción",
    "text": "7.2 Introducción\nLos métodos paramétricos asumen que los datos provienen de un modelo común, esto da la ventaja de que el problema de estimar el modelo se limita a encontrar los parámetros del mismo, por ejemplo los parámetros de una distribución Gausiana. Por otro lado en los métodos no paramétricos asumen que datos similares se comportan de manera similar, estos algoritmos también se les conoces como algoritmos de memoria o basados en instancias.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Métodos No Paramétricos</span>"
    ]
  },
  {
    "objectID": "capitulos/07NoParametricos.html#sec-no-parametricos-histogramas",
    "href": "capitulos/07NoParametricos.html#sec-no-parametricos-histogramas",
    "title": "7  Métodos No Paramétricos",
    "section": "7.3 Histogramas",
    "text": "7.3 Histogramas\nEl primer problema que estudiaremos será la estimación no paramétrica de una función de densidad, \\(f\\), recordando que se cuenta con un conjunto \\(\\mathcal D = \\{x_i\\}\\) que es tomado de \\(f\\) y el objetivo es usar \\(\\mathcal D\\) para estimar la función de densidad \\(\\hat f\\).\nEl histograma es una manera para estimar la función de densidad. Para formar un histograma se divide la línea en \\(h\\) segmentos disjuntos, los cuales se denominan bins. El histograma corresponde a una función constante por partes, donde la altura es la proporción de elementos de \\(\\mathcal D\\) que caen en el bin analizado.\nSuponiendo que todos los valores en \\(\\mathcal D\\) están en el rango \\([0, 1]\\), los bins se pueden definir como:\n\\[\nB_1 = [0, \\frac{1}{m}), B_2=[\\frac{1}{m}, \\frac{2}{m}), \\ldots, B_m=[\\frac{m-1}{m}, 1],\n\\]\ndonde \\(m\\) es el número de bins y \\(h=\\frac{1}{m}\\). Se puede definir a \\(\\hat p_j = \\frac{1}{N} \\sum_{x \\in \\mathcal D} 1( x \\in B_j )\\) y \\(p_j = \\int_{B_j} f(u) du\\), donde \\(p_j\\) es la probabilidad del \\(j\\)-ésimo bin y \\(\\hat p_j\\) es su estimación. Usando está definición se puede definir la estimación de \\(f\\) como:\n\\[\n\\hat f(x) = \\sum_{j=1}^N \\frac{\\hat p_j}{h} 1(x \\in B_j).\n\\]\nCon esta formulación se puede ver la motivación de usar histogramas como estimador de \\(f\\) véase:\n\\[\n\\mathbb E(\\hat f(x)) = \\frac{\\mathbb E(\\hat p_j)}{h} = \\frac{p_j}{h} = \\frac{\\int_{B_j} f(u) du}{h} \\approx \\frac{hf(x)}{h} = f(x).\n\\]\n\n7.3.1 Selección del tamaño del bin\nUna parte crítica para usar un histograma es la selección de \\(h\\) o equivalente el número de bins del estimador. Utilizando el método descrito en Wasserman (2004), el cual se basa en minimizar el riesgo haciendo una validación cruzada, obteniendo la siguiente ecuación:\n\\[\n\\hat J(h) = \\frac{2}{(N-1) h} - \\frac{N+1}{(N-1) h} \\sum_{j=1}^N {\\hat p}^2_j.\n\\]\nPara ilustrar el uso de la ecuación de minimización del riesgo se utilizará en el ejemplo utilizado en Wasserman (2004). Los datos se pueden descargar de http://www.stat.cmu.edu/~larry/all-of-statistics/=Rprograms/a1882_25.dat.\nEl primer paso es leer el conjunto de datos, dentro del ejemplo usado en Wasserman (2004) se eliminaron todos los datos menores a \\(0.2\\), esto se refleja en la última línea.\n\nD = np.r_[[list(map(float, x.strip().split())) \n          for x in open(\"a1882_25.dat\").readlines()]]\nD = D[:, 2]\nD = D[D &lt;= 0.2]\n\nHaciendo un paréntesis en el ejemplo, para poder calcular \\(\\hat p_j\\) es necesario calcular el histograma; dado que los valores están normalizados podemos realizar el histograma utilizando algunas funciones de numpy y librerías tradicionales.\nPara el ilustrar el método para generar el histograma se genera un histograma con 100 bins (primera línea). El siguiente paso (segunda línea) es encontrar los límites de los bins, para este proceso se usa la función np.linspace. En la tercera línea se encuentra el bin de cada elemento, con la característica que np.searchsorted regresa \\(0\\) si el valor es menor que el límite inferior y el tamaño del arreglo si es mayor. Entonces las líneas \\(4\\) y \\(5\\) se encargan de arreglar estas dos características. Finalmente se cuenta el número de elementos que pertenecen a cada bin con la ayuda de la clase Counter.\n\nm = 100\nlimits = np.linspace(D.min(), D.max(), m + 1)\n_ = np.searchsorted(limits, D, side='right')\n_[_ == 0] = 1\n_[_ == m + 1] = m\np_j = Counter(_)\n\nRealizando el procedimiento anterior se obtiene el histograma presentado en la Figura 7.1\n\n\nCódigo\nkeys = sorted(p_j.keys())\npj = [p_j[x] for x in range(keys[0], m + 1)]\npos = list(range(10, m, 10))\nfig = sns.barplot(x=list(range(keys[0], m + 1)), y=pj)\nfig.set_xticks(ticks=pos, labels=[f'{x}' for x in pos])\nfig.set_xlabel('Número de bin')\n_ = fig.set_ylabel('Cantidad de elementos')\n\n\n\n\n\n\n\n\nFigura 7.1: Histograma\n\n\n\n\n\nUniendo estos elementos se puede definir una función de riesgo de la siguiente manera\n\ndef riesgo(D, m=10):\n    \"\"\"Riesgo de validación cruzada de histograma\"\"\"\n    N = D.shape[0]\n    limits = np.linspace(D.min(), D.max(), m + 1)\n    h = limits[1] - limits[0]\n    _ = np.searchsorted(limits, D, side='right')\n    _[_ == 0] = 1\n    _[_ == m + 1] = m\n    p_j = Counter(_)\n    cuadrado = sum([(x / N)**2 for x in p_j.values()])\n    return (2 / ((N - 1) * h)) - ((N + 1) * cuadrado / ((N - 1) * h))\n\ndonde las partes que no han sido descritas solamente implementan la ecuación \\(\\hat J(h)\\).\nFinalmente se busca el valor \\(h\\) que minimiza la ecuación, iterando por diferentes valores de \\(m\\) se obtiene la Figura 7.2 donde se observa la variación del riesgo con diferentes niveles de bin.\n\n\nCódigo\nrr = [riesgo(D, m=i) for i in range(1, 501)]\ndata = pd.DataFrame({'Riesgo': rr, 'Número de bins': list(range(1, 501))})\ndata.set_index('Número de bins', inplace=True)\n_ = sns.relplot(data, kind='line')\n\n\n\n\n\n\n\n\nFigura 7.2: Riesgo",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Métodos No Paramétricos</span>"
    ]
  },
  {
    "objectID": "capitulos/07NoParametricos.html#estimador-de-densidad-por-kernel",
    "href": "capitulos/07NoParametricos.html#estimador-de-densidad-por-kernel",
    "title": "7  Métodos No Paramétricos",
    "section": "7.4 Estimador de Densidad por Kernel",
    "text": "7.4 Estimador de Densidad por Kernel\nComo se puede observar el histograma es un estimador discreto, otro estimador muy utilizado que cuenta con la característica de ser suave es el estimador de densidad por kernel, \\(K\\), el cual está definido de la siguiente manera.\n\\[\n\\hat f(x) = \\frac{1}{hN} \\sum_{w \\in \\mathcal D} K(\\frac{x - w}{h}),\n\\]\ndonde el kernel \\(K\\) podría ser \\(K(x) = \\frac{1}{\\sqrt{2\\pi}} \\exp [-\\frac{x^2}{2}],\\) con parámetros \\(\\mu=0\\) y \\(\\sigma=1\\). La Figura 7.3 muestra la estimación obtenida, con \\(h=0.003\\), en los datos utilizados en el ejemplo del histograma.\n\n\nCódigo\ndef hat_f(x, D, h):\n    N = D.shape[0]\n    return norm.pdf((x - D) / h).sum() / (h * N)\n\nx = np.linspace(D.min(), D.max(), D.shape[0])\ndata = pd.DataFrame({'Estimación': [hat_f(_, D, 0.003) for _ in x], 'x': x})\ndata.set_index('x', inplace=True)\n_ = sns.relplot(data, kind='line')\n\n\n\n\n\n\n\n\nFigura 7.3: Estimación por Kernel\n\n\n\n\n\n\n7.4.1 Caso multidimensional\nPara el caso multidimensional el estimador quedaría como\n\\[\n\\hat f(\\mathbf x) = \\frac{1}{h^dN} \\sum_{\\mathbf w \\in \\mathcal D} K(\\frac{\\mathbf x - \\mathbf w}{h}),\n\\]\ndonde \\(d\\) corresponde al número de dimensiones. Un kernel utilizado es:\n\\[\nK(\\mathbf x) = (\\frac{1}{\\sqrt{2\\pi}})^d \\exp [- \\frac{\\mid\\mid \\mathbf x \\mid\\mid ^2}{2}].\n\\]",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Métodos No Paramétricos</span>"
    ]
  },
  {
    "objectID": "capitulos/07NoParametricos.html#estimador-de-densidad-por-vecinos-cercanos",
    "href": "capitulos/07NoParametricos.html#estimador-de-densidad-por-vecinos-cercanos",
    "title": "7  Métodos No Paramétricos",
    "section": "7.5 Estimador de Densidad por Vecinos Cercanos",
    "text": "7.5 Estimador de Densidad por Vecinos Cercanos\nDado un conjunto \\(\\mathcal D=(x_1, \\ldots, x_N)\\), es decir, donde se conoce la posición de \\(x\\) en \\(\\mathcal D\\) y una medida de distancia \\(d\\), los \\(k\\) vecinos cercanos a \\(x\\), \\(\\textsf{kNN}(x)\\), se puede calcular ordenando \\(\\mathcal D\\) de la siguiente manera. Sea \\((\\pi_1, \\pi_2, \\ldots, \\pi_N)\\) la permutación tal que \\(x_{\\pi_1}=\\textsf{arg min}_{w \\in \\mathcal D} d(x, w)\\), donde \\(w_{\\pi_1} \\in \\mathcal D\\), \\(\\pi_2\\) corresponde al segundo índice menor, y así sucesivamente. Usando esta notación los \\(k\\) vecinos corresponden a \\(\\textsf{kNN}(x)=(x_{\\pi_1}, x_{\\pi_2}, \\ldots, x_{\\pi_k}).\\)\nUna maneara intuitiva de definir \\(h\\) sería en lugar de pensar en un valor constante para toda la función, utilizar la distancia que existe con el \\(k\\) vecino mas cercano, es decir, \\(h=d(w_{\\pi_k}, x)=d_k(x)\\), donde \\(w_{\\pi_k} \\in \\mathcal D\\). Remplazando esto en el estimado de densidad por kernel se obtiene:\n\\[\n\\hat f(x) = \\frac{1}{d_k(x) N} \\sum_{w \\in \\mathcal D} K(\\frac{x - w}{d_k(x)}).\n\\]\nUtilizando los datos anteriores el estimador por vecinos cercanos, con \\(k=50\\), quedaría como:\n\n\nCódigo\ndef hat_f_k(x, D, k):\n    _ = np.fabs(D - x)\n    _.sort()\n    h = _[k]\n    N = D.shape[0]\n    return norm.pdf((x - D) / h).sum() / (h * N)\n\nx = np.linspace(D.min(), D.max(), D.shape[0])\ndata = pd.DataFrame({'Estimación': [hat_f_k(_, D, 50) for _ in x], 'x': x})\ndata.set_index('x', inplace=True)\n_ = sns.relplot(data, kind='line')\n\n\n\n\n\n\n\n\nFigura 7.4: Estimación por Vecinos Cercanos",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Métodos No Paramétricos</span>"
    ]
  },
  {
    "objectID": "capitulos/07NoParametricos.html#clasificador-de-vecinos-cercanos",
    "href": "capitulos/07NoParametricos.html#clasificador-de-vecinos-cercanos",
    "title": "7  Métodos No Paramétricos",
    "section": "7.6 Clasificador de vecinos cercanos",
    "text": "7.6 Clasificador de vecinos cercanos\nEl clasificador de vecinos cercanos es un clasificador simple de entender, la idea es utilizar el conjunto de entrenamiento y una función de distancia para asignar la clase de acuerdo a los k-vecinos más cercanos al objeto deseado.\nUtilizando la notación \\(kNN(x)\\) se define el volumen de \\(kNN(x)\\) como \\(V(x)\\) y \\(N_c(x)=\\sum_{x_{\\pi} \\in \\textsf{kNN}(x)} 1(y_\\pi=c)\\) donde \\(y_\\pi\\) es la salida asociada a \\(x_\\pi\\). \\(N_c(x)\\) corresponde al número de vecinos de \\(x\\) que pertenecen a la clase \\(c\\). Con esta notación se define la verosimilitud como:\n\\[\n\\mathbb P(\\mathcal X=x \\mid \\mathcal Y=c) = \\frac{N_c(x)}{N_c V(x)},\n\\]\ndonde \\(N_c\\) es el número de elementos en \\(\\mathcal D\\) de la clase \\(c.\\)\nUtilizando el Teorema de Bayes y sabiendo que \\(\\mathcal P(Y=c)=\\frac{N_c}{N}\\) la probabilidad a posteriori queda como:\n\\[\n\\begin{split}\n\\mathcal P(\\mathcal Y=c \\mid \\mathcal X=x) &= \\frac{\\frac{N_c(x)}{N_c V(x)} \\frac{N_c}{N}}{\\sum_u \\frac{N_u(x)}{N_u V(x)} \\frac{N_u}{N}} \\\\\n&= \\frac{N_c(x)}{\\sum_u N_u(x)} \\\\\n&= \\frac{N_c(x)}{k},\n\\end{split}\n\\]\ndonde \\(\\sum_u N_u(x)=k\\) porque \\(N_u(x)\\) corresponde al número de elementos de \\(\\textsf{kNN}(x)\\) que pertenecen a la clase \\(u\\) y en total se seleccionan \\(k\\) elementos.\n\n7.6.1 Implementación\nEl clasificador de vecinos cercanos tiene una implementación directa, aunque ineficiente, cuando el número de ejemplos en el conjunto de entrenamiento es grande. Esta implementación se ejemplifica con los datos de dígitos que se cargan y se dividen en el conjunto de entrenamiento y prueba de la siguiente manera.\n\nX, y = load_digits(return_X_y=True)\nT, G, y_t, y_g = train_test_split(X, y, test_size=0.2)\n\n\n7.6.1.1 \\(\\textsf{kNN}\\)\nLo primero que se realiza es la función para calcular los \\(\\textsf{kNN}(x)\\) esto se puede generando una función kNN que recibe de parámetros \\(x\\), el conjunto \\(\\mathcal D\\), la cantidad de vecinos (\\(k\\)) y la distancia.\nEl código de la función kNN se muestra a continuación, donde en la primera línea se convierte a \\(x\\) en un arreglo de dos dimensiones. Esto tiene el objetivo de generar un código que pueda buscar los \\(k\\) vecinos cercanos de un conjunto de puntos. Por ejemplo, se podría calcular los vecinos cercanos de todo el conjunto \\(\\mathcal G.\\)\nLa segunda línea calcula los vecinos cercanos usando la función argsort lo único que se tiene que conocer es el eje donde se va a realizar la operación que en este caso el \\(0.\\) La transpuesta es para regresar el índice de los vecinos en cada renglón.\n\ndef kNN(x, D, k=1, d=lambda x, y: pairwise_distances(x, y)):\n    x = np.atleast_2d(x)\n    return (d(D, x).argsort(axis=0))[:k].T\n\nEn este momento es importante mencionar que el problema de los \\(k\\) vecinos cercanos tiene muchas aplicaciones además del los algoritmos de aprendizaje supervisado que se verán en esta unidad. Por ejemplo, cuando uno tiene una colección de objetos que podrían ser documentos, videos, fotografías o cualquier objeto, este problema permite encontrar los objetos más cercanos a un objeto dado. Lo que se desea es que el algoritmo regrese el resultado lo antes posible y por ese motivo no se puede utilizar el algoritmo que se acaba de mencionar dado que compara \\(x\\) contra todos los elementos de \\(\\mathcal D.\\) El área que estudia este tipo de problemas es el área de Recuperación de Información.\nPor ejemplo, el siguiente código calcula los cinco vecinos más cercanos de los tres primeros elementos de \\(\\mathcal G.\\)\n\nkNN(G[:3], T, k=5)\n\narray([[1008,  476,  838, 1365,   77],\n       [ 171,  455,  940,  672, 1265],\n       [ 508,  319,   54,  228,  861]])\n\n\nLa manera más sencilla de crear el clasificador de vecinos cercanos es utilizando un método exhaustivo en el cálculo de distancia. Como se comentó, existen métodos más eficientes y la clase NearestNeighbors implementa dos de ellos adicionales al método exhaustivo. Por ejemplo, el siguiente código realiza el procedimiento equivalente al ejemplo visto previamente.\n\nknn = NearestNeighbors(n_neighbors=5).fit(T)\nknn.kneighbors(G[:3], return_distance=False)\n\narray([[1008,  476,  838, 1365,   77],\n       [ 171,  455,  940,  672, 1265],\n       [ 508,  319,   54,  228,  861]])\n\n\n\n\n7.6.1.2 \\(N_c(x)\\)\nEl clasificador se basa en la función \\(N_c(x)\\), esta función se implementa conociendo las etiquetas y \\(\\textsf{kNN}(x)\\). Aunque \\(N_c(x)\\) requiere el parámetro de la clase, la función calculará \\(N_c(x)\\) para todas las clases. La función N_c recibe de parámetros todos los parámetros de kNN y además requiere la clases de cada elemento de \\(\\mathcal D\\) estas clases se dan como un arreglo adicional. El siguiente código muestra la función, donde en la primera línea se calcula los \\(k\\) vecinos y después se transforman los índices a las clases correspondientes, el resultado es guardado en la variable knn. La segunda línea usa la clase Counter para contar la frecuencia de cada clase en cada ejemplo dado en x.\n\ndef N_c(x, D, clases, k=1,\n        d=lambda x, y: pairwise_distances(x, y)):\n    knn = clases[kNN(x, D, k=k, d=d)]\n    return [Counter(x) for x in knn]\n\nPor ejemplo, la siguiente instrucción calcula \\(N_c(x)\\) para todos los datos en \\(\\mathcal G\\) usando \\(k=5.\\)\n\nnc = N_c(G, T, y_t, k=5)\n\nEl elemento en el índice 100, tiene el siguiente resultado Counter({6: 5}), que indica que la clase \\(6\\), fue vista \\(5\\). El error de este algoritmo en el conjunto de prueba es \\(0.0056\\), calculado con las siguientes instrucciones. Se observa que la primera línea genera las predicciones usando la función most_common y a continuación se calcula el error.\n\nhy = np.array([x.most_common(n=1)[0][0] for x in nc])\nerror = (y_g != hy).mean()\n\nUna implementación del clasificador de vecinos cercanos usando métodos eficientes para calcular \\(\\textsf{kNN}\\) se encuentra en la clase KNeighborsClassifier la cual se puede utilizar de la siguiente manera.\n\nkcl = KNeighborsClassifier().fit(T, y_t)\nhy = kcl.predict(G)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Métodos No Paramétricos</span>"
    ]
  },
  {
    "objectID": "capitulos/07NoParametricos.html#sec-regresion",
    "href": "capitulos/07NoParametricos.html#sec-regresion",
    "title": "7  Métodos No Paramétricos",
    "section": "7.7 Regresión",
    "text": "7.7 Regresión\nLa idea de utilizar vecinos cercanos no es solamente para problemas de clasificación, en problemas de regresión se puede seguir un razonamiento equivalente, el único cambio es en la función \\(N_c(x)\\) donde en lugar de calcular la frecuencia de las clases de los vecinos cercanos a \\(x\\) se hace un promedio (pesado) de la respuesta de cada uno de los vecinos cercanos.\nPara ilustrar esta adecuación en problemas de regresión se utiliza el conjunto de datos de diabetes, estos datos y los conjuntos se obtienen con las siguientes instrucciones.\n\nX, y = load_diabetes(return_X_y=True)\nT, G, y_t, y_g = train_test_split(X, y, test_size=0.2)\n\nSe puede observar en la función regresion que la diferencia con clasificación es que se calcula el promedio, en lugar de contar la frecuencia de las clases.\n\ndef regresion(x, D, respuesta, k=1,\n              d=lambda x, y: pairwise_distances(x, y)):\n    knn = respuesta[kNN(x, D, k=k, d=d)]\n    return knn.mean(axis=1)\n\nLa media del error absoluto en el conjunto \\(\\mathcal G\\) es \\(49.9820\\) calculado con las siguientes instrucciones.\nhy = regresion(G, T, y_t, k=5)\nerror = np.fabs(y_g - hy).mean()\nLa clase equivalente a KNeighborsClassifier para regresión es KNeighborsRegressor la cual se puede utilizar asi.\n\nkrg = KNeighborsRegressor().fit(T, y_t)\nhy = krg.predict(G)\n\n\n\n\n\n\n\nWasserman, Larry. 2004. All of Statistics : A Concise Course in Statistical Inference. Springer. https://doi.org/10.1007/978-0-387-21736-9.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Métodos No Paramétricos</span>"
    ]
  },
  {
    "objectID": "capitulos/08Arboles.html",
    "href": "capitulos/08Arboles.html",
    "title": "8  Árboles de Decisión",
    "section": "",
    "text": "8.1 Paquetes usados\nEl objetivo de la unidad es conocer y aplicar árboles de decisión a problemas de clasificación y regresión.\nfrom sklearn import tree\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets import load_breast_cancer, load_diabetes\nfrom sklearn.inspection import DecisionBoundaryDisplay\nfrom scipy.stats import multivariate_normal\nfrom matplotlib import pylab as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Árboles de Decisión</span>"
    ]
  },
  {
    "objectID": "capitulos/08Arboles.html#sec-intro-08",
    "href": "capitulos/08Arboles.html#sec-intro-08",
    "title": "8  Árboles de Decisión",
    "section": "8.2 Introducción",
    "text": "8.2 Introducción\nLos árboles de decisión son una estructura de datos jerárquica, la cual se construye utilizando una estrategia de divide y vencerás. Los árboles son un método no paramétrico diseñado para problemas de regresión y clasificación.\nEl árbol se camina desde la raíz hacia las hojas; en cada nodo se tiene una regla que muestra el camino de acuerdo a la entrada y la hoja indica la clase o respuesta que corresponde a la entrada.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Árboles de Decisión</span>"
    ]
  },
  {
    "objectID": "capitulos/08Arboles.html#sec-arboles-clasificacion",
    "href": "capitulos/08Arboles.html#sec-arboles-clasificacion",
    "title": "8  Árboles de Decisión",
    "section": "8.3 Clasificación",
    "text": "8.3 Clasificación\nUtilizando el procedimiento para generar tres Distribuciones Gausianas (Sección 2.3.1) se generan las siguientes poblaciones (Figura 8.1) con medias \\(\\mu_1=[5, 5]^\\intercal\\), \\(\\mu_2=[-5, -10]^\\intercal\\) y \\(\\mu_3=[15, -6]^\\intercal\\); utilizando las matrices de covarianza originales.\n\n\nCódigo\nseed = 1\nX_1 = multivariate_normal(mean=[5, 5],\n                          seed=seed,\n                          cov=[[4, 0], [0, 2]]).rvs(1000)\nX_2 = multivariate_normal(mean=[-5, -10],\n                          seed=seed,\n                          cov=[[2, 1], [1, 3]]).rvs(1000)\nX_3 = multivariate_normal(mean=[15, -6],\n                          seed=seed,\n                          cov=[[2, 3], [3, 7]]).rvs(1000)\ndf = pd.DataFrame([dict(x=x, y=y, clase=1) for x, y in X_1] + \\\n                  [dict(x=x, y=y, clase=2) for x, y in X_2] + \\\n                  [dict(x=x, y=y, clase=3) for x, y in X_3])\nsns.relplot(data=df, kind='scatter',\n            x='x', y='y', hue='clase')\n\n\n\n\n\n\n\n\nFigura 8.1: Tres distribuciones Gausianas\n\n\n\n\n\nCon estas tres poblaciones, donde cada distribución genera una clase se crea un árbol de decisión. El árbol se muestra en la Figura 8.2, donde se observa, en cada nodo interno, la siguiente información. La primera línea muestra el identificador del nodo, la segunda corresponde a la función de corte, la tercera línea es la entropía (\\(H(\\mathcal Y) = -\\sum_{y \\in \\mathcal Y} \\mathbb P(\\mathcal Y=y) \\log_2 \\mathbb P(\\mathcal Y=y)\\)), la cuarta es el número de elementos que llegaron al nodo y la última la frecuencia de cada clase en ese nodo.\n\n\nCódigo\nX = np.concatenate((X_1, X_2, X_3), axis=0)\ny = np.array([1] * 1000 + [2] * 1000 + [3] * 1000)\narbol = tree.DecisionTreeClassifier(criterion='entropy').fit(X, y)\n_ = tree.plot_tree(arbol, node_ids=True,\n                   feature_names=['x', 'y'], label='root')\n\n\n\n\n\n\n\n\nFigura 8.2: Árbol de decisión\n\n\n\n\n\nPor ejemplo el nodo raíz del árbol tiene una entropía de \\(1.5850\\), la función de decisión es \\(x \\leq 10.5605\\) que indica que todos los elementos con un valor en \\(x\\) menor o igual del valor calculado están del lado izquierdo. Los hojas (nodos #2, #3, #5, y #6) no cuentan con una función de corte, dado que son la parte final del árbol. En el árbol mostrado se observa que la entropía en todos los casos es \\(0\\), lo cual indica que todos los elementos que llegaron a ese nodo son de la misma clase. No en todos los casos las hojas tienen entropía cero y existen parámetros en la creación del árbol que permiten crear árboles más simples. Por ejemplo, hay hojas que tienen muy pocos ejemplos, uno se podría preguntar ¿qué pasaría si esas hojas se eliminan? para tener un árbol más simple.\nLa siguiente Figura 8.3 muestra el árbol generado cuando se remueven el nodo #6. Se observa un árbol con menos nodos, aunque la entropía en es diferente de cero en algunas hojas. La segunda parte de la figura muestra la función de decisión que genera el árbol de decisión. Se observa que cada regla divide el espacio en dos usando la información que se muestra en cada nodo.\n\n\nCódigo\nax = plt.subplot(2, 1, 1)\narbol = tree.DecisionTreeClassifier(criterion='entropy', min_samples_split=1003).fit(X, y)\n_ = tree.plot_tree(arbol, node_ids=True,\n                   feature_names=['x', 'y'], label='root')\nax = plt.subplot(2, 1, 2)\nDecisionBoundaryDisplay.from_estimator(arbol, X, cmap=plt.cm.RdYlBu,\n                                       response_method='predict',\n                                       ax=ax, xlabel='x', ylabel='y')\nfor i, color in enumerate('ryb'):\n  mask = y == (i + 1)\n  plt.scatter(X[mask, 0], X[mask, 1], c=color,\n              label=f'{i+1}', cmap=plt.cm.RdYlBu, edgecolor='black')\n\n\n\n\n\n\n\n\nFigura 8.3: Árbol de decisión y función\n\n\n\n\n\n\n8.3.1 Predicción\nUtilizando el árbol y la función de decisión mostrada en Figura 8.3, se puede explicar el proceso de clasificar un nuevo elemento. Por ejemplo, el elemento \\(\\mathbf u=(x=-3, y=0.5)\\) pasaría por los nodos #0, #1 y #3 para llegar a la clase correspondiente.\n\n\n8.3.2 Entrenamiento\nExisten diferentes sistemas para la generación de un árbol de decisión (e.g., Quinlan (1986)) la mayoría de ellos comparten las siguiente estructura general. La construcción un árbol se realiza mediante un procedimiento recursivo en donde se aplica la función de corte \\(f_m(\\mathbf x) = x_i \\leq a\\) en el nodo \\(m\\), donde el parámetro \\(a\\) y la componente \\(x_i\\) se identifican utilizando los datos que llegan al nodo \\(m\\) de tal manera que se maximice una función de costo.\nUna función de costo podría estar basada en la entropía, es decir, para cada posible corte se mide la entropía en los nodos generados y se calcula la esperanza de la entropía de la siguiente manera.\n\\[\nL(x_i, a) = \\sum_h \\frac{\\mid \\mathcal D_h \\mid}{\\mid \\mathcal D_m \\mid}  H(\\mathcal D_h),\n\\]\ndonde \\(H(\\mathcal D_h)\\) es la entropía de las etiquetas del conjunto \\(\\mathcal D_h\\), la entropía se puede calcular con la siguiente función. La función recibe un arreglo con las clases, está protegida para calcular \\(0 \\log 0 = 0\\) y finalmente regresa la entropía de arr.\n\ndef H(arr):\n    a, b = np.unique(arr, return_counts=True)\n    b = b / b.sum()\n    return - (b * np.log2(b, where=b != 0)).sum()\n\nLa función que optimiza \\(L(x_i, a),\\) para encontrar \\(a\\) se implementa en el procedimiento corte_var. Este procedimiento asume que las etiquetas (labels) están ordenadas por la variable \\(x_i\\), es decir la primera etiqueta corresponde al valor mínimo de \\(x_i\\) y la última al valor máximo. Considerando esto, el valor de \\(a\\) es el índice con el menor costo. En la primera línea se inicializa la variable mejor para guardar el valor de \\(a\\) con mejor costo. La segunda línea corresponde a \\(\\mid \\mathcal D_m \\mid\\), en la tercera línea se identifican los diferentes valores de \\(a\\) que se tiene que probar, solo se tienen que probar aquellos puntos donde cuando la clase cambia con respecto al elemento adyacente, esto se calcula con la función np.diff; dado que está quita el primer elemento entonces es necesario incrementar \\(1.\\) El ciclo es por todos los puntos de corte, se calculan el costo para los elementos que están a la izquierda y derecha del corte y se compara el resultado con el costo con menor valor encontrado hasta el momento. La última línea regresa el costo mejor así como el índice donde se encontró.\n\ndef corte_var(labels):\n    mejor = (np.inf, None)\n    D_m = labels.shape[0]\n    corte = np.where(np.diff(labels))[0] + 1\n    for j in corte:\n        izq = labels[:j]\n        der = labels[j:]\n        a = (izq.shape[0] / D_m) * H(izq)\n        b = (der.shape[0] / D_m) * H(der)\n        perf = a + b\n        if perf &lt; mejor[0]:\n          mejor = (perf, j)\n    return mejor\n\nEn el siguiente ejemplo se usa la función corte_var; la función regresa un costo de \\(0.4591\\) y el punto de corte es el elemento \\(3\\), se puede observar que es el mejor punto de corte en el arreglo dado.\n\ncosto, indice = corte_var(np.array([0, 0, 1, 0, 0, 0]))\n\nCon la función corte_var se optimiza el valor \\(a\\) de \\(L(x_i, a)\\), ahora es el turno de optimizar \\(x_i\\) con respecto a la función de costo. El procedimiento corte encuentra el mínimo con respecto de \\(x_i\\), está función recibe los índices (idx) donde se buscará estos valores, en un inicio idx es un arreglo de \\(0\\) al número de elemento del conjunto \\(\\mathcal D\\) menos uno. La primera línea define la variable donde se guarda el menor costo, en la segunda línea se ordenan las variables, la tercera línea se obtienen las etiquetas involucradas. El ciclo va por todas las variables \\(x_i\\). Dentro del ciclo se llama a la función corte_var donde se observa como las etiquetas van ordenadas de acuerdo a la variable que se está analizando; la función regresa el corte con menor costo y se compara con el menor costo obtenido hasta el momento, si es menor se guarda en mejor. Finalmente, se regresa mejor y los índices ordenados para poder identificar los elementos del hijo izquierdo y derecho.\n\ndef corte(idx):\n    mejor = (np.inf, None, None)\n    orden = np.argsort(X[idx], axis=0)\n    labels = y[idx]\n    for i, x in enumerate(orden.T):\n        comp = corte_var(labels[x])\n        if comp[0] &lt; mejor[0]:\n            mejor = (comp[0], i, comp[1])\n    return mejor, idx[orden[:, mejor[1]]]\n\nCon la función corte se puede encontrar los parámetros de la función de corte \\(f_m(\\mathbf x) = x_i \\leq a\\) para cada nodo del árbol completo del ejemplo anterior. Por ejemplo, los parámetros de la función de decisión para la raíz (#0) que se observa en la Figura 8.3 se puede obtener con el siguiente código.\n\nbest, orden = corte(np.arange(X.shape[0]))\nperf, i, j = best\n(X[orden[j], i] + X[orden[j-1], i]) / 2\n\n10.560464864725406\n\n\nLa variable orden tiene la información para dividir el conjunto dado, lo cual se realiza en las siguientes instrucciones, donde idx_i corresponde a los elementos a la izquierda y idx_d son los de la derecha.\n\nidx_i = orden[:j]\nidx_d = orden[j:]\n\nTeniendo los elementos a la izquierda y derecha, se puede calcular los parámetros de la función de corte del nodo #1 los cuales se pueden calcular con las siguientes instrucciones.\n\nbest, orden = corte(idx_i)\nperf, i, j = best\n(X[orden[j], i] + X[orden[j-1], i]) / 2\n\n-1.8516821607950367\n\n\n\n\n\n\n\n\nNota\n\n\n\nLa función corte no verifica que se esté en una hoja, entonces si se hace el corte en una hora regresará (np.inf, none, None)\n\n\n\n\n8.3.3 Ejemplo: Breast Cancer Wisconsin\nSe utiliza el conjunto de datos de Breast Cancer Wisconsin para ejemplificar el algoritmo de Árboles de Decisión. Las siguientes instrucciones se descargan los datos y se dividen en los conjuntos de entrenamiento y prueba.\n\nX, y = load_breast_cancer(return_X_y=True)\nT, G, y_t, y_g = train_test_split(X, y, test_size=0.2)\n\nLa siguiente instrucción entrena un árbol de decisión utilizando como función de costo la entropía. En la librería se encuentran implementadas otras funciones como el coeficiente Gini y Entropía Cruzada Sección 4.2.7 (Log-loss).\n\narbol = tree.DecisionTreeClassifier(criterion='entropy').fit(T, y_t)\n\nComo es de esperarse la predicción se realiza con el método predict como se ve a continuación.\n\nhy = arbol.predict(G)\n\nEl error en el conjunto de prueba \\(\\mathcal G\\) es \\(0.0439\\), se puede comparar este error con otros algoritmos utilizados en este conjunto como clasificadores paramétricos basados en distribuciones Gausianas (Sección 3.8.3). La siguiente instrucción muestra el cálculo del error.\n\nerror = (y_g != hy).mean()\n\nUn dato interesante, considerando los parámetros con los que se inicializó el árbol, entonces este hizo que todas las hojas fueran puras, es decir, con entropía cero. Por lo tanto el error de clasificación en el conjunto de entrenamiento \\(\\mathcal T\\) es cero, como se puede verificar con el siguiente código.\n\n(y_t != arbol.predict(T)).mean()\n\n0.0",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Árboles de Decisión</span>"
    ]
  },
  {
    "objectID": "capitulos/08Arboles.html#regresión",
    "href": "capitulos/08Arboles.html#regresión",
    "title": "8  Árboles de Decisión",
    "section": "8.4 Regresión",
    "text": "8.4 Regresión\nLos árboles de decisión aplicados a problemas de regresión siguen una idea equivalente a los desarrollados en problemas de clasificación. Para ejemplificar las diferencias se utiliza el siguiente problema sintético; el cual corresponde a la suma de un seno y un coseno como se muestra a continuación.\n\nX = np.linspace(-5, 5, 100)\ny = np.sin(X) + 0.3 * np.cos(X * 3.)\n\nCon este problema se genera un árbol de decisión utilizando la siguiente instrucción. El método fit espera recibir un arreglo en dos dimensiones por eso se usa la función np.atleast_2d y se calcula la transpuesta siguiendo el formato esperado. Se observa el uso del parámetro max_depth para limitar la profundidad del árbol de decisión.\n\narbol = tree.DecisionTreeRegressor(max_depth=3).fit(np.atleast_2d(X).T, y)\n\nEl árbol de decisión obtenido se muestra en la Figura 8.4. La información que se muestra en cada nodo interno es equivalente a la mostrada en los árboles de clasificación. La diferencia es que en los árboles de regresión se muestra el promedio (value) de las salidas que llegan a ese nodo y en regresión es la frecuencia de clases. Se observa que si la entrada es \\(x=-4.5\\) entonces la respuesta la da el nodo #4 con un valor de \\(1.088.\\)\n\n\nCódigo\n_ = tree.plot_tree(arbol, node_ids=True,\n                   feature_names=['x'], label='root')\n\n\n\n\n\n\n\n\nFigura 8.4: Árbol de Regresión\n\n\n\n\n\n\n8.4.1 Predicción\nEl árbol anterior se usa para predecir todos los puntos del conjunto de entrenamiento, el resultado se muestra en la Figura 8.5. Se observa que la predicción es discreta, son escalones y esto es porque las hojas predicen el promedio de los valores que llegaron hasta ahí, en este caso el árbol tiene 8 hojas entonces a lo más ese árbol puede predecir 8 valores distintos.\n\n\nCódigo\ndf = pd.DataFrame(dict(X=X, y=y, \n                       predicción=arbol.predict(np.atleast_2d(X).T)))\ndf.set_index('X', inplace=True)\nsns.relplot(df, kind='line')\n\n\n\n\n\n\n\n\nFigura 8.5: Problema de regresión\n\n\n\n\n\n\n\n8.4.2 Entrenamiento\nCon respecto al proceso de entrenamiento la diferencia entre clasificación y regresión se encuentra en la función de costo que guía el proceso de optimización. En el caso de clasificación la función de costo era la esperanza de la entropía. Por otro lado, en regresión una función de costo utilizada es la varianza que es el error cuadrático que se muestra en los nodos. Para ejemplificar el uso de esta función de costo se utilizan los datos de Diabetes tal y como se muestran en las siguientes instrucciones.\n\nX, y = load_diabetes(return_X_y=True)\nT, G, y_t, y_g = train_test_split(X, y, test_size=0.2)\n\nCon los datos de entrenamiento se genera el siguiente árbol de decisión para regresión. Solamente se muestran la información de la raíz y sus dos hijos. En la raíz se observa los parámetros de la función de corte, se selecciona la variable con índice 8 y se envían 235 elementos al hijo izquierdo y el resto al hijo derecho.\n\narbol = tree.DecisionTreeRegressor().fit(T, y_t)\n_ = tree.plot_tree(arbol, max_depth=1)\n\n\n\n\n\n\n\n\nEl siguiente método implementa la función de corte para regresión se puede observar que la única diferente con la función corte_var definida en clasificación (Sección 8.3) es que la entropía H se cambia por la varianza np.var.\n\ndef corte_var(response):\n    mejor = (np.inf, None)\n    D_m = response.shape[0]\n    corte = np.where(np.diff(response))[0] + 1\n    for j in corte:\n        izq = response[:j]\n        der = response[j:]\n        a = (izq.shape[0] / D_m) * np.var(izq)\n        b = (der.shape[0] / D_m) * np.var(der)\n        perf = a + b\n        if perf &lt; mejor[0]:\n          mejor = (perf, j)\n    return mejor    \n\nLa función corte_var de regresión se utiliza para encontrar el punto de corte en los datos del conjunto de entrenamiento de la siguiente manera. En la primera línea se ordenan las variables independientes y en la segunda línea se itera por todas las variables independientes para calcular el corte con costo mínimo.\n\norden = T.argsort(axis=0)\nres = [corte_var(y_t[orden[:, x]]) for x in range(10)]\nres\n\n[(5754.610581796953, 184),\n (5927.398638755012, 45),\n (4465.142942696684, 228),\n (4850.731227639909, 246),\n (5629.657991017557, 207),\n (5705.344226123572, 237),\n (5190.197430187472, 137),\n (4858.986024790986, 142),\n (4291.730795960237, 170),\n (5146.657059497997, 259)]\n\n\nEl resultado de ejecutar el código anterior se muestra a continuación; donde se observa que el costo mínimo corresponde a la variable con índice 8 tal y como se muestra en la figura anterior nodo derecho de la raíz.\n\n\n\n\n\n\nQuinlan, J. R. 1986. «Induction of decision trees». Machine Learning 1986 1:1 1 (marzo): 81-106. https://doi.org/10.1007/BF00116251.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Árboles de Decisión</span>"
    ]
  },
  {
    "objectID": "capitulos/09Lineal.html",
    "href": "capitulos/09Lineal.html",
    "title": "9  Discriminantes Lineales",
    "section": "",
    "text": "9.1 Paquetes usados\nEl objetivo de la unidad es conocer y aplicar diferentes métodos lineales de discriminación para atacar problemas de clasificación.\nfrom sklearn.svm import LinearSVC, SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score, recall_score, precision_score\nfrom scipy.stats import multivariate_normal\nfrom sklearn.datasets import load_iris\nfrom matplotlib import pylab as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Discriminantes Lineales</span>"
    ]
  },
  {
    "objectID": "capitulos/09Lineal.html#sec-intro-09",
    "href": "capitulos/09Lineal.html#sec-intro-09",
    "title": "9  Discriminantes Lineales",
    "section": "9.2 Introducción",
    "text": "9.2 Introducción\nEn unidades anteriores se han visto diferentes técnicas para discriminar entre clases; en particular se ha descrito el uso de la probabilidad \\(\\mathbb P(\\mathcal Y \\mid \\mathcal X)\\) para encontrar la clase más probable. Los parámetros de \\(\\mathbb P(\\mathcal Y \\mid \\mathcal X)\\) se han estimado utilizando métodos paramétricos y no paramétricos. En está unidad se describe el uso de funciones discriminantes para la clasificación y su similitud con el uso de \\(\\mathbb P(\\mathcal Y \\mid \\mathcal X).\\)",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Discriminantes Lineales</span>"
    ]
  },
  {
    "objectID": "capitulos/09Lineal.html#sec-discriminante",
    "href": "capitulos/09Lineal.html#sec-discriminante",
    "title": "9  Discriminantes Lineales",
    "section": "9.3 Función Discriminante",
    "text": "9.3 Función Discriminante\nEn la unidad de Teoría de Decisión Bayesiana (Capítulo 2) se describió el uso de \\(\\mathbb P(\\mathcal Y \\mid \\mathcal X)\\) para clasificar, se mencionó que la clase a la que pertenece \\(\\mathcal X=x\\) es la de mayor probabilidad, es decir,\n\\[\nC(x) = \\textsf{argmax}_{k=1}^K \\mathbb P(\\mathcal Y=k \\mid \\mathcal X=x),\n\\]\ndonde \\(K\\) es el número de clases y \\(\\mathcal Y=k\\) representa la \\(k\\)-ésima clase. Considerando que la evidencia es un factor que normaliza, entonces, \\(C(x)\\) se puede definir de la siguiente manera.\n\\[\nC(x) = \\textsf{argmax}_{k=1}^K \\mathbb P(\\mathcal X=x \\mid \\mathcal Y=k)\\mathbb P(\\mathcal Y=k).\n\\]\nAgrupando la probabilidad a priori y verosimilitud en una función \\(g_k,\\) es decir, \\(g_k(x) = P(\\mathcal X=x \\mid \\mathcal Y=k)\\mathbb P(\\mathcal Y=k),\\) hace que \\(C(x)\\) se sea:\n\\[\nC(x) = \\textsf{argmax}_{k=1}^K g_k(x).\n\\]\nObservando \\(C(x)\\) y olvidando los pasos utilizados para derivarla, uno se puede imaginar que lo único necesario para generar un clasificador de \\(K\\) clases es definir un conjunto de functions \\(g_k\\) que separen las clases correctamente. En esta unidad se presentan diferentes maneras para definir \\(g_k\\) con la característica de que todas ellas son lineales, e.g., \\(g_k(\\mathbf x) = \\mathbf w_k \\cdot \\mathbf x + w_{k_0}.\\)\n\n9.3.1 Clasificación Binaria\nLa descripción de discriminantes lineales empieza con el caso particular de dos clases, i.e., \\(K=2\\). En este caso \\(C(\\mathbf x)\\) es encontrar el máximo de las dos funciones \\(g_1\\) y \\(g_2\\). Una manear equivalente sería definir a \\(C(\\mathbf x)\\) como\n\\[\nC(\\mathbf x) = \\textsf{sign}(g_1(\\mathbf x) - g_2(\\mathbf x)),\n\\]\ndonde \\(\\textsf{sign}\\) es la función que regresa el signo, entonces solo queda asociar el signo positivo a la clase 1 y el negativo a la clase 2. Utilizando esta definición se observa lo siguiente\n\\[\n\\begin{split}\n    g_1(\\mathbf x) - g_2(\\mathbf x) &= (\\mathbf w_1 \\cdot \\mathbf x + w_{1_0}) - (\\mathbf w_2 \\cdot \\mathbf x + w_{2_0}) \\\\\n         &= (\\mathbf w_1 + \\mathbf w_2) \\cdot \\mathbf x + (w_{1_0} - w_{2_0}) \\\\\n         &= \\mathbf w \\cdot \\mathbf x + w_0\n\\end{split},\n\\]\ndonde se concluye que para el caso binario es necesario definir solamente una función discriminante y que los parámetros de esta función son \\(\\mathbf w\\) y \\(\\mathbf w_0.\\) Otra característica que se ilustra es que el parámetro \\(\\mathbf w_0\\) está actuando como un umbral, es decir, \\(\\mathbf x\\) corresponde a la clase positiva si \\(\\mathbf w \\cdot \\mathbf x &gt; -w_0.\\)\nEn la Figura 9.1 se observa el plano (linea) que divide las dos clases, este plano representa los puntos que satisfacen \\(g(\\mathbf x)=0\\).\n\n\nCódigo\nX_1 = multivariate_normal(mean=[15, 20],\n                          seed=0,\n                          cov=[[3, -3], [-3, 8]]).rvs(1000)\nX_2 = multivariate_normal(mean=[5, 5],\n                          seed=0,\n                          cov=[[4, 0], [0, 2]]).rvs(1000)\nT = np.concatenate((X_1, X_2))\ny_t = np.array(['P'] * X_1.shape[0] + ['N'] * X_2.shape[0])\nlinear = LinearSVC(dual=False).fit(T, y_t)\nw_1, w_2 = linear.coef_[0]\nw_0 = linear.intercept_[0]\ng_0 = [dict(x1=x, x2=y, tipo='g(x)=0')\n       for x, y in zip(T[:, 0], (-w_0 - w_1 * T[:, 0]) / w_2)]\ndf = pd.DataFrame(g_0 + \\\n                  [dict(x1=x, x2=y, clase='P') for x, y in X_1] + \\\n                  [dict(x1=x, x2=y, clase='N') for x, y in X_2]\n                 )\nax = sns.scatterplot(data=df, x='x1', y='x2', hue='clase', legend=True)\nsns.lineplot(data=df, x='x1', y='x2', ax=ax, hue='tipo', palette=['k'], legend=True)\n_ = ax.axis('equal')\n\n\n\n\n\n\n\n\nFigura 9.1: Función Discriminante\n\n\n\n\n\n\n\n9.3.2 Geometría de la Función de Decisión\nLa función discriminante \\(g(\\mathbf x) = \\mathbf w \\cdot \\mathbf x + w_0\\) tiene una representación gráfica. Lo primero que se observa es que los parámetros \\(\\mathbf w\\) viven en al mismo espacio que los datos, tal y como se puede observar en la Figura 9.2.\n\n\nCódigo\n_ = pd.DataFrame([dict(x1=w_1, x2=w_2, clase='w')])\ndf = pd.concat((df, _), axis=0)\nax = sns.scatterplot(data=df, x='x1', y='x2', hue='clase', legend=True)\nsns.lineplot(data=df, x='x1', y='x2', ax=ax, hue='tipo', palette=['k'], legend=True)\n_ = ax.axis('equal')\n\n\n\n\n\n\n\n\nFigura 9.2: Función discriminante\n\n\n\n\n\nSiguiendo con la descripción, los parámetros \\(\\mathbf w\\) y la función \\(g(\\mathbf x)\\) son ortogonales, tal y como se muestra en la Figura 9.3. Analiticamente la ortogonalidad se define de la siguiente manera. Sea \\(\\mathbf x_a\\) y \\(\\mathbf x_b\\) dos puntos en \\(g(\\mathbf x)=0\\), es decir,\n\\[\n\\begin{split}\ng(\\mathbf x_a) &= g(\\mathbf x_b) \\\\\n\\mathbf w \\cdot \\mathbf x_a + w_0 &= \\mathbf w \\cdot \\mathbf x_b + w_0\\\\\n\\mathbf w \\cdot (\\mathbf x_a -  \\mathbf x_b) &= 0,\n\\end{split}\n\\]\ndonde el vector \\(\\mathbf x_a -  \\mathbf x_b\\) es paralelo a \\(g(\\mathbf x)=0\\), ortogonal a \\(\\mathbf w\\) y el sub-espacio generado por \\(\\mathbf w \\cdot (\\mathbf x_a -  \\mathbf x_b) = 0\\) pasa por el origen.\n\n\nCódigo\nw = np.array([w_1, w_2]) / np.linalg.norm([w_1, w_2])\nlen_0 = w_0 / np.linalg.norm([w_1, w_2])\ndf = pd.DataFrame(g_0 + \\\n                  [dict(x1=x, x2=y, clase='P') for x, y in X_1] + \\\n                  [dict(x1=x, x2=y, clase='N') for x, y in X_2] + \\\n                  [dict(x1=0, x2=0, tipo='lw'),\n                   dict(x1=-w[0]*len_0, x2=-w[1]*len_0, tipo='lw')]\n                 )\nax = sns.scatterplot(data=df, x='x1', y='x2', hue='clase', legend=True)\nsns.lineplot(data=df, x='x1', y='x2', ax=ax, hue='tipo',\n             palette=['k'] + sns.color_palette()[2:3],\n             legend=True)\n_ = ax.axis('equal')\n\n\n\n\n\n\n\n\nFigura 9.3: Visualizando que \\(\\mathbf w\\) y la función discriminante son ortogonales.\n\n\n\n\n\nEn la figura anterior, \\(\\ell \\mathbf w\\) corresponde al vector \\(\\mathbf w\\) multiplicado por un factor \\(\\ell\\) de tal manera que intersecte con \\(g(\\mathbf x)=0.\\) El factor \\(\\ell\\) corresponde a la distancia que hay del origen a \\(g(\\mathbf x)=0\\) la cual es \\(\\ell = \\frac{w_0}{\\mid\\mid \\mathbf w \\mid\\mid}.\\) El signo de \\(\\ell\\) indica el lado donde se encuentra el origen con respecto a \\(g(\\mathbf x)=0.\\)\nLa Figura 9.4 muestra en rojo la línea generada por \\(\\mathbf w \\cdot \\mathbf x=0\\), la función discriminante \\(g(\\mathbf x)=0\\) (negro), la línea puntuada muestra la distancia entre ellas, que corresponde a \\(\\ell\\) y el vector \\(\\mathbf w\\). Visualmente, se observa que \\(\\mathbf w\\) está pegado a la línea roja, pero esto solo es un efecto de la resolución y estos elementos no se tocan.\n\n\nCódigo\nvec = np.array([1, (- w_1 * 1) / w_2])\nx_max = T[:, 0].max()\nlength = np.linalg.norm(np.array([x_max, (-w_0 - w_1 * x_max) / w_2]) -\n                        np.array([-w[0]*len_0, -w[1]*len_0]))\nvec_der = length * vec / np.linalg.norm(vec)\nx_min = T[:, 0].min()\nlength = np.linalg.norm(np.array([x_min, (-w_0 - w_1 * x_min) / w_2]) -\n                        np.array([-w[0]*len_0, -w[1]*len_0]))\nvec_izq = -length * vec / np.linalg.norm(vec)\n\ng = [dict(x1=x, x2=(- w_1 * x) / w_2, tipo='wx=0')\n     for x in np.linspace(vec_izq[0], vec_der[0])]\ndf = pd.DataFrame([dict(x1=x, x2=y, clase='P') for x, y in X_1] + \\\n                  [dict(x1=x, x2=y, clase='N') for x, y in X_2] +\\\n                  [dict(x1=w_1, x2=w_2, clase='w')] +\\\n                  g_0 + g)\nax = sns.scatterplot(data=df, x='x1', y='x2', hue='clase', legend=True)\nsns.lineplot(data=df, x='x1', y='x2', ax=ax, hue='tipo',\n             palette=['k'] + sns.color_palette()[3:4],\n             legend=True)\nax.plot([vec_der[0], x_max], [vec_der[1], (-w_0 - w_1 * x_max) / w_2], '--',\n        color=sns.color_palette()[4])\n_ = ax.axis('equal')\n\n\n\n\n\n\n\n\nFigura 9.4: Geometría de la función discriminante.\n\n\n\n\n\nFinalmente, será de utilidad representar a cada punto en \\(\\mathcal D\\) de la siguiente manera\n\\[\n\\mathbf x = \\mathbf x_g + \\ell \\frac{\\mathbf w}{\\mid\\mid \\mathbf w \\mid\\mid},\n\\]\ndonde \\(\\mathbf x_g\\) corresponde a la proyección en el hiperplano (\\(g(\\mathbf x) = 0\\)) de \\(\\mathbf x\\) y \\(\\ell\\) es la distancia que hay del hiperplano a \\(\\mathbf x\\). Utilizando esta representación se puede derivar la distancia \\(\\ell\\) de \\(\\mathbf x\\) con el siguiente procedimiento.\n\\[\n\\begin{split}\ng(\\mathbf x) &= g(\\mathbf x_g + \\ell \\frac{\\mathbf w}{\\mid\\mid \\mathbf w \\mid\\mid})\\\\\n&= \\mathbf w \\cdot (\\mathbf x_g + \\ell \\frac{\\mathbf w}{\\mid\\mid \\mathbf w \\mid\\mid}) + w_0\\\\\n&= \\mathbf w \\cdot (\\mathbf x_g + \\ell \\frac{\\mathbf w}{\\mid\\mid \\mathbf w \\mid\\mid})\\\\\n&= \\mathbf w \\cdot \\mathbf x_g + \\ell \\mathbf w \\cdot \\frac{\\mathbf w}{\\mid\\mid \\mathbf w \\mid\\mid}\\\\\n&= \\ell \\mathbf w \\cdot \\frac{\\mathbf w}{\\mid\\mid \\mathbf w \\mid\\mid}\\\\\n&= \\ell \\mid\\mid\\mathbf w\\mid\\mid\\\\\n\\ell &= \\frac{g(\\mathbf x)}{\\mid\\mid\\mathbf w \\mid\\mid}\n\\end{split}\n\\tag{9.1}\\]\nComo ya se había visto la distancia del origen al hiperplano está dada por \\(\\ell_0 = \\frac{w_0}{\\mid\\mid\\mathbf w \\mid\\mid}\\) y de cualquier elemento por \\(\\ell_{\\mathbf x} = \\frac{g(\\mathbf x)}{\\mid\\mid\\mathbf w \\mid\\mid}.\\) La Figura 9.5 muestra la \\(\\ell_{\\mathbf x}\\) en un elemento de la clase negativa. Se puede observar el punto \\(\\mathbf x_g\\) que es donde intersecta la línea con el hiperplano.\n\n\nCódigo\npoint = X_2[X_2.argmax(axis=0)[1]]\npoint_g = vec *  np.dot(point, vec) / np.dot(vec, vec) - len_0 * w\ndf = pd.DataFrame(g_0 + \\\n                  [dict(x1=x, x2=y, clase='P') for x, y in X_1] +\\\n                  [dict(x1=x, x2=y, clase='N') for x, y in X_2] +\\\n                  [dict(x1=point_g[0], x2=point_g[1], tipo='lx')] +\\\n                  [dict(x1=point[0], x2=point[1], tipo='lx')]                  \n                 )\nax = sns.scatterplot(data=df, x='x1', y='x2', hue='clase', legend=True)\nsns.lineplot(data=df, x='x1', y='x2', ax=ax,\n             hue='tipo',palette=['k'] + sns.color_palette()[4:5], legend=True)\n_ = ax.axis('equal')\n\n\n\n\n\n\n\n\nFigura 9.5: Distancia (\\(\\ell_{\\mathbf x} = x\\)) de un elemento al hiperplano\n\n\n\n\n\nConsiderando que el problema mostrado en la figura anterior está en \\(\\mathbb R^2\\), entonces \\(\\mathbf x_g\\) está dado por\n\\[\n\\mathbf x_g = \\frac{\\mathbf x \\cdot \\mathbf x_0}{\\mathbf x_0 \\cdot \\mathbf x_0} \\mathbf x_0 - \\ell_0 \\frac{\\mathbf w}{\\mid\\mid\\mathbf w \\mid\\mid},\n\\]\ndonde \\(\\ell_0\\) es la distancia del origen al hiperplano y \\(\\mathbf x_0\\) es cualquier vector que está en \\(\\mathbf x_0 \\cdot \\mathbf w=0.\\) Para dimensiones mayores el término \\(\\frac{\\mathbf x \\cdot \\mathbf x_0}{\\mathbf x_0 \\cdot \\mathbf x_0}\\) es la proyección al hiperplano \\(A\\) tal que \\(A \\mathbf w = 0.\\)\n\n\n9.3.3 Múltiples Clases\nUna manera de tratar un problema de \\(K\\) clases, es convertirlo en \\(K\\) problemas de clasificación binarios, a este procedimiento se le conoce como Uno vs Resto. La idea es entrenar \\(K\\) clasificadores donde la clase positiva corresponde a cada una de las clases y la clase de negativa se construye con todas las clases que no son la clase positiva en esa iteración. Finalmente, la clase predicha corresponde al clasificador que tiene el valor máximo en la función discriminante.\nLa Figura 9.6 ejemplifica el comportamiento de esta técnica en un problema de tres clases y utilizando un clasificador con discrimitante lineal. En la figura se muestra las tres funciones discriminantes \\(g_k(\\mathbf x)=0\\), los parámetros escalados de esas funciones, i.e., \\(\\ell_k \\mathbf w_k\\) y los datos. Por ejemplo se observa como la clase \\(1\\) mostrada en azul, se separa de las otras dos clases con la función \\(g_1(\\mathbf x)=0\\), es decir, para \\(g_1(\\mathbf x)=0\\) la clase positiva es \\(1\\) y la clase negativa corresponde a los elementos que corresponde a las clases \\(2\\) y \\(3.\\)\n\n\nCódigo\nseed = 3\nX_1 = multivariate_normal(mean=[15, 20],\n                          seed=seed,\n                          cov=[[3, -3], [-3, 8]]).rvs(1000)\nX_2 = multivariate_normal(mean=[5, 5],\n                          seed=seed,\n                          cov=[[4, 0], [0, 2]]).rvs(1000)\nX_3 = multivariate_normal(mean=[-5, 20],\n                          seed=seed,\n                          cov=[[2, 1], [1, 2]]).rvs(1000)\n\nT = np.concatenate((X_1, X_2, X_3))\ny_t = np.array(['1'] * X_1.shape[0] + ['2'] * X_2.shape[0] + ['3'] * X_3.shape[0])\nlinear = LinearSVC(dual=False).fit(T, y_t)\ng_0 = []\nfor i, (w, w_0) in enumerate(zip(linear.coef_, linear.intercept_)):\n    w_1, w_2 = w\n    g_0 += [dict(x1=x, x2=y, tipo=f'g{i+1}(x)=0')\n            for x, y in zip(T[:, 0], (-w_0 - w[0] * T[:, 0]) / w[1])]\nW = [-w0 * w / np.linalg.norm(w)**2 \n     for w, w0 in zip(linear.coef_, linear.intercept_)]    \ndf = pd.DataFrame(g_0 + \\\n                  [dict(x1=x, x2=y, clase='1') for x, y in X_1] +\\\n                  [dict(x1=x, x2=y, clase='2') for x, y in X_2] +\\\n                  [dict(x1=x, x2=y, clase='3') for x, y in X_3] +\\\n                  [dict(x1=w_1, x2=w_2, clase=f'lw{i+1}')\n                   for i, (w_1, w_2) in enumerate(W)]                  \n                 )\nax = sns.scatterplot(data=df, x='x1', y='x2', hue='clase', legend=True)\nsns.lineplot(data=df, x='x1', y='x2', ax=ax, hue='tipo',\n             palette=sns.color_palette()[6:9], legend=True)\n_ = ax.axis('equal')\n\n\n\n\n\n\n\n\nFigura 9.6: Problema multiclase",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Discriminantes Lineales</span>"
    ]
  },
  {
    "objectID": "capitulos/09Lineal.html#sec-svm",
    "href": "capitulos/09Lineal.html#sec-svm",
    "title": "9  Discriminantes Lineales",
    "section": "9.4 Máquinas de Soporte Vectorial",
    "text": "9.4 Máquinas de Soporte Vectorial\nEs momento de describir algunos algoritmos para estimar los parámetros \\(\\mathbf w\\), y \\(w_0\\) empezando por las máquinas de soporte vectorial. En este clasificador se asume un problema binario y las clases están representadas por \\(-1\\) y \\(1\\), es decir, \\(y \\in \\{-1, 1\\}\\). Entonces, las máquinas de soporte vectorial tratan de encontrar una función con las siguientes características.\nSea \\(\\mathbf x_i\\) un ejemplo que corresponde a la clase \\(1\\) entonces se busca \\(\\mathbf w\\) tal que\n\\[\n\\mathbf w \\cdot \\mathbf x_i + w_0 \\geq +1.\n\\]\nEn el caso contrario, es decir, \\(\\mathbf x_i\\) un ejemplo de la clase \\(-1\\), entonces\n\\[\n\\mathbf w \\cdot \\mathbf x_i + w_0 \\leq -1.\n\\]\nEstas ecuaciones se pueden escribir como\n\\[\n(\\mathbf w \\cdot \\mathbf x_i + w_0) y_i \\geq +1,\n\\]\ndonde \\((\\mathbf x_i, y_i) \\in \\mathcal D.\\)\nLa función discriminante es \\(g(\\mathbf x) = \\mathbf w \\cdot \\mathbf x + w_0\\) y la distancia (Ecuación 9.1) que existe entre cualquier punto \\(\\mathbf x_i\\) al discriminante está dada por\n\\[\n\\frac{g(\\mathbf x_i)}{\\mid\\mid \\mathbf w \\mid\\mid}y_i.\n\\]\nEntonces, se puede ver que lo que se busca es encontrar \\(\\mathbf w\\) de tal manera que cualquier punto \\(\\mathbf x_i\\) esté lo mas alejada posible del discriminante, esto se logra minimizando \\(\\mathbf w\\), es decir, resolviendo el siguiente problema de optimización:\n\\[\n\\min \\frac{1}{2} \\mid\\mid\\mathbf w \\mid\\mid\n\\]\nsujeto a \\((\\mathbf w \\cdot \\mathbf x_i + w_0) y_i \\geq +1, \\forall (\\mathbf x_i, y_i) \\in \\mathcal D.\\)\n\n9.4.1 Optimización\nEste es un problema de optimización que se puede resolver utilizando multiplicadores de Lagrange lo cual quedaría como\n\\[\nf_p = \\frac{1}{2}\\mid\\mid\\mathbf w \\mid\\mid - \\sum_i^N \\alpha_i ((\\mathbf w \\cdot \\mathbf x_i + w_0) y_i - 1),\n\\]\ndonde el mínimo corresponde a maximizar con respecto a \\(\\alpha_i \\geq 0\\) y minimizar con respecto a \\(\\mathbf w\\) y \\(w_0.\\) En esta formulación existe el problema para aquellos problemas donde no es posible encontrar un hiperplano que separa las dos clases. Para estos casos donde no es posible encontrar una separación perfecta se propone utilizar\n\\[\n(\\mathbf w \\cdot \\mathbf x_i + w_0) y_i \\geq 1 - \\xi_i,\n\\]\ndonde \\(\\xi\\) captura los errores empezando por aquellos elementos que están del lado correcto del hiperplano, pero que no son mayores a \\(1\\). La Figura 9.7 muestra un ejemplo donde existe un elemento negativo que se encuentra entre la función de decisión y el hiperplano de margen, i.e., el que corresponde a la restricción \\(\\mathbf w \\cdot \\mathbf x_i + w_0 \\geq 1\\), es decir ese punto tiene un \\(0 &lt; \\xi &lt; 1.\\) También se observa un elemento positivo que está muy cerca a \\(g(\\mathbf x) = 1.\\)\n\n\nCódigo\nseed = 2\nX_1 = multivariate_normal(mean=[15, 20], cov=[[3, -3], [-3, 8]], seed=seed).rvs(1000)\nX_2 = multivariate_normal(mean=[8, 8], cov=[[4, 0], [0, 2]], seed=seed).rvs(1000)\nT = np.concatenate((X_1, X_2))\ny_t = np.array(['P'] * X_1.shape[0] + ['N'] * X_2.shape[0])\n\nlinear = LinearSVC(dual=False).fit(T, y_t)\nw_1, w_2 = linear.coef_[0]\nw_0 = linear.intercept_[0]\nw = np.array([w_1, w_2]) / np.linalg.norm([w_1, w_2])\ng_0 = [dict(x1=x, x2=y, tipo='g(x)=0')\n       for x, y in zip(T[:, 0], (-w_0 - w_1 * T[:, 0]) / w_2)]\ng_p = [dict(x1=p['x1'] + w[0], x2=p['x2'] + w[1], tipo='g(x)=1')\n       for p in g_0]\ng_n = [dict(x1=p['x1'] - w[0], x2=p['x2'] - w[1], tipo='g(x)=-1')\n       for p in g_0]\ndf = pd.DataFrame(g_0 + g_p + g_n +\\\n                  [dict(x1=x, x2=y, clase='P') for x, y in X_1] + \\\n                  [dict(x1=x, x2=y, clase='N') for x, y in X_2]\n                 )\nax = sns.scatterplot(data=df, x='x1', y='x2', hue='clase', legend=True)\nsns.lineplot(data=df, x='x1', y='x2', ax=ax,\n             hue='tipo', palette=['k'] + sns.color_palette()[2:4], legend=True)\n_ = ax.axis('equal')\n\n\n\n\n\n\n\n\nFigura 9.7: Hiperplanos\n\n\n\n\n\nContinuando con el problema de optimización, en las condiciones anteriores la función a optimizar es \\(\\min \\frac{1}{2} \\mid\\mid\\mathbf w \\mid\\mid + C \\sum_i^N \\xi_i,\\) utilizando multiplicadores de Lagrange queda como\n\\[\nf_p = \\frac{1}{2}\\mid\\mid\\mathbf w \\mid\\mid - \\sum_i^N \\alpha_i ((\\mathbf w \\cdot \\mathbf x_i + w_0) y_i - 1 + \\xi_i) - \\sum_i^N \\beta_i \\xi_i.\n\\]\nSe observa que el parámetro \\(C\\) controla la penalización que se hace a los elementos que se encuentran en el lado incorrecto del hiperplano o dentro del margen. La Figura 9.8 muestra el hiperplano generado utilizando \\(C=1\\) y \\(C=0.01.\\) Se observa como el elemento que está correctamente clasificado en \\(C=1\\) pasa al lado incorrecto del hiperplano, ademas se ve como la función de decisión rota cuando el valor cambia.\n\n\nCódigo\nfor k, (C, legend) in enumerate(zip([1, 0.01], [False, True])):\n     linear = LinearSVC(dual=False, C=C).fit(T, y_t)\n     w_1, w_2 = linear.coef_[0]\n     w_0 = linear.intercept_[0]\n     w = np.array([w_1, w_2]) / np.linalg.norm([w_1, w_2])\n     g_0 = [dict(x1=x, x2=y, tipo='g(x)=0')\n          for x, y in zip(T[:, 0], (-w_0 - w_1 * T[:, 0]) / w_2)]\n     g_p = [dict(x1=p['x1'] + w[0], x2=p['x2'] + w[1], tipo='g(x)=1')\n          for p in g_0]\n     g_n = [dict(x1=p['x1'] - w[0], x2=p['x2'] - w[1], tipo='g(x)=-1')\n          for p in g_0]\n     df = pd.DataFrame(g_0 + g_p + g_n +\\\n                    [dict(x1=x, x2=y, clase='P') for x, y in X_1] + \\\n                    [dict(x1=x, x2=y, clase='N') for x, y in X_2]\n                    )\n     ax = plt.subplot(1, 2, k + 1)\n     sns.scatterplot(data=df, x='x1', y='x2', hue='clase', legend=legend, ax=ax)\n     sns.lineplot(data=df, x='x1', y='x2', ax=ax,\n               hue='tipo', palette=['k'] + sns.color_palette()[2:4], legend=legend)\n     ax.axis('equal')\n     ax.set_title(f'C={C}')\n     if legend:\n          sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 0.65))\n_ = plt.tight_layout()\n\n\n\n\n\n\n\n\nFigura 9.8: Hiperplanos para diferentes valores de \\(C\\). Se observa que en \\(C=0.01\\) se clasifica incorrectamente un elemento positivo.\n\n\n\n\n\n\nEste problema de optimización cumple con todas las características para poder encontrar su solución optimizando el problema dual. El problema dual corresponde a maximizar \\(f_p\\) con respecto a \\(\\alpha_i,\\) sujeto a que las restricciones de que el gradiente de \\(f_p\\) con respecto a \\(\\mid\\mid\\mathbf w \\mid\\mid\\), \\(w_0\\) y \\(\\xi_i\\) sean cero. Utilizando estas características el problema dual corresponde a\n\\[\nf_d = \\sum_i^N \\alpha_i - \\frac{1}{2} \\sum_i^N \\sum_j^N \\alpha_i \\alpha_j y_i y_j \\mathbf x_i \\cdot \\mathbf x_j,\n\\]\nsujeto a las restricciones \\(\\sum_i^N \\alpha_i y_i = 0\\) y \\(0 \\leq \\alpha_i \\leq C.\\)\nEl problema de optimización dual tiene unas características que lo hacen deseable en ciertos casos, por ejemplo, el problema depende del número de ejemplos (\\(N\\)) en lugar de la dimensión. Entonces en problemas donde \\(d &gt; N\\) es más conveniente utilizar el dual.\n\n\n9.4.2 Kernel\nLa otra característica del problema dual es que permite visualizar lo siguiente. Suponiendo que se usa una función \\(\\phi: \\mathbb R^d \\leftarrow \\mathbf R^{\\hat d},\\) de tal manera, que en el espacio \\(\\phi\\) se puede encontrar un hiperplano que separa las clases. Incorporando la función \\(\\phi\\) produce la siguiente función a optimizar\n\\[\nf_d = \\sum_i^N \\alpha_i - \\frac{1}{2} \\sum_i^N \\sum_j^N \\alpha_i \\alpha_j y_i y_j \\phi(\\mathbf x_i) \\cdot \\phi(\\mathbf x_j),\n\\]\ndonde primero se transforman todos los datos al espacio generado por \\(\\phi\\) y después se calcula el producto punto. El producto punto se puede cambiar por una función Kernel, i.e., \\(K(\\mathbf x_i, \\mathbf x_j) = \\phi(\\mathbf x_i) \\cdot \\phi(\\mathbf x_j)\\) lo cual hace que innecesaria la transformación al espacio \\(\\phi.\\) Utilizando la función de kernel, el problema de optimización dual queda como:\n\\[\nf_d = \\sum_i^N \\alpha_i - \\frac{1}{2} \\sum_i^N \\sum_j^N \\alpha_i \\alpha_j y_i y_j K(\\mathbf x_i, \\mathbf x_j).\n\\]\nLa función discriminante está dada por \\(g(\\mathbf x) = \\sum_i^N \\alpha_i y_i K(\\mathbf x_i, \\mathbf x),\\) donde aquellos elementos donde \\(\\alpha \\neq 0\\) se les conoce como los vectores de soporte. Estos elementos son los que se encuentran en el margen, dentro del margen y en el lado incorrecto de la función discriminante.\nLa Figura 9.9 muestra los datos del iris (proyectados con Análisis de Componentes Principales Sección 5.5), las clases se encuentran en color azul, naranja y verde; en color rojo se muestran los vectores de soporte. La figura derecha muestra en color negro aquellos vectores de soporte que se encuentran en el lado incorrecto del hiperplano. Por otro lado se puede observar como los vectores de soporte separan las clases, del lado izquierdo se encuentran todos los elementos de la clase \\(0\\), después se observan las clases \\(1\\) y del lado derecho las clases \\(2\\). Los vectores de soporte están en la frontera de las clases y los errores se encuentran entre las clases \\(1\\) y \\(2\\) que corresponden a las que no son linealmente separables.\n\n\nCódigo\nX, y = load_iris(return_X_y=True)\nlinear = SVC(kernel='poly', degree=2, C=10).fit(X, y)\nhy = linear.predict(X)\nD = PCA(n_components=2).fit_transform(X)\nmask = np.zeros(D.shape[0])\nmask[linear.support_] = True\ns = 'S'\ndf = pd.DataFrame([dict(x1=x1, x2=x2, tipo=f'{l if not c else s}', error=err)\n                   for (x1, x2), c, l, err in zip(D, mask, y, y != hy)])\nfor k, legend in enumerate([False, True]):     \n     if legend:\n          df.loc[df.error, 'tipo'] = 'X'\n     df.sort_values(by='tipo', inplace=True)\n     ax = plt.subplot(1, 2, k + 1)          \n     sns.scatterplot(data=df, x='x1', y='x2',\n                     palette=sns.color_palette()[:4] + ['k'],\n                     hue='tipo', legend=legend, ax=ax)\n     if legend:\n          sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 0.65))\n_ = plt.tight_layout()\n\n\n\n\n\n\n\n\nFigura 9.9: Visualización de los vectores de soporte usando PCA.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Discriminantes Lineales</span>"
    ]
  },
  {
    "objectID": "capitulos/09Lineal.html#sec-regresion-logistica",
    "href": "capitulos/09Lineal.html#sec-regresion-logistica",
    "title": "9  Discriminantes Lineales",
    "section": "9.5 Regresión Logística",
    "text": "9.5 Regresión Logística\nEn clasificación binaria (Sección 9.3.1) se describió que la función discriminante se puede definir como la resta, i.e., \\(g_1(\\mathbf x) - g_2(\\mathbf x);\\) equivalentemente se pudo haber seleccionado la división (\\(\\frac{g_1(\\mathbf x)}{g_2(\\mathbf x)}\\)) para generar la función discriminante o el logaritmo de la división, i.e., \\(\\log \\frac{g_1(\\mathbf x)}{g_2(\\mathbf x)}.\\) Esta última ecuación en el caso de \\(g_i(\\mathbf x)=\\mathbb P(\\mathcal Y=i \\mid \\mathcal X=\\mathbf x)\\) corresponde a la función \\(\\textsf{logit}\\), tal y como se muestra a continuación.\n\\[\n\\begin{split}\n\\log \\frac{\\mathbb P(\\mathcal Y=1 \\mid \\mathcal X=\\mathbf x)}{\\mathbb P(\\mathcal Y=2 \\mid \\mathcal X=\\mathbf x)} &= \\log \\frac{\\mathbb P(\\mathcal Y=1 \\mid \\mathcal X=\\mathbf x)}{1 - \\mathbb P(\\mathcal Y=1 \\mid \\mathcal X=\\mathbf x)}\\\\\n&= \\textsf{logit}(\\mathbb P(\\mathcal Y=1 \\mid \\mathcal X=\\mathbf x)),\n\\end{split}\n\\]\ndonde la inversa del \\(\\textsf{logit}\\) es la función sigmoide, \\(\\textsf{sigmoid}(x) = \\frac{1}{1 + \\exp(-x)}\\), es decir \\(\\textsf{sigmoid}(\\textsf{logit}(y)) = y\\).\nTrabajando un poco con el \\(\\textsf{logit}\\) se puede observar que para el caso de dos clases está función queda como\n\\[\n\\begin{split}\n\\textsf{logit}(\\mathbb P(\\mathcal Y=1 \\mid \\mathcal X=\\mathbf x)) &= \\log\\frac{\\mathbb P(\\mathcal Y=1 \\mid \\mathcal X=\\mathbf x)}{\\mathbb P(\\mathcal Y=2 \\mid \\mathcal X=\\mathbf x)}\\\\\n&= \\log\\frac{\\mathbb P(\\mathcal X=\\mathbf x \\mid \\mathcal Y=1)\\mathbb P(\\mathcal Y=1)}{\\mathbb P(\\mathcal X=\\mathbf x \\mid \\mathcal Y=2)\\mathbb P(\\mathcal Y=2)}\\\\\n&= \\log\\frac{\\mathbb P(\\mathcal X=\\mathbf x \\mid \\mathcal Y=1)}{\\mathbb P(\\mathcal X=\\mathbf x \\mid \\mathcal Y=2)} + \\log\\frac{\\mathbb P(\\mathcal Y=1)}{\\mathbb P(\\mathcal Y=2)}\n\\end{split},\n\\]\nasumiendo que la matriz de covarianza (\\(\\Sigma\\)) es compartida entre las dos clases la ecuación anterior quedaría como:\n\\[\n\\begin{split}\n\\textsf{logit}(\\mathbb P(\\mathcal Y=1 \\mid \\mathcal X=\\mathbf x)) &= \\log \\frac{(2\\pi)^{-\\frac{d}{2}} \\mid\\Sigma \\mid^{-\\frac{1}{2}}\\exp{(-\\frac{1}{2}(\\mathbf x - \\mathbf \\mu_1)^\\intercal \\Sigma^{-1}(\\mathbf x - \\mathbf \\mu_1))}}{(2\\pi)^{-\\frac{d}{2}} \\mid\\Sigma \\mid^{-\\frac{1}{2}}\\exp{(-\\frac{1}{2}(\\mathbf x - \\mathbf \\mu_2)^\\intercal \\Sigma^{-1}(\\mathbf x - \\mathbf \\mu_2))}}\\\\\n&+ \\log\\frac{\\mathbb P(\\mathcal Y=1)}{\\mathbb P(\\mathcal Y=2)}\\\\\n&= \\mathbf w \\cdot \\mathbf x + w_0\n\\end{split}\n\\]\ndonde \\(\\mathbf w=\\Sigma^{-1}(\\mathbf \\mu_1 - \\mathbf \\mu_2)\\) y \\(w_0=-\\frac{1}{2}(\\mathbf \\mu_1 + \\mathbf \\mu_2)^\\intercal \\Sigma^{-1}(\\mathbf \\mu_1 + \\mathbf \\mu_2)+ \\log\\frac{\\mathbb P(\\mathcal Y=1)}{\\mathbb P(\\mathcal Y=2)}.\\)\nEn el caso de regresión logística, se asume que \\(\\textsf{logit}(\\mathbb P(\\mathcal Y=1 \\mid \\mathcal X=\\mathbf x)) = \\mathbf w \\cdot \\mathbf x + w_0\\) y se realiza ninguna asunción sobre la distribución que tienen los datos. Equivalentemente, se puede asumir que \\(\\log\\frac{\\mathbb P(\\mathcal Y=1 \\mid \\mathcal X=\\mathbf x)}{\\mathbb P(\\mathcal Y=2 \\mid \\mathcal X=\\mathbf x)} = \\mathbf w \\cdot \\mathbf x + w_0^0,\\) realizando algunas substituciones se puede ver que \\(w_0 = w_0^0 + \\log\\frac{\\mathbb P(\\mathcal Y=1)}{\\mathbb P(\\mathcal Y=2)}.\\)\n\n9.5.1 Optimización\nSe puede asumir que \\(\\mathcal Y \\mid \\mathcal X\\) sigue una distribución Bernoulli en el caso de dos clases, entonces el logaritmo de la verosimilitud (Sección 3.3.1) quedaría como:\n\\[\n\\ell(\\mathbf w, w_0 \\mid \\mathcal D) = \\prod_{(\\mathbf x, y) \\in \\mathcal D} (C(\\mathbf x))^{y} (1 -  C(\\mathbf x)))^{1-y},\n\\]\ndonde \\(C(\\mathbf x)\\) es la clase estimada por el clasificador.\nSiempre que se tiene que obtener el máximo de una función esta se puede transformar a un problema de minimización, por ejemplo, para el caso anterior definiendo como \\(E = -\\log \\ell\\), utilizando esta transformación el problema sería minimizar la siguiente función:\n\\[\nE(\\mathbf w, w_0 \\mid \\mathcal D) = - \\sum_{(\\mathbf x, y) \\in \\mathcal D} y \\log C(x) + (1-y) \\log (1 -  C(x)).\n\\tag{9.2}\\]\nEs importante notar que la ecuación anterior corresponde a Entropía cruzada (Sección 4.2.7), donde \\(y=\\mathbb P(\\mathcal Y=y \\mid \\mathcal X=\\mathbf x))\\) y \\(C(\\mathbf x)=\\mathbb{\\hat P}(\\mathcal Y=y \\mid \\mathcal X=\\mathbf x)\\) y los términos \\(1-y\\) y \\(1-C(\\mathbf x)\\) corresponde a la otra clase.\nOtra característica de \\(E(\\mathbf w, w_0 \\mid \\mathcal D)\\) es que no tiene una solución cerrada y por lo tanto es necesario utilizar un método de optimización (Capítulo 10) para encontrar los parámetros \\(\\mathbf w\\) y \\(w_0\\).",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Discriminantes Lineales</span>"
    ]
  },
  {
    "objectID": "capitulos/09Lineal.html#comparación",
    "href": "capitulos/09Lineal.html#comparación",
    "title": "9  Discriminantes Lineales",
    "section": "9.6 Comparación",
    "text": "9.6 Comparación\nEs momento de comparar el comportamiento de los dos métodos de discriminantes lineales visto en la unidad, estos son, Máquinas de Soporte Vectorial (MSV) y Regresión Logística (RL). La Figura 9.10 muestra el hiperplano generado por MSV y RL, además se puede observar los valores de los pesos \\(\\mathbf w\\) para cada uno de los algoritmos.\n\n\nCódigo\nsvm = LinearSVC(dual=False).fit(T, y_t)\nlr = LogisticRegression().fit(T, y_t)\n\ng = []\nfor model, tipo in zip([svm, lr], ['MSV', 'RL']):\n     w_1, w_2 = model.coef_[0]\n     w_0 = model.intercept_[0]\n     g += [dict(x1=x, x2=y, tipo=tipo)\n           for x, y in zip(T[:, 0], (-w_0 - w_1 * T[:, 0]) / w_2)]\n     g.append(dict(x1=w_1, x2=w_2, clase=tipo))\ndf = pd.DataFrame(g + \\\n                  [dict(x1=x, x2=y, clase='P') for x, y in X_1] + \\\n                  [dict(x1=x, x2=y, clase='N') for x, y in X_2]\n                 )\nax = sns.scatterplot(data=df, x='x1', y='x2', hue='clase', legend=True)\nsns.lineplot(data=df, x='x1', y='x2', \n             ax=ax, hue='tipo', \n             palette=sns.color_palette()[:2], \n             legend=True)\n_ = ax.axis('equal')\n\n\n\n\n\n\n\n\nFigura 9.10: Comparación de dos métodos lineales\n\n\n\n\n\nComplementando la comparación anterior con los datos del iris que se pueden obtener con las siguientes dos instrucciones.\n\nD, y = load_iris(return_X_y=True)\nT, G, y_t, y_g = train_test_split(D, y,\n                                  test_size=0.4,\n                                  random_state=3)\n\nLos clasificadores a comparar son una máquina de soporte vectorial lineal, una máquina de soporte vectorial usando un kernel polinomial de grado \\(1\\) y una regresión logística, tal y como se muestra en el siguiente código.\n\nsvm = LinearSVC(dual=False).fit(T, y_t)\nsvm_k = SVC(kernel='poly', degree=1).fit(T, y_t)\nlr = LogisticRegression().fit(T, y_t)\n\nLa Tabla 9.1 muestra el rendimiento (en medidas macro) de estos algoritmos en el conjunto de prueba, se puede observar que estos algoritmos tienen rendimientos diferentes para esta selección del conjunto de entrenamiento y prueba. También en esta ocasión la regresión lineal es la que presenta el mejor rendimiento. Aunque es importante aclarar que este rendimiento es resultado del proceso aleatorio de selección del conjunto de entrenamiento y prueba.\n\n\n\n\nTabla 9.1: Rendimiento de clasificadores lineales\n\n\n\n\n\n\nClasificador\nPrecisión\n Recall\n\\(F_1\\)\n\n\n\n\nMSV - Lineal\n\\(0.9524\\)\n\\(0.9500\\)\n\\(0.9473\\)\n\n\nMSV - Kernel\n\\(0.9474\\)\n\\(0.9481\\)\n\\(0.9473\\)\n\n\nRL\n\\(0.9667\\)\n\\(0.9667\\)\n\\(0.9649\\)",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Discriminantes Lineales</span>"
    ]
  },
  {
    "objectID": "capitulos/10Optimizacion.html",
    "href": "capitulos/10Optimizacion.html",
    "title": "10  Optimización",
    "section": "",
    "text": "10.1 Paquetes usados\nEl objetivo de la unidad es conocer y aplicar el método de Descenso de Gradiente y Propagación hacia Atrás par estimar los parámetros de modelos de clasificación y regresión.\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler, minmax_scale\nfrom scipy.stats import multivariate_normal\nfrom jax import grad, jit, value_and_grad, random\nfrom jax.scipy.optimize import minimize\nimport jax.lax as lax\nimport jax.numpy as jnp\nfrom matplotlib import pylab as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Optimización</span>"
    ]
  },
  {
    "objectID": "capitulos/10Optimizacion.html#sec-intro-10",
    "href": "capitulos/10Optimizacion.html#sec-intro-10",
    "title": "10  Optimización",
    "section": "10.2 Introducción",
    "text": "10.2 Introducción\nExisten diferentes modelos de clasificación y regresión donde no es posible encontrar una solución analítica para estimar los parámetros, por ejemplo en Regresión Logística (Sección 9.5). Es en este escenario donde se voltea a métodos de optimización iterativos para calcular los parámetros.\nEn esta unidad se describe posiblemente el método de optimización más conocido que es Descenso de Gradiente. Este método como su nombre lo indica utiliza el gradiente como su ingrediente principal; se describirá como se puede calcular el gradiente utilizando un método gráfico y como este método naturalmente realiza Propagación hacia Atrás.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Optimización</span>"
    ]
  },
  {
    "objectID": "capitulos/10Optimizacion.html#sec-descenso-gradiente",
    "href": "capitulos/10Optimizacion.html#sec-descenso-gradiente",
    "title": "10  Optimización",
    "section": "10.3 Descenso por Gradiente",
    "text": "10.3 Descenso por Gradiente\nEn un modelo de clasificación y regresión interesa encontrar un vector de parámetros, \\(\\mathbf w^{*},\\) que minimicen una función de error, \\(E,\\) de la siguiente manera:\n\\[\n\\mathbf w^{*} = \\textsf{argmin}_{\\mathbf w} E(\\mathbf w \\mid \\mathcal D).\n\\]\nEn el caso de que \\(E(\\mathbf w \\mid \\mathcal D)\\) sea una función diferenciable, el gradiente está dado por:\n\\[\n\\nabla_{\\mathbf w} E(\\mathbf w \\mid \\mathcal D) = [\\frac{\\partial E}{\\partial \\mathbf w_1}, \\frac{\\partial E}{\\partial \\mathbf w_2}, \\ldots]^\\intercal.\n\\]\nLa idea general es tomar la dirección opuesta al gradiente para encontrar el mínimo de la función. Entonces el cambio de parámetro está dado por\n\\[\n\\begin{split}\n\\Delta \\mathbf w &= - \\eta \\nabla_{\\mathbf w} E\\\\\n       \\mathbf w^{t+1} &= \\mathbf w^{t-1} + \\Delta \\mathbf w \\\\\n       &= \\mathbf w^{t-1} - \\eta \\nabla_{\\mathbf w} E\n\\end{split}\n\\]\n\n10.3.1 Ejemplo - Regresión Lineal\nSuponiendo que se quieren estimar los parámetros de la siguiente ecuación lineal: \\(f(x) = a x + b,\\) para lo cual se tiene un conjunto de entrenamiento en el intervalo \\(x=[-10, 10],\\) generado con los parámetros \\(a=2.3\\) y \\(b=-3.\\) Importante no olvidar que los parámetros \\(a=2.3\\) y \\(b=-3\\) son desconocidos y se quieren estimar usando Descenso por Gradiente y también es importante mencionar que para este problema en particular es posible tener una solución analítica para estimar los parámetros.\nEl primer paso es definir la función de error \\(E(a, b \\mid \\mathcal D),\\) en problemas de regresión una función de error viable es: \\(E(a, b \\mid \\mathcal D) = \\sum_{(x, y) \\in \\mathcal D} (y - f(x))^2.\\)\nLa regla para actualizar los valores iniciales es: \\(w = w - \\eta \\nabla_w E\\); por lo que se procede a calcular \\(\\nabla_w E\\) donde \\(w\\) corresponde a los parámetros \\(a\\) y \\(b\\).\n\\[\n\\begin{split}\n    \\frac{\\partial E}{\\partial w} &= \\frac{\\partial}{\\partial w} \\sum (y - f(x))^2 \\\\\n    &= 2 \\sum (y - f(x)) \\frac{\\partial}{\\partial w} (y - f(x)) \\\\\n    &= - 2 \\sum (y - f(x)) \\frac{\\partial}{\\partial w} f(x)\n\\end{split}\n\\]\ndonde \\(\\frac{\\partial}{\\partial a} f(x) = x\\) y \\(\\frac{\\partial}{\\partial b} f(x) = 1.0\\) Las ecuaciones para actualizar \\(a\\) y \\(b\\) serían:\n\\[\n\\begin{split}\n    e(y, x) &= y - f(x) \\\\\n    a &= a + 2 \\eta \\sum_{(x, y) \\in \\mathcal D} e(y, x) x \\\\  \n    b &= b + 2 \\eta \\sum_{(x, y) \\in \\mathcal D} e(y, x)\n\\end{split}\n\\]\nCon el objetivo de visualizar descenso por gradiente y completar el ejemplo anterior, el siguiente código implementa el proceso de optimización mencionado. Lo primero es generar el conjunto de entrenamiento.\n\nx = np.linspace(-10, 10, 50)\ny = 2.3 * x - 3\n\nEl proceso inicia con valores aleatorios de \\(a\\) y \\(b\\), estos valores podrían ser \\(5.3\\) y \\(-5.1,\\) además se utilizará una \\(\\eta=0.0001\\), se guardarán todos los puntos visitados en la lista D. Las variables y valores iniciales quedarían como:\n\na = 5.3\nb = -5.1\ndelta = np.inf\neta = 0.0001\nD = [(a, b)]\n\nEl siguiente ciclo realiza la iteración del proceso de optimización y se detienen cuando los valores estimados varían poco entre dos iteraciones consecutivas, en particular cuando en promedio el cambio en las constantes sea menor a \\(0.0001\\).\n\nwhile delta &gt; 0.0001:\n    hy = a * x + b\n    e = (y - hy)\n    a = a + 2 * eta * (e * x).sum()\n    b = b + 2 * eta * e.sum()\n    D.append((a, b))\n    delta = np.fabs(np.array(D[-1]) - np.array(D[-2])).mean()\n\nEn la Figura 10.1 se muestra el camino que siguieron los parámetros hasta llegar a los parámetros que generaron el problema. Los parámetros que generaron el problema se encuentran marcados en negro.\n\n\nCódigo\ndf = pd.DataFrame(np.array(D), columns=['a', 'b'])\n_ = np.atleast_2d(np.log(np.arange(1, df.shape[0] + 1))).T\ndf['iteración %'] = minmax_scale(_).flatten()\nsns.relplot(data=df, kind='scatter', x='a', y='b', hue='iteración %')\n_ = plt.tight_layout()\n\n\n\n\n\n\n\n\nFigura 10.1: Camino de los parámetros en el proceso de optimización.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Optimización</span>"
    ]
  },
  {
    "objectID": "capitulos/10Optimizacion.html#sec-diferenciacion-automatica",
    "href": "capitulos/10Optimizacion.html#sec-diferenciacion-automatica",
    "title": "10  Optimización",
    "section": "10.4 Diferenciación Automática",
    "text": "10.4 Diferenciación Automática\nNo en todos los casos es posible encontrar una ecuación cerrada para actualizar los parámetros; también el trabajo manual que se requiere para encontrar la solución analítica es considerable y depende de la complejidad de la función objetivo que se quiere derivar. Observando el procedimiento para actualizar los parámetros, i.e., \\(\\mathbf w^{t+1} = w^{t-1} - \\eta \\nabla_{\\mathbf w} E\\), se concluye que se requiere evaluar \\(\\nabla_{\\mathbf w} E\\) en un punto en particular, entonces, para solucionar el problema, es suficiente contar con un procedimiento que permita conocer el valor de \\(\\nabla_{\\mathbf w} E\\) en cualquier punto deseado, y en particular no es necesario conocer la solución analítica de \\(\\nabla_{\\mathbf w} E.\\) Al procedimiento que encuentra el valor de la derivada de cualquier función en un punto de manera automática se le conoce como diferenciación automática.\n\n10.4.1 Una Variable\nSe puede entender el proceso de diferenciación automática siguiendo un par de ejemplos. Sea \\(f(x) = x^2,\\) en este caso \\(f'(x) = 2x.\\) Ahora considerando que se quiere evaluar \\(f'(2.5)\\), se sabe que \\(f'(2.5)=5,\\) pero también se puede generar un programa donde en la primera fase se calcule \\(f(2.5)=(2.5)^2\\) y al momento de calcular \\(f\\) se guarde en un espacio asociado a \\(f\\) el valor de \\(f'(2.5).\\) es decir \\(5\\). Se puede observar que este procedimiento soluciona este problema simple para cualquier función de una variable.\nLa librería JAX permite hacer diferenciación automática en Python. Siguiendo el ejemplo anterior, se genera la función \\(f(x) = x^2\\) con el siguiente código\n\ndef sq(x):\n    return x**2\n\nEsta función se puede evaluar como sq(2.5); lo interesante es que sq se puede componer con la función grad para calcular la derivada de la siguiente manera.\n\nres = grad(sq)(2.5)\n\nEjecutando el código anterior se obtiene \\(5\\), grad internamente guarda \\(5\\), grad asociado a sq.\nAhora en el caso de una composición, por ejemplo, sea \\(g(x)=\\sin(x)\\) y se desea conocer \\(\\frac{d}{dx} g(f(x)),\\) siguiendo el mismo principio primero se evalúa \\(f(2.5)\\) y se guarda asociado a \\(f\\) el valor de \\(5\\) que corresponde a \\(f',\\) después se evalúa \\(g(5)\\) y se guarda asociado a \\(g\\) el valor \\(\\cos(2.5^2).\\) Ahora para conocer el valor de \\(\\frac{d}{dx} g(f(2.5))\\) se camina en el sentido inverso multiplicando todos los valores guardados, es decir, se multiplica \\(5 \\times \\cos(2.5^2).\\) Implementando este ejemplo en Python quedaría como:\n\ndef sin_sq(x):\n    return jnp.sin(sq(x))\n\ndonde la función sin_sq tiene la composición de \\(g \\circ f.\\) Ahora la derivada de esta composición en 2.5 se obtiene como grad(sin_sq)(2.5) obteniendo un valor de \\(4.9972\\).\n\n\n10.4.2 Dos Variables\nEl ejemplo anterior se puede extender para cualquier composición de funciones, pero ese ejemplo no deja claro lo que pasaría con una función de dos o más variables, como por ejemplo, \\(h(x, y) = x \\times y.\\) En este caso, el objetivo es calcular tanto \\(\\frac{d}{dx} h\\) como \\(\\frac{d}{dy} h.\\)\nEl procedimiento es similar, con el ingrediente extra de que se tiene que recordar la función y la posición del argumento, es decir, para \\(h(2, 5)\\) se asocia el valor \\(\\frac{d}{dx} h\\) con el primer argumento de la función \\(h\\) y \\(\\frac{d}{dx} h\\) con el segundo argumento de la función \\(h\\). Para \\(h'(2, 5)\\) se asocia el valor de \\(5\\) con el primer argumento de \\(h\\) y \\(2\\) con el segundo argumento de \\(h.\\) Se puede observar que los valores guardados corresponden a \\(\\frac{d}{dx}h(2, 5)=y=5\\) y \\(\\frac{d}{dy}h(2, 5)=x=2.\\) Escribiendo este ejemplo en Python quedaría como\n\ndef prod(x):\n    return x[0] * x[1]\n\ncalculando la derivada como grad(prod)(jnp.array([2., 5.])) se obtiene [5., 2.] que corresponde a la derivada parcial en cada argumento.\n\n\n10.4.3 Visualización\nUna manera de visualizar este proceso de diferenciación automática es poniéndolo en un árbol de expresión, en la Figura 10.2 se muestra la ecuación \\(ax^2+bx+c\\). Dentro de cada nodo se observa el valor que se tiene que guardar para cualquier valor de \\(a,b,c\\) y \\(x.\\)\n\n\n\n\n\n\nFigura 10.2: Árbol de expresión\n\n\n\n\n\n10.4.4 Regresión Lineal\nEn esta sección se realiza utilizando diferenciación automática el ejemplo de regresión lineal (Sección 10.3.1). Lo primero que se tiene que hacer es definir la función para la cual se quieren optimizar los parámetros. Esta función es \\(ax + b\\) la cual se define con el siguiente código. El primer argumento de la función son los parámetros y después viene los argumentos de la función que en este caso son los valores de \\(x.\\)\n\ndef func(params, x):\n    a, b = params\n    return a * x + b\n\nEl siguiente paso es definir la función de error, en este caso la función de error definida previamente es \\(\\sum_{i=1}^{N} (y_i - \\hat y_i)^2\\) tal y como se muestra en la siguiente función.\n\ndef error(params, x, y):\n    hy = func(params, x)\n    return lax.fori_loop(0, x.shape[0],\n                         lambda i, acc: acc + (y[i] - hy[i])**2,\n                         0)\n\nFinalmente, se actualizan los parámetros siguiendo un procedimiento equivalente al mostrado anteriormente. La primera linea define el valor de \\(\\eta,\\) el valor de la variable delta indica el término del ciclo, la tercera línea define los parámetros iniciales (params), la siguiente guarda los todos los puntos visitados (cuarta línea) y la quinta línea deriva la función de error para calcular el gradiente. La primera instrucción dentro del ciclo actualiza los parámetros.\n\neta = 0.0001\ndelta = np.inf\nparams = jnp.array([5.3, -5.1])\nx = jnp.array(x)\ny = jnp.array(y)\nD = [params]\nerror_grad = grad(error)\nwhile delta &gt; 0.0001:\n    params -= eta * error_grad(params, x, y)\n    D.append(params)\n    delta = jnp.fabs(D[-1] - D[-2]).mean()",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Optimización</span>"
    ]
  },
  {
    "objectID": "capitulos/10Optimizacion.html#sec-regresion-logistica-optimizacion",
    "href": "capitulos/10Optimizacion.html#sec-regresion-logistica-optimizacion",
    "title": "10  Optimización",
    "section": "10.5 Regresión Logística",
    "text": "10.5 Regresión Logística\nEn esta sección, se presenta la implementación de Regresión Logística (Sección 9.5) utilizando diferenciación automática.\nEl método se probará en los datos generados por dos normales en \\(\\mathbb R^2\\) que se generan con las siguientes instrucciones.\n\nX_1 = multivariate_normal(mean=[15, 20], cov=[[3, -3], [-3, 8]]).rvs(1000)\nX_2 = multivariate_normal(mean=[8, 8], cov=[[4, 0], [0, 2]]).rvs(1000)\nT = np.concatenate((X_1, X_2))\nnormalize = StandardScaler().fit(T)\nT = jnp.array(normalize.transform(T))\ny_t = jnp.array([1] * X_1.shape[0] + [0] * X_2.shape[0])\n\nSiguiendo los pasos utilizados en el ejemplo anterior, la primera función a implementar es el model, es decir la función sigmoide, i.e., \\(\\textsf{sigmoid}(\\mathbf x) = \\frac{1}{1 + \\exp(- (\\mathbf w \\cdot \\mathbf x + w_0))}.\\)\n\ndef modelo(params, x):\n    _ = jnp.exp(-(jnp.dot(x, params[:2]) + params[-1]))\n    return 1 / (1 + _)\n\nEl siguiente paso es implementar la función de error que guía el proceso de optimización, en el caso de regresión logística de dos clases la función de error corresponde a la media de la Entropía Cruzada (Ecuación 9.2). Esta función se implementa en dos pasos, primero se calcula la entropía cruzada usando el siguiente procedimiento. Donde la primera línea verifica selecciona si se trata de la clase positiva (\\(1\\)) o de la clase negativa \\(0\\) y calcula el \\(\\log \\hat y\\) o \\(\\log (1 - \\hat y)\\) respectivamente.\n\ndef entropia_cruzada(y, hy):\n    _ = lax.cond(y == 1, lambda w: jnp.log(w), lambda w: jnp.log(1 - w), hy)\n    return lax.cond(_ == -jnp.inf, lambda w: jnp.log(1e-6), lambda w: w, _)\n\nEl segundo paso es calcular la media de la entropía cruzada de cada elemento de \\(\\mathcal D,\\) esto se puede realizar con la siguiente función.\n\ndef suma_entropia_cruzada(params, x, y):\n    hy = modelo(params, x)\n    return - lax.fori_loop(0, y.shape[0],\n                           lambda i, x: x + entropia_cruzada(y[i], hy[i]),\n                           1) / y.shape[0]\n\nEl paso final es actualizar los parámetros, en esta ocasión se utilizará la función value_and_grad que regresa la evaluación de la función así como la derivada, esto para poder desplegar como el error disminuye con el paso de las iteraciones. El código es similar al mostrado anteriormente. La diferencias son la forma en generar los parámetros iniciales, primeras tres líneas, el parámetro \\(\\eta\\), que se itera por \\(n=5000\\) iteraciones y la función value_and_grad.\n\nkey = random.PRNGKey(0)\nkey, subkey = random.split(key)\nparams = random.normal(subkey, (3,)) * jnp.sqrt(2 / 2)\neta = 0.1\nerror = []\nerror_grad  = value_and_grad(suma_entropia_cruzada)\nfor i in range(5000):\n    _, g = error_grad(params, T, y_t)\n    error.append(_)\n    params -= eta * g\n\nLa Figura 10.3 muestra como se reduce la media de la entropía cruzada con respecto al número de iteraciones, este error sigue bajando aunque la velocidad disminuye drasticamente.\n\n\nCódigo\ndf = pd.DataFrame({'Iteración': np.arange(5000), 'error': np.array(error)})\nsns.relplot(data=df, x='Iteración', y='error', kind='line')\n_ = plt.tight_layout()\n\n\n\n\n\n\n\n\nFigura 10.3: Descenso de Entropía Cruzada\n\n\n\n\n\n\nOptimizando los parámetros de la regresión logística utilizando el procedimiento de diferenciación automática se obtiene [3.9203, 4.3832, -0.4768].\nEn Discriminantes Lineales (Capítulo 9) se presento el procedimiento para entrenar un clasificador logístico usando la siguiente instrucción.\n\nlr = LogisticRegression().fit(T, y_t)\n\nLos parámetros son [3.2929, 4.4508, -0.3220]. El error en el conjunto se entrenamiento es se puede calcular de la siguiente manera. En comparación el error obtenido por diferenciación automática es \\(0.0026\\), por supuesto este puede variar cambiando el número de iteraciones.\n\n_ = jnp.array([lr.coef_[0, 0], lr.coef_[0, 1], lr.intercept_[0]])\nsuma_entropia_cruzada(_, T, y_t)\n\nArray(0.00329172, dtype=float32)",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Optimización</span>"
    ]
  },
  {
    "objectID": "capitulos/10Optimizacion.html#sec-actualizacion-parametros",
    "href": "capitulos/10Optimizacion.html#sec-actualizacion-parametros",
    "title": "10  Optimización",
    "section": "10.6 Actualización de Parámetros",
    "text": "10.6 Actualización de Parámetros\nPor supuesto la regla \\(\\mathbf w^{t+1} = \\mathbf w^{t-1} - \\eta \\nabla_{\\mathbf w} E\\) para actualizar los parámetros \\(\\mathbf w\\) no es única y existe una gama de métodos que se pueden seleccionar dependiendo de las características del problema. En particular regresión logística es una problema de optimización convexo, en este tipo de problemas un algoritmos para encontrar los parámetros es el BFGS. Por ejemplo el siguiente código utiliza este algoritmo para encontrar los parámetros de la regresión logística.\n\np = random.normal(subkey, (3,)) * jnp.sqrt(2 / 2)\nres = minimize(suma_entropia_cruzada, p, args=(T, y_t), method='BFGS')\n\nSe observa como se usa la misma función de error (suma_entropia_cruzada) y los mismos parámetros iniciales. Los parámetros que se encuentran con este método son [13.5714, 20.6805, 1.9514] y tiene un error \\(-0.0005\\).\nLa Figura 10.4 muestra la función discriminantes obtenida por cada uno de los métodos, el método de diferenciación automática (JAX), el método de la librearía sklearn y el algoritmo BFGS. Se puede observar que el plano de sklearn y BFGS son más similares, esto no es sorpresa porque los dos métodos implementan el mismo método de optimización, es decir, BFGS. Por supuesto la implementaciones tiene algunas diferencias, que pueden ir desde el número de iteraciones y la forma de generar los parámetros iniciales. Si se escalan los parámetros \\(\\mathbf w\\) para que tengan una longitud de \\(1\\) se observaría que sklearn y BFGS se tocan.\n\n\nCódigo\nW = [jnp.array([lr.coef_[0, 0], lr.coef_[0, 1], lr.intercept_[0]]), params, res.x]\ng = []\nfor w, tipo in zip(W, ['sklearn', 'JAX', 'BFGS']):\n     w_1, w_2, w_0 = w\n     g += [dict(x1=float(x), x2=float(y), tipo=tipo)\n           for x, y in zip(T[:, 0], (-w_0 - w_1 * T[:, 0]) / w_2)]\n     # w_1, w_2, w_0 = w / np.linalg.norm(w) * 3\n     g.append(dict(x1=float(w_1), x2=float(w_2), clase=tipo))\n\ndf = pd.DataFrame(g + \\\n                  [dict(x1=x, x2=y, clase='P') for x, y in normalize.transform(X_1)] + \\\n                  [dict(x1=x, x2=y, clase='N') for x, y in normalize.transform(X_2)]\n                 )\n\nax = sns.scatterplot(data=df, x='x1', y='x2', hue='clase', legend=True)\nsns.lineplot(data=df, x='x1', y='x2', \n             ax=ax, \n             hue='tipo', \n             palette=sns.color_palette()[:3],\n             legend=True)\n\n_ = ax.axis('equal')\n\n\n\n\n\n\n\n\nFigura 10.4: Comparación de modelos lineales con diferentes optimizadores",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Optimización</span>"
    ]
  },
  {
    "objectID": "capitulos/11RedesNeuronales.html",
    "href": "capitulos/11RedesNeuronales.html",
    "title": "11  Redes Neuronales",
    "section": "",
    "text": "11.1 Paquetes usados\nEl objetivo de la unidad es conocer, diseñar y aplicar redes neuronales artificiales para problemas de regresión y clasificación.\nimport jax\nimport jax.lax as lax\nimport jax.numpy as jnp\nimport optax\nfrom sklearn.datasets import load_iris, load_digits\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Redes Neuronales</span>"
    ]
  },
  {
    "objectID": "capitulos/11RedesNeuronales.html#sec-intro-11",
    "href": "capitulos/11RedesNeuronales.html#sec-intro-11",
    "title": "11  Redes Neuronales",
    "section": "11.2 Introducción",
    "text": "11.2 Introducción\nLas redes neuronales son sin duda uno de los algoritmos de aprendizaje supervisado que mas han tomado auge en los últimos tiempos. Para iniciar la descripción de redes neuronales se toma de base el algoritmo de Regresión Logística (Sección 10.5) pero en el caso de múltiples clases, es decir, Regresión Logística Multinomial.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Redes Neuronales</span>"
    ]
  },
  {
    "objectID": "capitulos/11RedesNeuronales.html#sec-regresion-logistica-multinomial",
    "href": "capitulos/11RedesNeuronales.html#sec-regresion-logistica-multinomial",
    "title": "11  Redes Neuronales",
    "section": "11.3 Regresión Logística Multinomial",
    "text": "11.3 Regresión Logística Multinomial\nLa idea de regresión logística es modelar \\(\\mathbb P(\\mathcal Y=y \\mid \\mathcal X=\\mathbf x)=\\textsf{Ber}(y \\mid \\textsf{sigmoid}(\\mathbf w \\cdot \\mathbf x + w_0)),\\) es decir, que la clase \\(y\\) esta modelada como una distribución Bernoulli con parámetro \\(\\textsf{sigmoid}(\\mathbf w \\cdot \\mathbf x + w_0).\\) Siguiendo está definición que es equivalente a la mostrada anteriormente, se puede modelar a un problema de multiples clases como \\(\\mathbb P(\\mathcal Y=y \\mid \\mathcal X=\\mathbf x)=\\textsf{Cat}(y \\mid \\textsf{softmax}(W \\mathbf x + \\mathbf w_0)),\\) es decir, que la clase proviene de una distribución Categórica con parámetros \\(\\textsf{softmax}(W \\mathbf x + \\mathbf w_0),\\) donde \\(W \\in \\mathbb R^{K \\times d},\\) \\(\\mathbf x \\in \\mathbb R^d\\) y \\(\\mathbf w_0 \\in \\mathbb R^d.\\)\nLa función \\(\\textsf{softmax}(\\mathbf v)\\), donde \\(\\mathbf v = W \\mathbf x + \\mathbf w_0\\) está definida como:\n\\[\n\\mathbf v_i = \\frac{\\exp \\mathbf v_i}{\\sum_{j=1}^K \\exp \\mathbf v_j}.\n\\]\nLa función jax.nn.softmax implementa \\(\\textsf{softmax}\\); en el siguiente ejemplo se calcula para el vector [2, 1, 3]\n\njax.nn.softmax(np.array([2, 1, 3]))\n\nArray([0.24472848, 0.09003057, 0.66524094], dtype=float32)\n\n\nSe puede observar que \\(\\textsf{softmax}\\) transforma los valores del vector \\(\\mathbf v\\) en probabilidades.\nPara seguir explicando este tipo de regresión logística se utilizará el problema del Iris, el cual se obtiene de la siguiente manera, es importante notar que las entradas están normalizadas para tener media cero y desviación estándar uno.\n\nD, y = load_iris(return_X_y=True)\nnormalize = StandardScaler().fit(D)\nD = normalize.transform(D)\n\nEl siguiente paso es generar el modelo de la Regresión Logística Multinomial, el cual depende de una matriz de coeficientes \\(W \\in \\mathbb R^{K \\times d}\\) y \\(\\mathbf w_0 \\in \\mathbb R^d.\\) Los parámetros iniciales se puede generar con la función parametros_iniciales tal y como se muestra a continuación.\n\nn_labels = np.unique(y).shape[0]\ndef parametros_iniciales(key=0):\n    key = jax.random.PRNGKey(key)\n    d = D.shape[1]\n    params = []\n    normal = jax.random.normal\n    sqrt = jnp.sqrt\n    for _ in range(n_labels):\n        key, subkey = jax.random.split(key)\n        _ = dict(w=normal(subkey, (d, )) * sqrt(2 / d),\n                 w0=jnp.ones(1))\n        params.append(_)\n    return params\n\nUtilizando los parámetros en el formato anterior, hace que el modelo se pueda implementar con las siguientes instrucciones. Donde el ciclo es por cada uno de los parámetros de las \\(K\\) clases y la última línea calcula el \\(\\textsf{softmax}.\\)\n\n@jax.jit\ndef modelo(params, X):\n    o = []\n    for p in params:\n        o.append(X @ p['w'] + p['w0'])\n    return jax.nn.softmax(jnp.array(o), axis=0).T\n\nUna característica importante es que la función de perdida, en este caso, a la Entropía Cruzada (Sección 4.2.7), requiere codificada la probabilidad de cada clase en un vector, donde el índice con probabilidad \\(1\\) corresponde a la clase, esto se puede realizar con el siguiente código.\n\ny_oh = jax.nn.one_hot(y, n_labels)\n\nAhora se cuenta con todos los elementos para implementar la función de Entropía Cruzada para múltiples clases, la cual se muestra en el siguiente fragmento.\n\n@jax.jit\ndef media_entropia_cruzada(params, X, y_oh):\n    hy = modelo(params, X)\n    return - (y_oh * jnp.log(hy)).sum(axis=1).mean()\n\n\n11.3.1 Optimización\nEl siguiente paso es encontrar los parámetros del modelo, para esto se utiliza el método de optimización visto en Regresión Logística ( Sección 10.5) con algunos ajustes. Lo primero es que se desarrolla todo en una función fit que recibe el parámetro \\(\\eta\\), los parámetros a identificar y el número de épocas, es decir, el número de iteraciones que se va a realizar el procedimiento.\nDentro de la función fitse observa la función update que calcula los nuevos parámetros, también regresa el valor del error, esto para poder visualizar como va aprendiendo el modelo. La primera linea después de la función update genera la función que calculará el valor y el gradiente de la función media_entropia_cruzada. Finalmente viene el ciclo donde se realizan las actualizaciones de los parámetros y se guarda el error calculado en cada época.\n\ndef fit(eta, params, epocas=500):\n    @jax.jit\n    def update(params, eta, X, y_oh):\n        _ , gs = error_grad(params, X, y_oh)\n        return _, jax.tree_map(lambda p, g: p - eta * g,\n                               params, gs)\n\n    error_grad  = jax.value_and_grad(media_entropia_cruzada)\n    error = []\n    for i in range(epocas):\n        _, params = update(params, eta, D, y_oh)\n        error.append(_)\n    return params, error\n\n\n\n11.3.2 Optimización Método Adam\nComo se había visto en la Sección 10.6 existen diferentes métodos para encontrar los parámetros, en particular en esta sección se utilizará el método Adam (implementado en la librería optax) para encontrar los parámetros de la Regresión Logística Multinomial. Se decide utilizar este método dado que su uso es frecuente en la identificación de parámetros de redes neuronales.\nSiguiendo la misma estructura que la función fit, la función adam recibe tres parámetros el primer es la instancia de optimizador, la segunda son los parámetros y finalmente el número de épocas que se va a ejecutar. La primera línea de la función update (que se encuentra en adam) calcula el valor de la función de error y su gradiente, estos son utilizados por optimizer.update para calcular la actualización de parámetros así como el nuevo estado del optimizador, los nuevos parámetros son calculados en la tercera línea y la función regresa los nuevos parámetros, el estado del optimizador y el error en esa iteración. La primera línea después de update inicializa el optimizador, después se general la función que calculará el valor y gradiente de la función media_entropia_cruzada. El ciclo llama la función update y guarda el error encontrado en cada época.\n\ndef adam(optimizer, params, epocas=500):\n    @jax.jit\n    def update(params, opt_state, X, y_oh):\n        loss_value, grads = error_grad(params,\n                                       X,\n                                       y_oh)\n        updates, opt_state = optimizer.update(grads,\n                                              opt_state,\n                                              params)\n        params = optax.apply_updates(params, updates)\n        return params, opt_state, loss_value\n    \n    opt_state = optimizer.init(params)\n    error_grad  = jax.value_and_grad(media_entropia_cruzada)    \n    error = []\n    for i in range(epocas):\n        params, opt_state, loss_value = update(params,\n                                               opt_state,\n                                               D,\n                                               y_oh)\n        error.append(loss_value)\n    return params, error\n\n\n\n11.3.3 Comparación entre Optimizadores\nLos optimizadores descritos anteriormente se pueden utilizar con el siguiente código, donde la primera línea calcula los parámetros iniciales, después se llama a la función fit para encontrar los parámetros con el primer método. La tercera línea genera una instancia del optimizador Adam; el cual se pasa a la función adam para encontrar los parámetros con este método.\n\nparams = parametros_iniciales()\np1, error1 = fit(1e-2, params)\noptimizer = optax.adam(learning_rate=1e-2)\np2, error2 = adam(optimizer, params)\n\n/var/folders/wk/rlx2pk5j42v6mpjfd_0842c00000gn/T/ipykernel_42054/2693901055.py:5: DeprecationWarning: jax.tree_map is deprecated: use jax.tree.map (jax v0.4.25 or newer) or jax.tree_util.tree_map (any JAX version).\n  return _, jax.tree_map(lambda p, g: p - eta * g,\n\n\nLa Figura 11.1 muestra cómo la media de la Entropía Cruzada se minimiza con respecto a las épocas para los dos métodos. Se puede observar como el método adam converge más rápido y llega a un valor menor de Entropía Cruzada.\n\n\nCódigo\ndf = pd.DataFrame(dict(entropia=np.array(error1),\n                       optimizador='fit',\n                       epoca=np.arange(1, 501)))\n\ndf = pd.concat((df, pd.DataFrame(dict(entropia=np.array(error2),\n                                      optimizador='adam',\n                                      epoca=np.arange(1, 501)))))\n_ = sns.relplot(data=df, x='epoca', y='entropia', hue='optimizador', kind='line')\n\n\n\n\n\n\n\n\nFigura 11.1: Comparación de diferentes optimizadores.\n\n\n\n\n\nFinalmente la exactitud (Sección 4.2.2) en el conjunto de entrenamiento del modelo estimado con fit es \\(0.8867\\) (i.e., (y == modelo(p1, D).argmax(axis=1)).mean()) y del estimado con adam es \\(0.9667\\).",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Redes Neuronales</span>"
    ]
  },
  {
    "objectID": "capitulos/11RedesNeuronales.html#sec-preceptron",
    "href": "capitulos/11RedesNeuronales.html#sec-preceptron",
    "title": "11  Redes Neuronales",
    "section": "11.4 Perceptrón",
    "text": "11.4 Perceptrón\nLa unidad básica de procesamiento en una red neuronal es el perceptrón, el cual es un viejo conocido de Discriminantes Lineales (Capítulo 9), es decir, \\(g(\\mathbf x) = \\mathbf w \\cdot \\mathbf x + \\mathbf w_0.\\) En problemas de clasificación binaria se encuentran los parámetros de \\(g(\\mathbf x)\\) de tal manera que genera un hiperplano y se clasifican los elementos de acuerdo al lado positivo o negativo del hiperplano. En problemas de Regresión (Sección 3.10) los parámetros de \\(g(\\mathbf x)\\) se encuentran utilizando mínimos cuadrados.\nEn el case de tener \\(K&gt;2\\) clases entonces el problema se puede afrontar entrenando \\(g_k(\\mathbf x)\\) perceptrones (\\(k=1, \\ldots, K\\)) tal y como se realizó Discriminantes Lineales (Sección 9.3.3). De manera concisa se puede definir a \\(g: \\mathbb R^d \\rightarrow \\mathbb R^K\\), es decir, \\(g(\\mathbf x)=W \\mathbf x + \\mathbf w_0\\) tal y como se realizó en Regresión Logística Multinomial (Sección 11.3). En el caso de desear conocer la probabilidad de pertenencia a una clase, en el caso binario se utilizó \\(g(\\mathbf x) = \\textsf{sigmoid}(\\mathbf w \\cdot \\mathbf x + \\mathbf w_0)\\) y en el caso multiclase \\(g(\\mathbf x) = \\textsf{softmax}(W \\mathbf x + \\mathbf w_0).\\)\n\n11.4.1 Composición de Perceptrones Lineales\nSe puede realizar una composición de perceptrones de la siguiente manera, sea \\(g_1: \\mathbb R^d \\rightarrow \\mathbb R^{d'}\\) y \\(g_2: \\mathbb R^{d'} \\rightarrow \\mathbb R^K,\\) es decir \\(g = g_2 \\circ g_1.\\) Realizando está composición en las ecuaciones descritas anteriormente se tiene\n\\[\n\\begin{split}\n\\hat{\\mathbf{y}}_1 &= g_1(\\mathbf x) \\\\\n\\hat{\\mathbf y} &= g_2(\\hat{\\mathbf{y}}_1)\n\\end{split}\n\\]\nExpandiendo las ecuaciones anteriores se tiene\n\\[\n\\begin{split}\n\\hat{\\mathbf{y}}_1 &= W_1 \\mathbf x + \\mathbf w_{1_0}\\\\\n\\hat{\\mathbf y} &= W_2 \\hat{\\mathbf{y}}_1 + \\mathbf w_{2_0}\\\\\n&= W_2 (W_1 \\mathbf x + \\mathbf w_{1_0}) + \\mathbf w_{2_0}\\\\\n&= W_2 W_1 \\mathbf x + W_2 \\mathbf w_{1_0} + \\mathbf w_{2_0}\\\\\n&= W \\mathbf x + \\mathbf w_0\n\\end{split}\n\\]\ncomo se puede observar la composición realizada da como resultado una red donde se tienen que identificar \\(W \\in \\mathbb R^{K \\times d}\\) y \\(\\mathbf w_0 \\in \\mathbb R^d,\\) es decir, son \\(K\\) perceptrones equivalentes al modelado de Regresión Logística Multinomial. Esto es porque la composición fue con funciones lineales.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Redes Neuronales</span>"
    ]
  },
  {
    "objectID": "capitulos/11RedesNeuronales.html#perceptrón-multicapa",
    "href": "capitulos/11RedesNeuronales.html#perceptrón-multicapa",
    "title": "11  Redes Neuronales",
    "section": "11.5 Perceptrón Multicapa",
    "text": "11.5 Perceptrón Multicapa\nPara evitar que la composición de perceptrones colapsen a una función equivalente, es necesario incluir una función no lineal, sea \\(\\phi\\) esta función no lineal, (a esta función se le conoce como función de activación) entonces se puede observar que la composición \\(g=g_2 \\circ g_1\\) donde \\(g_1 = \\phi(W_1 \\mathbf x + \\mathbf w_{1_0})\\) resulta en\n\\[\n\\begin{split}\n\\hat{\\mathbf{y}}_1 &= \\phi(W_1 \\mathbf x + \\mathbf w_{1_0}) \\\\\n\\hat{\\mathbf y} &= W_2 \\hat{\\mathbf{y}}_1 + \\mathbf w_{2_0}\n\\end{split}.\n\\]\nA la estructura anterior se le conoce como una red neuronal de una capa oculta, la salida de la capa oculta está en \\(\\hat{\\mathbf{y}}_1\\) y la salida de la red es \\(\\hat{\\mathbf y}.\\) Siguiendo la notación anterior se puede definir una red neuronal con dos capas ocultas de la siguiente manera\n\\[\n\\begin{split}\n\\hat{\\mathbf{y}}_1 &= \\phi(W_1 \\mathbf x + \\mathbf w_{1_0}) \\\\\n\\hat{\\mathbf y}_2 &= \\phi_2(W_2 \\hat{\\mathbf{y}}_1 + \\mathbf w_{2_0})\\\\\n\\hat{\\mathbf y} &= (W_3 \\hat{\\mathbf{y}}_2 + \\mathbf w_{3_0})\n\\end{split},\n\\]\ndonde la salida de la primera capa oculta (\\(\\hat{\\mathbf{y}}_1\\)) es la entrada de la segunda capa oculta y su salida (\\(\\hat{\\mathbf{y}}_2\\)) se convierte en la entrada de la capa de salida.\n\n11.5.1 Desvanecimiento del Gradiente\nPor lo expuesto hasta el momento se podría pensar que una candidata para ser la función \\(\\phi\\) es la función \\(\\textsf{sigmoid},\\) aunque esto es factible, esta presenta el problema de desvanecimiento del gradiente. Para ejemplificar este problema, se utilizan dos funciones \\(g_1(x) = w_1 x + 1.0\\) y \\(g_1(x) = w_2 x + 1.0;\\) haciéndose la composición de estas dos funciones \\(g=g_2 \\circ g_1.\\)\nLas siguientes instrucciones implementan las funciones anteriores utilizando la librería JAX.\n\n@jax.jit\ndef g_1(params, x):\n    return jax.nn.sigmoid(params['w1'] * x + 1.0)\n\n@jax.jit\ndef g_2(params, x):\n    return jax.nn.sigmoid(params['w2'] * x + 1.0)\n\n@jax.jit\ndef g(params, x):\n    return g_2(params, g_1(params, x))\n\nUtilizando unos parámetros aleatorios generados con el siguiente código\n\nkey = jax.random.PRNGKey(0)\nkey, subkey1, subkey2 = jax.random.split(key, num=3)\nparams = dict(w1=jax.random.normal(subkey1),\n              w2=jax.random.normal(subkey2))\n\nse tiene que la derivada de \\(g_1\\) con respecto a \\(w_1\\) (i.e., jax.grad(g_1)(params, 1.0)) y \\(g_2\\) con respecto a \\(w_2\\) (i.e., jax.grad(g_2)(params, 1.0)) es 0.1418 y 0.1171, respectivamente. El problema viene cuando se calcula \\(\\frac{\\partial g}{\\partial w_1}\\) en este caso se obsevar que el gradiente es pequeño comparado con el gradiente obtenido en \\(\\frac{d g}{d w_1},\\) i.e., jax.grad(g)(params, 1.0), donde se observa que el gradiente para \\(w_1\\) corresponde a 0.0157, el gradiente de \\(w_2\\) sigue en la misma mágnitud teniendo un valor de 0.1077.\nEl problema de desvanecimiento de gradiente, hace que el gradiente disminuya de manera exponencial, entonces los pesos asociados a las capas alejadas de la capa de salida reciben un gradiente equivalente a cero y no se cuenta con información para actualizar sus pesos. Por este motivo es recomendable utilizar funciones de activación que no presenten esta característica, una muy utilizada es \\(\\textsf{ReLU}(x) = \\max(0, x)\\).",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Redes Neuronales</span>"
    ]
  },
  {
    "objectID": "capitulos/11RedesNeuronales.html#ejemplo-dígitos",
    "href": "capitulos/11RedesNeuronales.html#ejemplo-dígitos",
    "title": "11  Redes Neuronales",
    "section": "11.6 Ejemplo: Dígitos",
    "text": "11.6 Ejemplo: Dígitos\nPara ejemplificar el uso de una red neuronal en un poblema de clasificación se utilizarán los datos de Dígitos, los cuales se pueden obtener con las siguientes instrucciones.\n\nX, y = load_digits(return_X_y=True)\nT, G, y_t, y_g = train_test_split(X, y, test_size=0.2)\n\nUn procedimiento necesario en redes neuronales es que los datos estén normalizados, tradicionalmente esto se realiza haciendo que los datos tengan media cero y desviación estandar uno. En las siguientes lineas se normalizan los datos usando la clase StandardScaler se puede observar que los parámetros para la normalización son encontrados en el conjunto de entrenamiento (T) y aplicados tanto al conjunto de entrenamiento como el conjunto de prueba G.\n\nnormalize = StandardScaler().fit(T)\nT = normalize.transform(T)\nG = normalize.transform(G)\n\nComo se realizó previamente es necesario convertir las clases de salida para que cada ejemplo sea un vector unitario donde el índice con el valor \\(1\\) representa la clase, esto se realiza con las siguientes instrucciones.\n\nn_labels = np.unique(y).shape[0]\nyt_oh = jax.nn.one_hot(y_t, n_labels)\n\nEs momento de decidir la estructura de la red neuronal, las únicas dos restricciones es que la primera capa tiene que tener la dimensión del vector de entrada, en esta caso corresponde a \\(64\\) (T.shape[1]) y la última capa tiene que tener de salida el número de clases, en este caso \\(10\\) (n_labels), el resto de las capas ocultas pueden tener cualquier valor solamente es necesario que la dimensiones sean coherentes con la operación que se va a realizar.\nLa red que se va a implementar es la siguiente, como super-índice se encuentran las dimensiones para que sea más fácil seguir la estructura de la red.\n\\[\n\\begin{split}\n\\hat{\\mathbf{y}}_1^{32} &= \\phi(W^{32\\times 64} \\mathbf x^{64} + \\mathbf w_{1_0}^{32})\\\\\n\\hat{\\mathbf{y}}_2^{16} &= \\phi(W^{16\\times 32} \\hat{\\mathbf{y}}_1^{32} + \\mathbf w_{2_0}^{16})\\\\\n\\hat{\\mathbf{y}}^{10} &= W^{10\\times 16} \\hat{\\mathbf{y}}_2^{16} + \\mathbf w_{3_0}^{10}\n\\end{split}\n\\]\nConsiderando que las entradas se encuentran en una matrix \\(X^{N\\times64},\\) entonces se puede definir esta estructura en términos de múltiplicación de matrices, lo cual queda como\n\\[\n\\begin{split}\n\\hat{Y}_1^{N\\times 32} &= \\phi(X^{N\\times 64} W^{64\\times 32} + \\mathbf w_{1_0}^{32})\\\\\n\\hat{Y}_2^{N\\times 16} &= \\phi(\\hat{Y}_1^{N\\times 32} W^{32\\times 16} + \\mathbf w_{2_0}^{16})\\\\\n\\hat{Y}^{N\\times 10} &= \\hat{Y}_2^{N\\times 16} W^{16\\times 10} + \\mathbf w_{3_0}^{10}\\\\\n\\end{split},\n\\]\ndonde la suma con el término \\(\\mathbf w_0\\) se realiza en la dimensión que corresponde y se replica tantas veces para cumplir con la otra dimensión. Esta configuración se puede expresar en un lista como la que se muestra a continuación.\n\nd = [64, 32, 16, 10]\n\nUtilizando esta notación los parámetros iniciales de la red se pueden generar con la siguiente función, se puede observar como el ciclo está iterando por los elementos de d creando pares, para generar las dimensiones adecuadas para las matrices \\(W.\\)\n\ndef parametros_iniciales(d, key=0):\n    key = jax.random.PRNGKey(key)\n    params = []\n    for init, end in zip(d, d[1:]):\n        key, subkey1, subkey2 = jax.random.split(key, num=3)\n        _ = dict(w=jax.random.normal(subkey1, (init, end)) * jnp.sqrt(2 / (init * end)),\n                 w0=jax.random.normal(subkey2, (end, )) * jnp.sqrt(2 / end))\n        params.append(_)\n    return params\n\nHabiendo generado los parámetros iniciales de la red, es momento para implmentar la red, la siguiente función implementa la red, se puede observar como es realizan las operaciones matriciales tal y como se mostraron en las ecuaciones anteriores. La función de activiación \\(\\phi\\) seleccionada fue \\(\\textsf{ReLU}\\) que está implementada en la función jax.nn.relu.\n\n@jax.jit\ndef ann(params, D):\n    y1 = jax.nn.relu(D @ params[0]['w'] + params[0]['w0'])\n    y2 = jax.nn.relu(y1 @ params[1]['w'] + params[1]['w0'])\n    return y2 @ params[2]['w'] + params[2]['w0']\n\nComo medida de error se usa la Entropía Cruzada (Sección 4.2.7) tal y como se implementa a continuación. El caso \\(0 \\log 0\\) corresponde a un valor no definido lo cual genera que el valor de la función tampoco este definido, para proteger la función en ese caso se usa jnp.nansum que trata los valores no definidos como ceros.\n\n@jax.jit\ndef media_entropia_cruzada(params, D, y_oh):\n    hy = jax.nn.softmax(ann(params, D), axis=1)\n    return - jnp.nansum(y_oh * jnp.log(hy), axis=1).mean()\n\nEn esta ocasión se utiliza el optimizador Adam, tal y como se muestra en la siguiente función. La única diferencia con respecto al visto previamente es la función update_finite que actualiza los parámetros siempre y cuando el nuevo valor sea un valor numérico, de los contrario se queda con el valor anterior.\n\ndef adam(optimizer, params, epocas=500):\n    @jax.jit\n    def update_finite(a, b):\n        m = jnp.isfinite(b)\n        return jnp.where(m, b, a)\n    \n    @jax.jit\n    def update(params, opt_state, X, y_oh):\n        loss_value, grads = error_grad(params, X, y_oh)\n        updates, opt_state = optimizer.update(grads, opt_state, params)\n        params = optax.apply_updates(params, updates)\n        return params, opt_state, loss_value\n    \n    opt_state = optimizer.init(params)\n    error_grad  = jax.value_and_grad(media_entropia_cruzada)    \n    error = []\n    for i in range(epocas):\n        p, opt_state, loss_value = update(params, opt_state, T, yt_oh)\n        params = jax.tree_map(update_finite, params, p)\n        error.append(loss_value)\n    return params, error\n\nFinalmente, la red creada se entrana utilizando las siguientes instrucciones, donde la primera linea genera los parámetros iniciales, después se inicializa el optimizador y en la línea final se llama al optimizador con los parámetros y número de épocas.\n\nparams = parametros_iniciales(d)\noptimizer = optax.adam(learning_rate=1e-2)\np, error = adam(optimizer, params, epocas=500)\n\n/var/folders/wk/rlx2pk5j42v6mpjfd_0842c00000gn/T/ipykernel_42054/978170560.py:19: DeprecationWarning: jax.tree_map is deprecated: use jax.tree.map (jax v0.4.25 or newer) or jax.tree_util.tree_map (any JAX version).\n  params = jax.tree_map(update_finite, params, p)\n\n\nEl resultado de esta red, es que el error en el conjunto de prueba es \\(0.0528\\) calculado con la siguiente instrucción (ann(p, G).argmax(axis=1) != y_g).mean().",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Redes Neuronales</span>"
    ]
  },
  {
    "objectID": "capitulos/12Ensambles.html",
    "href": "capitulos/12Ensambles.html",
    "title": "12  Ensambles",
    "section": "",
    "text": "12.1 Paquetes usados\nEl objetivo de la unidad es conocer y aplicar diferentes técnicas para realizar un ensamble de clasificadores o regresores.\nfrom scipy.stats import binom\nfrom sklearn.datasets import load_diabetes, load_digits\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import LinearSVC, LinearSVR, SVR\nfrom sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.ensemble import StackingRegressor\nfrom sklearn.metrics import recall_score, mean_absolute_percentage_error\nfrom collections import Counter\nfrom matplotlib import pylab as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Ensambles</span>"
    ]
  },
  {
    "objectID": "capitulos/12Ensambles.html#sec-intro-12",
    "href": "capitulos/12Ensambles.html#sec-intro-12",
    "title": "12  Ensambles",
    "section": "12.2 Introducción",
    "text": "12.2 Introducción\nComo se ha visto hasta el momento, cada algoritmo de clasificación y regresión tiene un sesgo, este puede provenir de los supuestos que se asumieron cuando se entrenó o diseño; por ejemplo, asumir que los datos provienen de una distribución gaussiana multivariada o que se pueden separar los ejemplos mediante un hiperplano, entre otros. Dado un problema se desea seleccionar aquel algoritmo que tiene el mejor rendimiento, visto de otra manera, se selecciona el algoritmo cuyo sesgo este mejor alineado al problema. Una manera complementaria sería utilizar varios algoritmos y tratar de predecir basados en las predicciones individuales de cada algoritmo. En esta unidad se explicarán diferentes metodologías que permiten combinar predicciones de algoritmos de clasificación y regresión.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Ensambles</span>"
    ]
  },
  {
    "objectID": "capitulos/12Ensambles.html#sec-fundamentos",
    "href": "capitulos/12Ensambles.html#sec-fundamentos",
    "title": "12  Ensambles",
    "section": "12.3 Fundamentos",
    "text": "12.3 Fundamentos\nLa descripción de ensambles se empieza observando el siguiente comportamiento. Suponiendo que se cuenta con \\(M\\) algoritmos de clasificación binaria cada uno tiene una exactitud de \\(p=0.51\\) y estos son completamente independientes. El proceso de clasificar un elemento corresponde a preguntar la clase a los \\(M\\) clasificadores y la clase que se recibe mayor votos es la clase seleccionada, esta votación se comporta como una variable aleatoria que tiene una distribución Binomial. Suponiendo con la clase del elemento es \\(1\\), en esta condición la función cumulativa de distribución (\\(\\textsf{cdf}\\)) con parámetros \\(k=\\lfloor \\frac{M}{2}\\rfloor,\\) \\(n=M\\) y \\(p=0.51\\) indica seleccionar la clase \\(0\\) y \\(1 - \\textsf{cdf}\\) corresponde a la probabilidad de seleccionar la clase \\(1\\).\nLa Figura 12.1 muestra como cambia la exactitud, cuando el número de clasificadores se incrementa, cada uno de esos clasificadores son independientes y tiene una exactitud de \\(p=0.51,\\) se puede observar que cuando \\(M=501\\) el rendimiento es \\(0.673\\) y con \\(9,999\\) clasificadores se tiene un valor de \\(0.977.\\)\n\n\nCódigo\nN = range(3, 10002, 2)\ncdf_c = [1 - binom.cdf(np.floor(n / 2), n, 0.51) for n in N]\ndf = pd.DataFrame(dict(accuracy=cdf_c, ensamble=N))\n_ = sns.relplot(data=df, x='ensamble', y='accuracy', kind='line')\n\n\n\n\n\n\n\n\nFigura 12.1: Rendimiento cuando el número de clasificadores se incrementa\n\n\n\n\n\n\nEn el caso de regresión, en particular cuando se usa como función de error el cuadrado del error, i.e., \\((\\hat y - y)^2\\) se tiene el intercambio entre varianza y sesgo, el cual se deriva de la siguiente manera.\n\\[\n\\begin{split}\n\\mathbb E[(\\hat y - y)^2] &=\\\\\n&=\\mathbb E[(\\hat y - \\mathbb E[\\hat y] + \\mathbb E[\\hat y] - y)^2]\\\\\n&=\\underbrace{\\mathbb E[(\\hat y - \\mathbb E[\\hat y])^2]}_{\\mathbb V(\\hat y)} + \\mathbb E[(\\mathbb E[\\hat y] - y)^2] \\\\\n&+ 2 \\mathbb E[(\\hat y - \\mathbb E[\\hat y])(\\mathbb E[\\hat y] - y)]\\\\\n&=\\mathbb V(\\hat y) + (\\underbrace{\\mathbb E[\\hat y] - y}_{\\text{sesgo}})^2 + 2 \\underbrace{\\mathbb E[(\\hat y - \\mathbb E[\\hat y])]}_{\\mathbb E[\\hat y] - \\mathbb E[\\hat y] = 0}(\\mathbb E[\\hat y] - y)\\\\\n&=\\mathbb V(\\hat y) + (\\mathbb E[\\hat y] - y)^2\n\\end{split}\n\\]\nSe observa que el cuadrado del error está definido por la varianza de \\(\\hat y\\) (i.e., \\(\\mathbb V(\\hat y)\\)), la cual es independiente de la salida \\(y\\) y el sesgo al cuadrado del algoritmo (i.e., \\((\\mathbb E[\\hat y] - y)^2\\)).\nEn el contexto de ensamble, asumiendo que se tienen \\(M\\) regresores independientes donde la predicción está dada por \\(\\bar y = \\frac{1}{M}\\sum_{i=1}^M \\hat y^i\\), se tiene que el sesgo de cada predictor individual es igual al sesgo de su promedio (i.e., \\((\\mathbb E[\\bar y] - y) = (\\mathbb E[\\hat y^i] - y)\\)) como se puede observar a continuación.\n\\[\n\\begin{split}\n\\mathbb E[\\bar y] &= \\mathbb E[\\frac{1}{M} \\sum_{i=1}^M \\hat y^i]\\\\\n&=\\frac{1}{M} \\sum_{i=1}^M \\underbrace{\\mathbb E[\\hat y^i]}_{\\mathbb E[\\hat y]} =\\frac{1}{M} M \\mathbb E[\\hat y] =\\mathbb E[\\hat y]\n\\end{split}\n\\]\nPor otro lado la varianza del promedio (i.e., \\(\\mathbb V(\\bar y)\\)) está dada por \\(\\mathbb V(\\bar y)=\\frac{1}{M} \\mathbb V(\\hat y)\\), que se deriva siguiendo los pasos del error estándar de la media (Sección A.1.1).\nEsto quiere decir que si se tienen \\(M\\) regresores independientes, entonces el error cuadrado de su promedio es menor que el error de cada regresor individual, esto es porque su la varianza se reduce tal y como se mostró.\nTanto en el caso de clasificación como en el caso del error cuadrado, es poco probable contar con clasificadores y regresores que sean completamente independientes, entonces sus predicciones van a estar relacionadas en algún grado y no se podrá llegar a las reducciones obtenidas en el procedimiento presentado.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Ensambles</span>"
    ]
  },
  {
    "objectID": "capitulos/12Ensambles.html#sec-bagging",
    "href": "capitulos/12Ensambles.html#sec-bagging",
    "title": "12  Ensambles",
    "section": "12.4 Bagging",
    "text": "12.4 Bagging\nSiguiendo con la idea de combinar \\(M\\) instancias independientes de un tipo de algoritmo, en esta sección se presenta el algoritmo Bagging (Bootstrap Aggregation) el cual como su nombre lo indica se basa la técnica de Bootstrap (Sección A.2) para generar \\(M\\) instancias del algoritmo y la combinación es mediante votación o el promedio en caso de regresión o que se cuente con la probabilidad de cada clase.\n\n12.4.1 Ejemplo: Dígitos\nPara ejemplificar el uso del algoritmo de Bagging se utilizará el conjunto de datos de Dígitos. Estos datos se pueden obtener y generar el conjunto de entrenamiento (\\(\\mathcal T\\)) y prueba (\\(\\mathcal G\\)) con las siguientes instrucciones.\n\nX, y = load_digits(return_X_y=True)\nT, G, y_t, y_g = train_test_split(X, y,\n                                  test_size=0.2,\n                                  random_state=0)\n\nLos algoritmos que se utilizarán de base son Máquinas de Soporte Vectorial Lineal (Sección 9.4) y Árboles de Decisión (Capítulo 8). Lo primero que se realizará es entrenar una instancia de estos algoritmos para poder comparar su rendimiento en el conjunto de prueba contra Bagging.\nLa siguientes instrucciones entrenan una máquina de soporte vectorial, calculando en la segunda línea el macro-recall (Sección 4.2.6). El rendimiento se presenta en una tabla para facilitar la comparación.\n\nsvc = LinearSVC(dual=False).fit(T, y_t)\nsvc_recall = recall_score(y_g, svc.predict(G),\n                          average=\"macro\")\n\nComplementando las instrucciones anteriores, en el siguiente código se entrena un Árbol de Decisión.\n\ntree = DecisionTreeClassifier(criterion='entropy',\n                              min_samples_split=9).fit(T, y_t)\ntree_recall = recall_score(y_g, tree.predict(G),\n                           average=\"macro\")\n\nEl algoritmo de Bootstrap inicia generando las muestras tal y como se realizó en el ejemplo del error estándar de la media (Sección A.2.1); el siguiente código genera las muestras, en particular el ensamble sería de \\(M=11\\) elementos.\n\nB = np.random.randint(T.shape[0],\n                      size=(11, T.shape[0]))\n\nEmpezando con Bagging usando como clasificador base la Máquina de Soporte Vectorial Lineal. La primera línea de las siguientes instrucciones, entra los máquinas de soporte, después se realizan las predicciones. En la tercera línea se calcula la clase que tuvo la mayor cantidad de votos y finalmente se calcula el error en términos de macro-recall.\n\nsvc_ins = [LinearSVC(dual=False).fit(T[b], y_t[b])\n           for b in B]\nhys = np.array([m.predict(G) for m in svc_ins])\nhy = np.array([Counter(x).most_common(n=1)[0][0]\n               for x in hys.T])\nbsvc_recall = recall_score(y_g, hy, average=\"macro\")\n\nEl siguiente algoritmo son los Árboles de Decisión; la única diferencia con respecto a las instrucciones anteriores es la primera línea donde se entrenan los árboles.\n\ntree_ins = [DecisionTreeClassifier(criterion='entropy',\n                                   min_samples_split=9).fit(T[b], y_t[b])\n            for b in B]\nhys = np.array([m.predict(G) for m in tree_ins])\nhy = np.array([Counter(x).most_common(n=1)[0][0]\n               for x in hys.T])\nbtree_recall = recall_score(y_g, hy,\n                            average=\"macro\")\n\nComo se mencionó, la predicción final se puede realizar de dos manera en clasificación una es usando votación, como se vió en los códigos anteriores y la segunda es utilizando el promedio de las probabilidades. En el caso de las Máquinas de Soporte Vectorial, estas no calculas las probabilidad de cada clase, pero se cuenta con el valor de la función de decisión, en el siguiente código se usa está información, la segunda y tercera línea normaliza los valores para que ningún valor sea mayor que \\(1\\) y menor que \\(-1\\) y finalmente se calcula la suma para después seleccionar la clase que corresponde al argumento máximo.\n\nhys = np.array([m.decision_function(G) for m in svc_ins])\nhys = np.where(hys &gt; 1, 1, hys)\nhys = np.where(hys &lt; -1, -1, hys)\nhys = hys.sum(axis=0)\ncsvc_recall = recall_score(y_g, hys.argmax(axis=1),\n                           average=\"macro\")\n\nEl procedimiento anterior se puede adaptar a los Árboles de Decisión utilizando el siguiente código.\n\nhys = np.array([m.predict_proba(G)\n                for m in tree_ins])\nctree_recall = recall_score(y_g,\n                            hys.sum(axis=0).argmax(axis=1),\n                            average=\"macro\")\n\nFinalmente, la Tabla 12.1 muestra el rendimiento de las diferentes combinaciones, se puede observar el valor tanto de las Máquinas de Soporte Vectorial (M.S.V) Lineal y de los Árboles de decisión cuando se utilizaron fuera del ensamble; en el segundo renglón se muestra el rendimiento cuando la predicción del ensamble se hizo mediante votación y el último renglón presenta el rendimiento cuando se hace la suma.\nComparando los diferentes rendimientos, se puede observar que no existe mucha diferencia en rendimiento en las M.S.V Lineal y que la mayor mejora se presentó en los Árboles de Decisión. Este comportamiento es esperado dado que para que Bagging funciones adecuadamente requiere algoritmos inestables, es decir, algoritmos cuyo comportamiento cambia considerablemente con un cambio pequeño en el conjunto de entrenamiento, este es el caso de los Árboles. Por otro lado las M.S.V son algoritmos estables y un cambio pequeño en su conjunto de entrenamiento no tendrá una repercusión considerable en el comportamiento del algoritmo.\n\n\n\n\nTabla 12.1: Rendimiento (macro-recall) de bagging y estimadores base.\n\n\n\n\n\n\n\nM.S.V. Lineal\nÁrboles de Decisión\n\n\n\n\nÚnico\n\\(0.9425\\)\n \\(0.8342\\)\n\n\nVotación (\\(M=11\\))\n\\(0.9520\\)\n \\(0.9380\\)\n\n\nSuma (\\(M=11\\))\n\\(0.9471\\)\n \\(0.9323\\)\n\n\n\n\n\n\n\n\n\n\n12.4.2 Ejemplo: Diabetes\nAhora toca el turno de atacar un problema de regresión mediante Bagging, el problema que se utilizará es el de Diabetes. Las instrucciones para obtener el problema y generar los conjuntos de entrenamiento (\\(\\mathcal T\\)) y prueba (\\(\\mathcal G\\)) se muestra a continuación.\n\nX, y = load_diabetes(return_X_y=True)\nT, G, y_t, y_g = train_test_split(X, y,\n                                  random_state=0,\n                                  test_size=0.2)\n\nTomando el caso de Dígitos como base, el primer algoritmo a entrenar es la M.S.V. Lineal y se usa como mediada de rendimiento el porcentaje del error absoluto (Ecuación 4.6); tal y como se muestran en las siguientes instrucciones.\n\nsvr = LinearSVR(dual='auto').fit(T, y_t)\nsvr_mape = mean_absolute_percentage_error(y_g,\n                                          svr.predict(G))\n\nEl árbol de decisión y su rendimiento se implementa con el siguiente código.\n\ntree = DecisionTreeRegressor(min_samples_split=9).fit(T,\n                                                      y_t)\ntree_mape = mean_absolute_percentage_error(y_g,\n                                           tree.predict(G))\n\nAl igual que en el caso de clasificación, la siguiente instrucción genera los índices para generar las muestras. Se hace un ensamble de \\(M=11\\) elementos.\n\nB = np.random.randint(T.shape[0], size=(11, T.shape[0]))\n\nEn el caso de regresión, la predicción final corresponde al promedio de las predicciones individuales, la primera línea de las siguientes instrucciones se entrena las M.S.V Lineal, en la segunda instrucción se hacen las predicciones y se en la tercera se realiza el promedio y se mide el rendimiento.\n\nsvr_ins = [LinearSVR(dual='auto').fit(T[b], y_t[b])\n           for b in B]\nhys = np.array([m.predict(G) for m in svr_ins])\nbsvr_mape = mean_absolute_percentage_error(y_g,\n                                           hys.mean(axis=0))\n\nDe manera equivalente se entrenan los Árboles de Decisión, como se muestra a continuación.\n\ntree_ins = [DecisionTreeRegressor(min_samples_split=9).fit(T[b], y_t[b])\n            for b in B]\nhys = np.array([m.predict(G) for m in tree_ins])\nbtree_mape = mean_absolute_percentage_error(y_g,\n                                            hys.mean(axis=0))\n\nLa Tabla 12.2 muestra el rendimiento de los algoritmos de regresión utilizados, al igual que en el caso de clasificación, la M.S.V. no se ve beneficiada con el uso de Bagging. Por otro lado los Árboles de Decisión tienen un incremento en rendimiento considerable al usar Bagging.\n\n\n\n\nTabla 12.2: Rendimiento (MAPE) de bagging y estimadores base.\n\n\n\n\n\n\n\nM.S.V. Lineal\nÁrboles de Decisión\n\n\n\n\nÚnico\n\\(0.4131\\)\n \\(0.5479\\)\n\n\nPromedio (\\(M=11\\))\n\\(0.4132\\)\n \\(0.3946\\)\n\n\n\n\n\n\n\n\nHasta este momento los ensambles han sido de \\(M=11\\) elementos, queda la duda como varía el rendimiento con respecto al tamaño del ensamble. La Figura 12.2 muestra el rendimiento de Bagging utilizando Árboles de Decisión, cuando el ensamble cambia \\(M=2,\\ldots,500.\\) Se observa que alrededor que hay un decremento importante cuando el ensamble es pequeño, después el error se incrementa y vuelve a bajar alrededor de \\(M=100.\\) Finalmente se ve que el rendimiento es estable cuando \\(M&gt;200.\\)\n\n\nCódigo\nB = np.random.randint(T.shape[0], size=(500, T.shape[0]))\ntree_ins = [DecisionTreeRegressor(min_samples_split=9).fit(T[b], y_t[b]) for b in B]\nhys = np.array([m.predict(G) for m in tree_ins])\n\nM = range(2, len(tree_ins) + 1)\np = [mean_absolute_percentage_error(y_g, \n                                    hys[:i].mean(axis=0))\n     for i in M]\ndf = pd.DataFrame(dict(error=p, ensamble=M))\nsns.relplot(data=df, x='ensamble', y='error', kind='line')\n\n\n\n\n\n\n\n\nFigura 12.2: Variación del rendimiento con respecto al tamaño del ensamble (\\(M\\)).\n\n\n\n\n\n\n\n\n\n\n\nNota\n\n\n\nLas clases BaggingClassifier y BaggingRegressor implementan el ensamble de Bagging. Estas clases tienen parámetros que permiten ejecutar variaciones de la idea original. El uso de la clase BaggingRegressor se ilustra con el siguiente código,\n\ntree_ins = DecisionTreeRegressor(min_samples_split=9)\nens = BaggingRegressor(tree_ins).fit(T, y_t)\nhy = ens.predict(G)\n\ndonde el promedio del error absoluto es \\(0.3997.\\)",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Ensambles</span>"
    ]
  },
  {
    "objectID": "capitulos/12Ensambles.html#bosques-aleatorios-random-forest",
    "href": "capitulos/12Ensambles.html#bosques-aleatorios-random-forest",
    "title": "12  Ensambles",
    "section": "12.5 Bosques Aleatorios (Random Forest)",
    "text": "12.5 Bosques Aleatorios (Random Forest)\nEn la sección anterior se vió como se puede utilizar Bagging y Árboles de Decisión para generar un ensamble, en general Bagging (Sección 12.4) creado con árboles de decisión se les conoce como bosques aleatorios. Breiman (2001) propone los árboles aleatorios y muestra de manera teórica su comportamiento en la predicción así como de manera experimental su rendimiento en problemas de clasificación.\nEl uso de árboles aleatorios es directo mediante las clases RandomForestClassifier y RandomForestRegressor tal y como se muestra en el siguiente código:\n\nens = RandomForestRegressor(min_samples_split=9)\nens.fit(T, y_t)\nhy = ens.predict(G)\n\ndonde el promedio del error absoluto es \\(0.3924.\\)\n\n\n\n\n\n\nActividad\n\n\n\n\n\nVisualizar el efecto que tiene el parámetro min_samples_split en el algoritmo RandomForestClassifier cuando este varía como se muestra en Figura 12.3. El problema utilizado es el de dígitos (Sección B.3.3) con una partición de 80% para entrenamiento y 20% para validación.\n\n\n\n\n\n\n\n\nFigura 12.3: Cambio del rendimiento cuando el parámetro que controla el número de muestras para realizar la partición (i.e., min_samples_split) varía.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Ensambles</span>"
    ]
  },
  {
    "objectID": "capitulos/12Ensambles.html#stack-generalization",
    "href": "capitulos/12Ensambles.html#stack-generalization",
    "title": "12  Ensambles",
    "section": "12.6 Stack Generalization",
    "text": "12.6 Stack Generalization\nContinuando con la descripción de ensambles, se puede observar que Bagging en el caso de la media se puede representar como \\(\\sum_i^M \\frac{1}{M} \\hat y^i,\\) donde el factor \\(\\frac{1}{M}\\) se puede observar como un parámetro a identificar. Entonces la idea siguiente sería como se podría estimar parámetros para cada uno de los estimadores bases, e.g., \\(\\sum_i^M w_i \\hat y^i\\) donde \\(w_i\\) para bagging corresponde a \\(\\frac{1}{M}.\\) Se podría ir más allá y pensar que las predicciones \\(\\mathbf y=(\\hat y^1, \\ldots, \\hat y^M)\\) podrían ser la entrada a otro estimador.\nEsa es la idea detrás de Stack Generalization, Wolpert (1992) propone utilizar las predicciones de los estimadores bases como las entradas de otro estimador. Para poder llevar este proceso es necesario contar con un conjunto independiente del conjunto de entrenamiento para encontrar los parámetros del estimador que combina las predicciones.\n\n12.6.1 Ejemplo: Diabetes\nPara ejemplificar el uso de Stack Generalization, se usa el conjunto de datos de Diabetes. Como se acaba de describir es necesario contar con un conjunto independiente para estimar los parámetros del estimador del stack. Entonces el primer paso es dividir el conjunto de entrenamiento en un conjunto de entrenamiento y validación (\\(\\mathcal V,\\)) tal y como se muestra en la siguiente instrucción.\n\nT1, V, y_t1, y_v = train_test_split(T, y_t,\n                                    test_size=0.3)\n\nPara este ejemplo se usará como regresores bases el algoritmo de Vecinos Cercanos (Sección 7.7) con diferentes parámetros (primera línea), después se usan los modelos para predecir el conjunto de validación (\\(\\mathcal V\\)) y prueba (\\(\\mathcal G\\)), esto se observa en la segunda y tercera línea del siguiente código.\n\nmodels = [KNeighborsRegressor(n_neighbors=n).fit(T1, y_t1)\n          for n in [7, 9]]\nV_stack = np.array([m.predict(V) for m in models]).T\nG_stack = np.array([m.predict(G) for m in models]).T\n\nEl porcentaje del error absoluto (Ecuación 4.6) de los estimadores bases en el conjunto de prueba se puede calcular con el siguiente código\n\nmape_test = []\nfor hy in G_stack.T:\n  mape = mean_absolute_percentage_error(y_g, hy)\n  mape_test.append(mape)\n\nteniendo los siguientes valores \\(0.3694\\) y \\(0.3614\\), respectivamente.\nFinalmente, es momento de entrenar el regresor que combinará las salidas de los estimadores bases, i.e., Vecinos Cercanos. Se decidió utilizar una Máquina de Soporte Vectorial (Sección 9.4) con kernel polinomial de grado \\(2\\). Los parámetros de la máquina se estiman en la primera línea, y después se predicen los datos del conjunto de prueba.\n\nstacking = SVR(kernel='poly', degree=2).fit(V_stack, y_v)\nhy = stacking.predict(np.vstack(G_stack))\n\nEl error (Ecuación 4.6) obtenido por este procedimiento es de \\(0.3477\\); cabe mencionar que no en todos los casos el procedimiento de stacking consigue un mejor rendimiento que los estimadores bases. En las siguientes instrucciones se entrena un Bagging con Árboles de Decisión para ser utilizado en lugar de la Máquina de Soporte Vectorial.\n\nst_trees = BaggingRegressor(estimator=DecisionTreeRegressor(min_samples_split=9),\n                            n_estimators=200).fit(V_stack, y_v)\nhy = st_trees.predict(np.vstack(G_stack))\nmape = mean_absolute_percentage_error(y_g, hy)\n\nEl rendimiento de este cambio es \\(0.4239\\).\n\n\n\n\n\n\nNota\n\n\n\nLas classes StackingClassifier y StackingRegressor implementan la idea de Stack Generalization. El siguiente código muestra su uso en el ejemplo de diabetes, utilizando los algoritmos de vecinos cercanos y máquinas de soporte vectorial.\n\nmodels = [(f'KNN-{n}', KNeighborsRegressor(n_neighbors=n))\n          for n in [7, 9]]\nfinal_estimator = SVR(kernel='poly', degree=2)\nstack = StackingRegressor(models, final_estimator=final_estimator).fit(T, y_t)\nhy = stack.predict(G)\n\nEl promedio del error absoluto es \\(0.3751.\\)\n\n\n\n\n\n\n\n\nBreiman, Leo. 2001. «Random Forests». Machine Learning 45: 5-32. https://doi.org/10.1214/ss/1009213726.\n\n\nWolpert, David H. 1992. «Stacked generalization». Neural Networks 5 (2): 241-59. https://doi.org/https://doi.org/10.1016/S0893-6080(05)80023-1.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Ensambles</span>"
    ]
  },
  {
    "objectID": "capitulos/13Comparacion.html",
    "href": "capitulos/13Comparacion.html",
    "title": "13  Comparación de Algoritmos",
    "section": "",
    "text": "13.1 Paquetes usados\nEl objetivo de la unidad es conocer y aplicar diferentes procedimientos estadísticos para comparar y analizar el rendimiento de algoritmos.\nfrom CompStats import StatisticSamples, CI\nfrom CompStats import performance, plot_performance\nfrom CompStats import difference, plot_difference\nfrom scipy.stats import norm, wilcoxon\nfrom sklearn.datasets import load_iris, load_breast_cancer\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.metrics import recall_score\nimport numpy as np\nimport seaborn as sns\nimport pandas as pd",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Comparación de Algoritmos</span>"
    ]
  },
  {
    "objectID": "capitulos/13Comparacion.html#sec-intro-13",
    "href": "capitulos/13Comparacion.html#sec-intro-13",
    "title": "13  Comparación de Algoritmos",
    "section": "13.2 Introducción",
    "text": "13.2 Introducción\nHasta el momento se han descrito diferentes algoritmos de clasificación y regresión; se han presentado diferentes medidas para conocer su rendimiento, pero se ha dejado de lado el conocer la distribución de estas medidas para poder tener mayor información sobre el rendimiento del algoritmo y también poder comparar y seleccionar el algoritmo que tenga las mejores prestaciones ya sea en rendimiento o en complejidad.",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Comparación de Algoritmos</span>"
    ]
  },
  {
    "objectID": "capitulos/13Comparacion.html#sec-intervalos",
    "href": "capitulos/13Comparacion.html#sec-intervalos",
    "title": "13  Comparación de Algoritmos",
    "section": "13.3 Intervalos de confianza",
    "text": "13.3 Intervalos de confianza\nEl análisis del rendimiento se inicia partiendo de que el rendimiento se puede estimar a partir del conjunto de prueba, \\(\\mathcal G\\); el valor obtenido estima el rendimiento real, \\(\\theta\\), el cual se considera una constante. Una manera de conocer el rango de valores donde se puede encontrar \\(\\theta\\) es generando su intervalo de confianza. El intervalo de confianza de \\(\\theta\\) está dado por \\(C = (a(\\mathcal G), b(\\mathcal G)),\\) de tal manera que \\(P_{\\theta}(\\theta \\in C) \\geq 1 - \\alpha\\). Es importante mencionar que el intervalo no mide la probabilidad de \\(\\theta\\) dado que \\(\\theta\\) es una constante, en su lugar mide de que el valor estimado esté dentro de esos límites con esa probabilidad. Por otro lado se utiliza la notación \\(a(\\mathcal G)\\) y \\(b(\\mathcal G)\\) para hacer explicito que en este caso los límites del intervalo son obtenidos utilizando el conjunto de prueba. Una manera de entender el intervalo de confianza de cualquier parámetro es suponer que si el parámetro se estima \\(100\\) veces con el mismo procedimiento, en diferentes muestras, un intervalo del 95% de confianza dice que 95 de las veces la estimación del parámetro estará en el intervalo calculado.\n\n13.3.1 Método: Distribución Normal\nExisten diferentes procedimientos para generar intervalos de confianza, uno de ellos es asumir que la estimación de \\(\\theta\\), i.e., \\(\\hat \\theta\\) se distribuye como una normal, i.e., \\(\\hat \\theta \\sim \\mathcal N(\\mu, \\sigma^2),\\) donde \\(\\sigma=\\textsf{se}=\\sqrt{\\mathbb V(\\hat \\theta)}\\) corresponde al error estándar (Sección A.1) de la estimación \\(\\hat \\theta.\\) En estas condiciones el intervalo está dado por:\n\\[\nC = (\\hat \\theta - z_{\\frac{\\alpha}{2}}\\textsf{se}, \\hat \\theta + z_{\\frac{\\alpha}{2}}\\textsf{se}),\n\\]\ndonde \\(z_{\\frac{\\alpha}{2}} = \\Phi^{-1}(1 - \\frac{\\alpha}{2})\\) y \\(\\Phi\\) es la función de distribución acumulada de una normal.\n\n\n13.3.2 Ejemplo: Exactitud\nRecordado que dado una entrada el clasificador puede acertar la clase a la que pertenece esa entrada, entonces el resultado se puede representar como \\(1\\) si la respuesta es correcta y \\(0\\) de lo contrario. En este caso la respuesta es una variable aleatoria con una distribución de Bernoulli. Recordando que la distribución Bernoulli está definida por un parámetro \\(p\\), estimado como \\(\\hat p = \\frac{1}{N} \\sum_{i=1}^N \\mathcal X_i\\) donde \\(\\mathcal X_i\\) corresponde al resultado del algoritmo en el \\(i\\)-ésimo ejemplo. La varianza de una distribución Bernoulli es \\(p(1-p)\\) por lo que el error estándar es: \\(se=\\sqrt{\\frac{p(1-p)}{N}}\\) dando como resultado el siguiente intervalo:\n\\[\nC = (\\hat p_N - z_{\\frac{\\alpha}{2}}\\sqrt{\\frac{p(1-p)}{N}}, \\hat p_N + z_{\\frac{\\alpha}{2}}\\sqrt{\\frac{p(1-p)}{N}}).\n\\]\nSuponiendo \\(N=100\\) y \\(p=0.85\\) el siguiente código calcula el intervalo usando \\(\\alpha=0.05\\)\n\nalpha = 0.05\nz = norm().ppf(1 - alpha / 2)\np = 0.85\nN = 100\nCn = (p - z * np.sqrt(p * (1 - p) / N),\n      p + z * np.sqrt(p * (1 - p) / N))\n\ndando como resultado el siguiente intervalo, \\(C = (0.78, 0.92)\\).\nEn el caso anterior se supuso que se contaba con los resultados de un algoritmo de clasificación, con el objetivo de completar este ejemplo a continuación se presenta el análisis con un Naive Bayes en el problema del Iris.\nLo primero que se realiza es cargar los datos y dividir en el conjunto de entrenamiento (\\(\\mathcal T\\)) y prueba (\\(\\mathcal G\\)) como se muestra a continuación.\n\nX, y = load_iris(return_X_y=True)\nT, G, y_t, y_g = train_test_split(X, y,\n                                  random_state=1,  \n                                  test_size=0.3)\n\nEl siguiente paso es entrenar el algoritmo y realizar las predicciones en el conjunto de prueba (\\(\\mathcal G\\)) tal y como se muestra en las siguientes instrucciones.\n\nmodel = GaussianNB().fit(T, y_t)\nhy = model.predict(G)\n\nCon las predicciones se estima la exactitud y se siguen los pasos para calcular el intervalo de confianza como se ilustra en el siguiente código.\n\n_ = np.where(y_g == hy, 1, 0)\np = _.mean()\nN = _.shape[0]\nC = (p - z * np.sqrt(p * (1 - p) / N), p + z * np.sqrt(p * (1 - p) / N))\n\nEl intervalo de confianza obtenido es \\(C = (0.86, 1.01)\\). se puede observar que el límite superior es mayor que \\(1\\) lo cual no es posible dado que el máximo valor del accuracy es \\(1,\\) esto es resultado de generar el intervalo de confianza asumiendo una distribución normal.\nCuando se cuenta con conjuntos de datos pequeños y además no se ha definido un conjunto de prueba, se puede obtener las predicciones del algoritmo de clasificación mediante el uso de validación cruzada usando K-fold. En el siguiente código se muestra su uso, el cambio solamente es en el procedimiento para obtener las predicciones.\n\nkf = StratifiedKFold(n_splits=10,\n                     random_state=0,\n                     shuffle=True)\nhy = np.empty_like(y)\nfor tr, ts in kf.split(X, y):\n    model = GaussianNB().fit(X[tr], y[tr])\n    hy[ts] = model.predict(X[ts])\n\nEl resto del código es equivalente al usado previamente obteniendo el siguiente intervalo de confianza \\(C = (0.92, 0.99)\\).\n\n\n13.3.3 Método: Bootstrap del error estándar\nExisten ocasiones donde no es sencillo identificar el error estándar (\\(\\textsf{se}\\)) y por lo mismo no se puede calcular el intervalo de confianza. En estos casos se emplea la técnica de Bootstrap (Sección A.2) para estimar \\(\\mathbb V(\\hat \\theta).\\) Un ejemplo donde no es sencillo encontrar analíticamente el error estándar es en el \\(recall\\) (Sección 4.2.3).\nEs más sencillo entender este método mediante un ejemplo. Usando el ejercicio de \\(N=100\\) y \\(p=0.85\\) y \\(\\alpha=0.05\\) descrito previamente, el siguiente código primero construye las variables aleatorias de tal manera que den \\(p=0.85\\)\n\nalpha = 0.05\nN = 100\nz = norm().ppf(1 - alpha / 2)\nX = np.zeros(N)\nX[:85] = 1\n\nX es una arreglo que podrían provenir de la evaluación de un clasificador usando alguna medida de similitud entre predicción y valor medido. El siguiente paso es generar seleccionar con remplazo y obtener \\(\\hat \\theta\\) para cada muestra, en este caso \\(\\hat \\theta\\) corresponde a la media. El resultado se guarda en una lista \\(B\\) y se repite el experimento \\(500\\) veces.\n\nS = np.random.randint(X.shape[0],\n                      size=(500, X.shape[0]))\nB = [X[s].mean() for s in S]\n\nEl error estándar es y el intervalo de confianza se calcula con las siguientes instrucciones\n\nse = np.sqrt(np.var(B))\nC = (p - z * se, p + z * se)\n\nel intervalo de confianza corresponde a \\(C = (0.88, 1.03)\\).\nContinuando con el mismo ejemplo pero ahora analizando Naive Bayes en el problema del Iris. El primer paso es obtener evaluar las predicciones que se puede observar en el siguiente código (previamente descrito.)\n\nX, y = load_iris(return_X_y=True)\nkf = StratifiedKFold(n_splits=10,\n                     random_state=0,\n                     shuffle=True)\n\nhy = np.empty_like(y)\nfor tr, ts in kf.split(X, y):\n    model = GaussianNB().fit(X[tr], y[tr])\n    hy[ts] = model.predict(X[ts])\nX = np.where(y == hy, 1, 0)\n\nRealizando la selección con remplazo se obtiene el intervalo con las siguientes instrucciones\n\nB = [X[s].mean() for s in S]\nse = np.sqrt(np.var(B))\nC = (p - z * se, p + z * se)\n\nteniendo un valor de \\(C = (0.92, 0.98)\\).\n\n\n13.3.4 Método: Percentil\nExiste otra manera de calcular los intervalos de confianza y es mediante el uso del percentil, utilizando directamente las estimaciones realizadas a \\(\\hat \\theta\\) en la selección. El siguiente código muestra este método usando el ejemplo anterior,\nalpha = 0.05 / 2\nC = (np.percentile(B, alpha * 100),\n     np.percentile(B, (1 - alpha) * 100))\nobteniendo un intervalo de \\(C = (0.92, 0.98)\\).\n\n\n13.3.5 Ejemplo: macro-recall\nHasta el momento se ha usado una medida de rendimiento para la cual se puede conocer su varianza de manera analítica. Existen problemas donde esta medida no es recomendada, en el siguiente ejemplo utilizaremos macro-recall para medir el rendimiento de Naive Bayes en el problema del Iris. El primer paso es realizar las predicciones del algoritmo usando validación cruzada y hacer la muestra con reemplazo \\(B\\).\n\nalpha = 0.05\nz = norm().ppf(1 - alpha / 2)\n\nX, y = load_iris(return_X_y=True)\nkf = StratifiedKFold(n_splits=10,\n                     random_state=0,\n                     shuffle=True)\n\nhy = np.empty_like(y)\nfor tr, ts in kf.split(X, y):\n    model = GaussianNB().fit(X[tr], y[tr])\n    hy[ts] = model.predict(X[ts])\n\nS = np.random.randint(hy.shape[0],\n                      size=(500, hy.shape[0]))\nB = [recall_score(y[s], hy[s], average=\"macro\")\n     for s in S]\n\nEl siguiente paso es calcular el intervalo asumiendo que este se comporta como una normal tal y como se muestra en las siguientes instrucciones;\n\np = np.mean(B)\nse = np.sqrt(np.var(B))\nC = (p - z * se, p + z * se)\n\nobteniendo un intervalo de \\(C = (0.92, 0.99)\\) Completando el ejercicio, el intervalo se puede calcular directamente usando el percentil, estimando un intervalo de \\(C = (0.92, 0.98)\\)\n\n\n\n\n\n\nNota\n\n\n\nEl método de bootstrap para calcular el error estándar y el método de percentil para calcular el intervalo de confianza se pueden estimar utilizando la clase StatisticSamples. Las siguientes instrucciones se pueden utilizar para calcular el error estándar.\n\nrecall = lambda y, hy: recall_score(y, hy,\n                                    average=\"macro\")\n    \nstatistic = StatisticSamples(statistic=recall)\nsamples = statistic(y, hy)\nnp.std(samples)                               \n\n0.016940515918937093\n\n\nComplementando el intervalo de confianza con el método de percentil se implementa en el siguiente código.\n\nCI(samples)\n\n(0.9180458920264762, 0.9860852396514161)",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Comparación de Algoritmos</span>"
    ]
  },
  {
    "objectID": "capitulos/13Comparacion.html#comparación-de-algoritmos",
    "href": "capitulos/13Comparacion.html#comparación-de-algoritmos",
    "title": "13  Comparación de Algoritmos",
    "section": "13.4 Comparación de Algoritmos",
    "text": "13.4 Comparación de Algoritmos\nSe han descrito varios procedimientos para conocer los intervalos de confianza de un algoritmos de aprendizaje. Es momento para describir la metodología para conocer si dos algoritmos se comportan similar en un problema dado.\n\n13.4.1 Método: Distribución \\(t\\) de Student\nSuponiendo que se tienen las medidas de rendimiento de dos algoritmos mediante validación cruzada de K-fold, es decir, se tiene el rendimiento del primer algoritmo como \\(p_i^1\\) y del segundo como \\(p_i^2\\) en la \\(i\\)-ésima instancia. Suponiendo que el rendimiento es una normal, entonces la resta, i.e., \\(p_i = p_i^1 - p_i^2\\) también sería normal. Dado que se está comparando los algoritmos en los mismos datos, se puede utilizar la prueba \\(t\\) de Student de muestras dependientes. La estadística de la prueba está dada por \\(\\frac{\\sqrt{K} m}{S} \\sim t_{K-1}\\), donde \\(m\\) y \\(S^2\\) es la media varianza estimada.\nEn el siguiente ejemplo se compara el rendimiento de Árboles Aleatorios y Naive Bayes en el problema de Breast Cancer. El primer paso es cargar las librerías así como obtener las predicciones de los algoritmos.\n\nK = 30\nkf = StratifiedKFold(n_splits=K,\n                     random_state=0,\n                     shuffle=True)\nX, y = load_breast_cancer(return_X_y=True)\n\nP = []\nfor tr, ts in kf.split(X, y):\n    forest = RandomForestClassifier().fit(X[tr], y[tr]).predict(X[ts])\n    naive = GaussianNB().fit(X[tr], y[tr]).predict(X[ts])\n    P.append([recall_score(y[ts], hy, average=\"macro\") for hy in [forest, naive]])\nP = np.array(P)\n\nComo se puede observar la medida de rendimiento es macro-recall. Continuando con el procedimiento para obtener la estadística \\(t_{K-1}\\)\n\np = P[:, 0] - P[:, 1]\nt = np.sqrt(K) * np.mean(p) / np.std(p)\n\ndonde el valor de la estadística es \\(2.9329\\), si el valor está fuera del siguiente intervalo \\((-2.045, 2.045)\\) se rechaza la hipótesis nula de que los dos algoritmos se comportan similar.\nEn caso de que la medida de rendimiento no esté normalmente distribuido, la prueba no-parametrica equivalente corresponde a Wilcoxon. La instrucción wilcoxon(P[:, 0], P[:, 1]) se puede utilizar para calcularla, dando un \\(p_{\\text{value}}\\) de \\(0.0103\\). En ambos casos podemos concluir que los algoritmos Árboles Aleatorios y Naive Bayes son estadisticamente diferentes con una confianza del 95% en el problema de Breast Cancer.\n\n\n13.4.2 Método: Bootstrap en diferencias\nUn método para comparar el rendimiento de dos algoritmo que no asume ningún tipo de distribución se puede realizar mediante la técnica de Bootstrap. Nava-Muñoz, Graff, y Escalante (2024) utilizan esta idea para comparar diferentes algoritmos en el esquema de una competencia de aprendizaje supervisado. La idea es calcular las predicciones de los algoritmos y realizar la muestra calculando en cada una la diferencia del rendimiento. Este se procedimiento se explicará mediante un ejemplo.\nEl primer paso es calcular las predicciones de los algoritmos, en este caso se realizar una validación cruzada, tal y como se muestra a continuación.\n\nforest = np.empty_like(y)\nnaive = np.empty_like(y)\nfor tr, ts in kf.split(X, y):\n    forest[ts] = RandomForestClassifier().fit(X[tr], y[tr]).predict(X[ts])\n    naive[ts] = GaussianNB().fit(X[tr], y[tr]).predict(X[ts])\n\nEl macro-recall para los Bosques Aleatorios es \\(0.95\\) y para el Naive Bayes es \\(0.93\\). Lo que se observa es que los bosques tienen un mejor rendimiento, entonces la distribución de la diferencia del rendimiento entre bosques y Naive Bayes no debería de incluir al cero, si lo incluye la masa que está al lado izquierdo del cero debe de ser menor, esa mas corresponde al valor \\(p.\\)\nLas muestras de la diferencia de rendimiento se pueden calcular de las siguientes instrucciones.\n\nS = np.random.randint(y.shape[0],\n                      size=(500, y.shape[0]))\nr = recall_score                      \ndiff = lambda y, hy1, hy2: r(y, hy1, average=\"macro\") -\\\n                           r(y, hy2, average=\"macro\")\nB = [diff(y[s], forest[s], naive[s])\n     for s in S]\n\nFinalmente, el \\(p_{\\text{value}}\\) corresponde a la proporción de elementos que son menores que cero, i.e., (np.array(B) &lt; 0).mean(), es decir, aquellas muestras donde Naive Bayes tiene un mejor desempeño que los bosques. En este caso el \\(p_{\\text{value}}\\) tiene un valor de \\(0.0100\\). Dado que el valor es menor que \\(0.05\\) se puede rechazar la hipótesis nula con una confianza superior al 95% y concluir que existe una diferencia estadísticamente significativa en el rendimiento entre los dos algoritmos. La Figura 13.1 muestra la distribución de la diferencia de rendimiento, en esta se puede observar como la mayor parte de la masa se encuentra del lado positivo y que muy poca masa es menor que cero.\n\n\nCódigo\nfig = sns.displot(B, kde=True)\n\n\n\n\n\n\n\n\nFigura 13.1: Distribución de la diferencia de rendimiento",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Comparación de Algoritmos</span>"
    ]
  },
  {
    "objectID": "capitulos/13Comparacion.html#compstats",
    "href": "capitulos/13Comparacion.html#compstats",
    "title": "13  Comparación de Algoritmos",
    "section": "13.5 CompStats",
    "text": "13.5 CompStats\nLa librería CompStats permite realizar de manera sencilla la comparación entre el rendimiento de varios algoritmos, además de presentar gráficas sobre su comportamiento. Esta librería usa la técnica de Bootstrap tal y como se ha mostrado en este capítulo.\nLo primero que se realiza es calcular las muestras del rendimiento entre los dos algoritmos analizados, los cuales tienen sus predicciones en las variables naive y forest. En la primera línea se inicializa la variable macro_recall que calcula el promedio de la cobertura. La segunda línea crea un cuadro de datos (DataFrame) que contiene tanto la variable medida como las predicciones. La tercera línea calcula el rendimiento de los dos algoritmos.\n\nmacro_recall = lambda y, hy: recall_score(y, hy,\n                                          average='macro')\ndf = pd.DataFrame(dict(y=y,\n                       naive=naive,\n                       forest=forest))\nperf = performance(df, score=macro_recall)\n\nLa variable perf contiene las muestras del rendimiento de cada algoritmo. Por ejemplo, la siguiente línea calcula el intervalo de confianza de cada algoritmo.\n\nCI(perf)\n\n{'naive': (0.906377443590034, 0.9510763230509942),\n 'forest': (0.9321793126961182, 0.9704785347769698)}\n\n\nLos intervalos de confianza se pueden visualizar en la Figura 13.2.\n\n\nCódigo\nplot_performance(perf)\n\n\n\n\n\n\n\n\nFigura 13.2: Intervalos de confianzas\n\n\n\n\n\nEl segundo paso es conocer si la diferencia en rendimiento es significativa, en la Figura 13.3 se observa la comparación entre el mejor algoritmo (i.e., forest) y los otros algoritmos (naive) incluidos en la comparación. Se observa, en la figura, una linea puntuada que se encuentra en cero para facilitar la comparación, si el intervalo de confianza intersecta con la linea se puede concluir que los algoritmos comparados no son estadísticamente diferentes. En el ejemplo mostrado se ve que el intervalo no intersecta entonces se puede concluir que la hipótesis nula se puede descartar con una cierta confianza.\n\n\nCódigo\ndiff = difference(perf)\nplot_difference(diff)\n\n\n\n\n\n\n\n\nFigura 13.3: Comparación contra el mejor\n\n\n\n\n\n\n\n\n\n\n\nNava-Muñoz, Sergio, Mario Graff, y Hugo Jair Escalante. 2024. «Analysis of systems’ performance in natural language processing competitions». Pattern Recognition Letters, marzo. https://doi.org/10.1016/J.PATREC.2024.03.010.",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Comparación de Algoritmos</span>"
    ]
  },
  {
    "objectID": "capitulos/17Referencias.html",
    "href": "capitulos/17Referencias.html",
    "title": "Referencias",
    "section": "",
    "text": "Breiman, Leo. 2001a. “Random Forests.” Machine\nLearning 45: 5–32. https://doi.org/10.1214/ss/1009213726.\n\n\n———. 2001b. “Statistical Modeling: The Two Cultures.”\nStatistical Science 16 (3): 199–231. https://doi.org/10.1214/ss/1009213726.\n\n\nEsteva, Andre, Brett Kuprel, Roberto A. Novoa, Justin Ko, Susan M.\nSwetter, Helen M. Blau, and Sebastian Thrun. 2017.\n“Dermatologist-Level Classification of Skin Cancer with Deep\nNeural Networks.” Nature 542 (7639): 115–18. https://doi.org/10.1038/nature21056.\n\n\nFisher, Ronald Aylmer. 1936. “The Use of Multiple Measurements in\nTaxonomic Problems.” Annals of Eugenics 7 (2): 179–88.\nhttps://doi.org/https://doi.org/10.1111/j.1469-1809.1936.tb02137.x.\n\n\nHannun, Awni Y., Pranav Rajpurkar, Masoumeh Haghpanahi, Geoffrey H.\nTison, Codie Bourn, Mintu P. Turakhia, and Andrew Y. Ng. 2019.\n“Cardiologist-Level Arrhythmia Detection and Classification in\nAmbulatory Electrocardiograms Using a Deep Neural Network.”\nNature Medicine 25 (1): 65–69. https://doi.org/10.1038/s41591-018-0268-3.\n\n\nLangley, Pat. 1986. “Machine Learning: An Editorial.”\nMaching Learning 1: 5–10. https://doi.org/10.1023/A:1022687019898.\n\n\nMcInnes, Leland, John Healy, and James Melville. 2020. “UMAP:\nUniform Manifold Approximation and Projection for Dimension\nReduction.” https://arxiv.org/abs/1802.03426.\n\n\nNava-Muñoz, Sergio, Mario Graff, and Hugo Jair Escalante. 2024.\n“Analysis of Systems’ Performance in Natural Language Processing\nCompetitions.” Pattern Recognition Letters, March. https://doi.org/10.1016/J.PATREC.2024.03.010.\n\n\nQuinlan, J. R. 1986. “Induction of Decision Trees.”\nMachine Learning 1986 1:1 1 (March): 81–106. https://doi.org/10.1007/BF00116251.\n\n\nSebastiani, Fabrizio. 2015. “An Axiomatically Derived Measure for\nthe Evaluation of Classification Algorithms.” In Proceedings\nof the 2015 International Conference on the Theory of Information\nRetrieval, 11–20. ICTIR ’15. New York, NY, USA: Association for\nComputing Machinery. https://doi.org/10.1145/2808194.2809449.\n\n\nSilver, David, Aja Huang, Chris J. Maddison, Arthur Guez, Laurent Sifre,\nGeorge van den Driessche, Julian Schrittwieser, et al. 2016.\n“Mastering the Game of Go with Deep Neural Networks and Tree\nSearch.” Nature 529 (7587): 484–89. https://doi.org/10.1038/nature16961.\n\n\nSilver, David, Julian Schrittwieser, Karen Simonyan, Ioannis Antonoglou,\nAja Huang, Arthur Guez, Thomas Hubert, et al. 2017. “Mastering the\nGame of Go Without Human Knowledge.” Nature 550 (7676):\n354–59. https://doi.org/10.1038/nature24270.\n\n\nStreet, William Nick, William H. Wolberg, and Olvi L. Mangasarian. 1993.\n“Nuclear Feature Extraction for Breast Tumor Diagnosis.” In\nElectronic Imaging. https://api.semanticscholar.org/CorpusID:14922543.\n\n\nWasserman, Larry. 2004. All of Statistics : A Concise Course in\nStatistical Inference. Springer. https://doi.org/10.1007/978-0-387-21736-9.\n\n\nWolpert, David H. 1992. “Stacked Generalization.”\nNeural Networks 5 (2): 241–59. https://doi.org/https://doi.org/10.1016/S0893-6080(05)80023-1.\n\n\nXu, L., A. Krzyzak, and C. Y. Suen. 1992. “Methods of Combining\nMultiple Classifiers and Their Applications to Handwriting\nRecognition.” IEEE Transactions on Systems, Man, and\nCybernetics 22 (3): 418–35. https://doi.org/10.1109/21.155943.",
    "crumbs": [
      "Referencias"
    ]
  },
  {
    "objectID": "capitulos/14Estadistica.html",
    "href": "capitulos/14Estadistica.html",
    "title": "Apéndice A — Estadística",
    "section": "",
    "text": "Paquetes usados\nEl objetivo de este apéndice es complementar la información de algunos procedimientos estadísticos usados en el curso.\nfrom scipy.stats import norm\nfrom matplotlib import pylab as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns",
    "crumbs": [
      "Apéndices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Estadística</span>"
    ]
  },
  {
    "objectID": "capitulos/14Estadistica.html#sec-error-estandar",
    "href": "capitulos/14Estadistica.html#sec-error-estandar",
    "title": "Apéndice A — Estadística",
    "section": "A.1 Error estándar",
    "text": "A.1 Error estándar\nEl error estándar está definido como \\(\\sqrt{\\mathbb V(\\hat \\theta)}\\) donde \\(\\hat \\theta\\) es el valor estimado. No para todas las estadísticas es posible tener una ecuación analítica para calcular \\(\\sqrt{\\mathbb V(\\hat \\theta)}\\) y en los casos donde el valor analítico no se puede calcular se puede usar la técnica de Bootstrap.\n\nA.1.1 Media\nUna de las estadísticas donde si se puede calcular analíticamente \\(\\sqrt{\\mathbb V(\\hat \\theta)}\\) es la media, es decir, se tiene una muestra \\(\\mathcal D\\) con \\(N\\) elementos independientes y idénticamente distribuidos, entonces la media corresponde a\n\\[\\bar x = \\frac{1}{N} \\sum_{x \\in \\mathcal D} x.\\]\nEl error estándar de \\(\\bar x\\) es \\(\\sqrt{\\mathbb V(\\bar x)}\\). Para derivar el valor analítico de este error estándar es necesario utilizar la siguiente propiedad de la varianza:\n\\[\\mathbb V(\\sum_i a_i \\mathcal X_i) = \\sum_i a_i^2 \\mathbb V(\\mathcal X_i),\\]\ndonde \\(a_i\\) representa una constante y las variables aleatorias \\(\\mathcal X\\) son independientes. En lugar de utilizar la definición asumiendo la realización de las variables aleatorias, esto es, cuando \\(\\mathcal D\\) tiene valores, se define la media con respecto a \\(N\\) variables aleatorias, i.e., \\(\\bar{\\mathcal X} = \\frac{1}{N} \\sum_i^N \\mathcal X_i.\\) En estas condiciones se observa que para el caso del error estándar de la media la constante es \\(\\frac{1}{N}\\) y las variables son independientes entonces\n\\[\n\\begin{split}\n\\sqrt{\\mathbb V(\\bar{\\mathcal X})} &= \\sqrt{\\mathbb V(\\frac{1}{N} \\sum_i^N \\mathcal X_i)}\\\\\n&= \\sqrt{\\sum_i^N \\frac{1}{N^2} \\mathbb V(\\mathcal X_i)}\\\\\n&= \\sqrt{\\frac{1}{N^2} \\sum_i^N \\sigma^2}\\\\\n&= \\sqrt{\\frac{N}{N^2} \\sigma^2}\\\\\n&= \\sqrt{\\frac{\\sigma^2}{N}} = \\frac{\\sigma}{\\sqrt{N}},\n\\end{split}\n\\]\ndonde \\(\\sigma^2\\) es la varianza de la distribución. Es importante notar que \\(\\mathbb V(X_i)\\) es independiente de \\(i\\) dado \\(\\mathcal X_i \\sim F\\) para cualquier \\(i\\), donde la distribución \\(F\\) tiene una varianza \\(\\sigma^2\\) por lo tanto \\(\\mathbb V(X_i)=\\sigma^2.\\)\n\n\nA.1.2 Ejemplo: Media\nEl siguiente ejemplo complementa la información al presentar el error estándar de la media cuando los datos vienen de una distribución Gausiana. Suponiendo que se tiene \\(1000\\) muestras de una distribución Gausiana \\(\\mathcal N(1, 4),\\) i.e., \\(\\mu=1\\) y \\(\\sigma=2\\). La error estándar de estimar la media con esos datos está dado por \\(\\mathbb V(\\hat \\mu) = \\frac{\\sigma}{\\sqrt{N}} = \\frac{2}{\\sqrt{1000}}=0.0632.\\)\nContinuado con el ejemplo, se simula la generación de esta población de \\(1000\\) elementos. El primer paso es iniciar la clase norm (que implementa una distribución Gausiana) para que se simule \\(\\mathcal N(1, 4).\\) Es importante notar que el parámetro scale de norm corresponde a la desviación estándar \\(\\sigma.\\)\n\np1 = norm(loc=1, scale=2)\n\nUsando p1 se simulan 500 poblaciones de 1000 elementos cada una, y para cada una de esas poblaciones se calcula su media. La primera linea crea la muestra \\(\\mathcal D\\) y a continuación se calcula la media por cada población, renglón de D.\n\nD = p1.rvs(size=(500, 1000))\nmu = [x.mean() for x in D]\n\n\n\nEl error estándar es la desviación estándar de mu, el cual se puede calcular con la siguiente instrucción. se tiene un valor de \\(0.0665\\), que es similar al obtenido mediante \\(\\mathbb V(\\hat \\mu).\\)\n\n\n\nse = np.std(mu)\n\nPara complementar la información se presenta el histograma de mu donde se puede observar la distribución de estimar la media de una población.\n\nfig = sns.histplot(mu)\n\n\n\n\n\n\n\n\n\n\nA.1.3 Ejemplo: Coeficientes OLS\nEl error estándar de los coeficientes estimados con mínimos cuadrados se puede calcular de la siguiente forma. El primer paso es utilizar la siguiente identidad\n\\[\\mathbb V(A \\mathcal Y) = A \\Sigma A^\\intercal,\\]\ndonde \\(A\\) es una matriz y \\(\\mathcal Y\\) es un vector de variables aleatorias. La matriz \\(A\\) en OLS es\n\\[A=(X^\\intercal X)^{-1}X^\\intercal.\\]\nquedando la varianza como\n\\[\\mathbb V(\\mathbf w) = A \\Sigma A^\\intercal,\\]\ndonde \\(\\Sigma\\) es la covarianza de \\(\\mathcal Y.\\) Dado que \\(\\mathcal Y\\) tiene una varianza constante entonces \\(\\Sigma=\\sigma^2 I.\\) Usando esta información se puede derivar la varianza de \\(\\mathbf w\\) de la siguiente manera\n\\[\n\\begin{split}\n\\mathbb V(\\mathbf w) &= A \\sigma^2 I A^\\intercal \\\\  \n&= \\sigma^2 A  A^\\intercal \\\\\n&= \\sigma^2 (X^\\intercal X)^{-1}X^\\intercal ((X^\\intercal X)^{-1}X^\\intercal)^\\intercal\\\\\n&= \\sigma^2 (X^\\intercal X)^{-1}X^\\intercal X (X^\\intercal X)^{-1} \\\\\n&= \\sigma^2 (X^\\intercal X)^{-1}\\\\\n\\end{split}\n\\]\nPor lo tanto el error estándar es: \\(\\textsf{se}(\\mathbf w) = \\sigma \\sqrt{(X^\\intercal X)^{-1}}.\\)",
    "crumbs": [
      "Apéndices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Estadística</span>"
    ]
  },
  {
    "objectID": "capitulos/14Estadistica.html#sec-bootstrap",
    "href": "capitulos/14Estadistica.html#sec-bootstrap",
    "title": "Apéndice A — Estadística",
    "section": "A.2 Bootstrap",
    "text": "A.2 Bootstrap\nExisten ocasiones donde no se cuenta con una ecuación cerrada para \\(\\mathbb V(\\hat \\theta)\\), un ejemplo sería la mediana. En aquellas estadísticas donde no se tenga el error estándar no se pueda calcular analíticamente se puede utilizar Bootstrap.\nBootstrap es un procedimiento que permite calcular el error estándar. Suponiendo que se la estadística se calcula mediante la realización de \\(N\\) variables aleatorias, \\(\\mathcal X \\sim F\\), es decir, \\(\\theta = g(\\mathcal X_1, \\mathcal X_2, \\ldots, \\mathcal X_N).\\) Por ejemplo, la media es \\(g(\\mathcal X_1, \\mathcal X_2, \\ldots, \\mathcal X_N) = \\frac{1}{N} \\sum_i^N \\mathcal X_i.\\)\nEl Bootstrap simula la distribución \\(\\theta\\) mediante la selección con remplazo de \\(N\\) elementos del conjunto de la muestra \\(\\mathcal D = (x_1, x_2, \\ldots, x_n)\\) donde \\(x_i \\sim F\\). Es decir, se genera un nuevo conjunto \\(\\mathcal D_j = (x_{j_1}, x_{j_2}, \\ldots, x_{j_n})\\) donde \\(x_{j_1}\\) podría ser \\(x_4\\) de \\(\\mathcal D\\) y dado que se selecciona con reemplazo entonces \\(x_4\\) podría aparecer otra vez en \\(\\mathcal D_j.\\) Utilizando \\(\\mathcal D_j\\) se puede estimar la estadística \\(\\hat \\theta_j = g(x_{j_1}, x_{j_2}, \\ldots, x_{j_n}).\\) Bootstrap repite el proceso anterior \\(B\\) donde en cada iteración se selecciona con reemplazo \\(N\\) veces \\(\\mathcal D\\). Utilizando las \\(\\theta_j\\) calculadas se estima \\(\\mathbb V(\\theta)\\) con la siguiente ecuación\n\\[\\mathbb V(\\hat \\theta) = \\frac{1}{B} \\sum_{j=1}^B (\\hat \\theta_j - \\frac{1}{B} \\sum_k^B \\hat \\theta_k)^2.\\]\n\nA.2.1 Ejemplo\nUtilizando los datos generados en la Sección A.1.2 se puede calcular el error estándar de la mediana. El primer paso es tener el conjunto \\(\\mathcal D\\) el cual puede ser cualquier renglón de los 500 de la variable D, por simplicidad se toma el primero como se muestra a continuación.\n\nD_mediana = D[0]\n\nLa variable D_mediana tiene la muestra \\(\\mathcal D\\) con la que se trabajará para estimar el error estándar de la mediana. Se tienen que generar \\(B\\) repeticiones de muestrear \\(\\mathcal D\\) \\(N\\) veces con reemplazo. Esto se puede implementar usando índices y números aleatorios de \\([0, N)\\) considerando que en Python el primer índice es \\(0\\). Este procedimiento se muestra en la primera linea del siguiente código. El arreglo S contiene los índices para realizar las \\(B\\) muestras, en la segunda linea se itera por los renglones de S y en cada operación se calcula la mediana. Es decir, en cada iteración se está calculando un \\(\\hat \\theta_i\\) que corresponde a la mediana. Finalmente, se calcula la desviación estándar de la lista B y ese valor corresponde a error estándar de la mediana.\n\nS = np.random.randint(D_mediana.shape[0],\n                      size=(500, D_mediana.shape[0]))\nB = [np.median(D_mediana[s]) for s in S]\nse = np.std(B)\n\n\n\nse tiene un valor de \\(0.0735.\\)\n\n\nConsiderando que se generaron \\(500\\) poblaciones de \\(1000\\) elementos que se encuentra en la variable D se puede visualizar el histograma de las medianas calculadas con D y aquellas obtenidas con Bootstrap. Se guardan estos dos valores en un DataFrame para posteriormente graficar el histograma, como se muestra en el siguiente código y en la Figura A.1.\n\ndf = pd.DataFrame(dict(Bootstrap=B, \n                       Muestra=[np.median(x) for x in D]))\nfig = sns.histplot(df)                       \n\n\n\n\n\n\n\nFigura A.1: Histograma de la mediana",
    "crumbs": [
      "Apéndices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Estadística</span>"
    ]
  },
  {
    "objectID": "capitulos/16ConjuntosDatos.html",
    "href": "capitulos/16ConjuntosDatos.html",
    "title": "Apéndice B — Conjunto de Datos",
    "section": "",
    "text": "Paquetes usados\nEl objetivo de este apéndice es listar los conjuntos de datos utilizados en el curso.\nfrom sklearn.datasets import load_breast_cancer,\\\n                             load_diabetes,\\\n                             load_digits, load_iris,\\\n                             load_wine\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import decomposition\nfrom scipy.stats import multivariate_normal\nimport umap\nfrom matplotlib import pylab as plt\nimport matplotlib as mpl\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns",
    "crumbs": [
      "Apéndices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Conjunto de Datos</span>"
    ]
  },
  {
    "objectID": "capitulos/16ConjuntosDatos.html#problemas-sintéticos",
    "href": "capitulos/16ConjuntosDatos.html#problemas-sintéticos",
    "title": "Apéndice B — Conjunto de Datos",
    "section": "B.1 Problemas Sintéticos",
    "text": "B.1 Problemas Sintéticos\nEn esta sección se presentan los problemas sintéticos que corresponden aquellos problemas en los que se conocen todos los parámetros y se usan para mostrar algunas características de los algoritmos.",
    "crumbs": [
      "Apéndices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Conjunto de Datos</span>"
    ]
  },
  {
    "objectID": "capitulos/16ConjuntosDatos.html#mezcla-de-clases",
    "href": "capitulos/16ConjuntosDatos.html#mezcla-de-clases",
    "title": "Apéndice B — Conjunto de Datos",
    "section": "B.2 Mezcla de Clases",
    "text": "B.2 Mezcla de Clases\n\np1 = multivariate_normal(mean=[5, 5],\n                         cov=[[4, 0], [0, 2]])\nX_1 = p1.rvs(size=1000)\np2 = multivariate_normal(mean=[1.5, -1.5],\n                         cov=[[2, 1], [1, 3]])\nX_2 = p2.rvs(size=1000)\np3 = multivariate_normal(mean=[12.5, -3.5],\n                         cov=[[2, 3], [3, 7]])\nX_3 = p3.rvs(size=1000)\n\nFigura B.1 muestra estas tres distribuciones.\n\n\nCódigo\nD = np.concatenate((X_1, X_2, X_3))\nclase = [1] * 1000 + [2] * 1000 + [3] * 1000\nD = np.concatenate((D, np.atleast_2d(clase).T), axis=1)\ndf = pd.DataFrame(D, columns=['x', 'y', 'clase'])\n_ = sns.relplot(data=df, kind='scatter', x='x',\n                palette=PALETTE,\n                y='y', hue='clase')\n\n\n\n\n\n\n\n\nFigura B.1: Muestras de 3 distribuciones gausianas\n\n\n\n\n\n\nB.2.1 Clases Separadas\n\nX_1 = multivariate_normal(mean=[5, 5],\n                          cov=[[4, 0], [0, 2]]).rvs(1000)\nX_2 = multivariate_normal(mean=[-5, -10],\n                          cov=[[2, 1], [1, 3]]).rvs(1000)\nX_3 = multivariate_normal(mean=[15, -6],\n                          cov=[[2, 3], [3, 7]]).rvs(1000)\n\nEste problema se muestra en la Figura B.2.\n\n\nCódigo\nD = np.concatenate((X_1, X_2, X_3))\nclase = [1] * 1000 + [2] * 1000 + [3] * 1000\nD = np.concatenate((D, np.atleast_2d(clase).T), axis=1)\ndf = pd.DataFrame(D, columns=['x', 'y', 'clase'])\n_ = sns.relplot(data=df, kind='scatter', x='x',\n                palette=PALETTE,\n                y='y', hue='clase')\n\n\n\n\n\n\n\n\nFigura B.2: Muestras de 3 distribuciones gausianas",
    "crumbs": [
      "Apéndices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Conjunto de Datos</span>"
    ]
  },
  {
    "objectID": "capitulos/16ConjuntosDatos.html#problemas-de-clasificación",
    "href": "capitulos/16ConjuntosDatos.html#problemas-de-clasificación",
    "title": "Apéndice B — Conjunto de Datos",
    "section": "B.3 Problemas de Clasificación",
    "text": "B.3 Problemas de Clasificación\nEn esta sección se listan los problemas de clasificación utilizados durante el curso. La Tabla B.1 resume las principales características de los problemas utilizados. Se incluye la entropía como una media que está relacionada al desbalance de clases, la entropía está normalizada para que su rango se encuentre entre \\([0, 1].\\)\n\n\n\n\nTabla B.1: Problemas de clasificación\n\n\n\n\n\n\n\n\n\n\n\n\n\nNombre\nTamaño (\\(N\\))\nDimensión (\\(d\\))\nNúmero de clases (\\(K\\))\nEntropía\n\n\n\n\nBreast Cancer\n\\(569\\)\n\\(30\\)\n\\(2\\)\n0.95\n\n\nIris\n\\(150\\)\n\\(4\\)\n\\(3\\)\n1.00\n\n\nDígitos\n\\(1797\\)\n\\(64\\)\n\\(10\\)\n1.00\n\n\nVino\n\\(178\\)\n\\(13\\)\n\\(3\\)\n0.99\n\n\n\n\n\n\n\n\n\nB.3.1 Breast Cancer Wisconsin\nEl conjunto de datos de Breast Cancer Wisconsin (ver Street, Wolberg, y Mangasarian (1993)) se obtiene con el siguiente código. La Figura B.3 muestra una proyección utilizando PCA de este conjunto de datos.\n\nD, y = load_breast_cancer(return_X_y=True)\n\n\n\nCódigo\nD = StandardScaler().fit_transform(D)\npca = decomposition.PCA(n_components=2).fit(D)\nlow_dim = pca.transform(D)\n# reducer = umap.UMAP(n_neighbors=5)\n# low_dim = reducer.fit_transform(D)\ndf = pd.DataFrame(low_dim, columns=['x', 'y'])\ndf['Clase'] = y\nfig = sns.relplot(df, kind='scatter', \n                  legend='full',  # palette=pal,\n                   x='x', y='y', hue='Clase')\nfig.tick_params(bottom=False, top=False, \n                left=False, right=False,\n                labelbottom=False, labelleft=False)\n_ = fig.set(xlabel=None, ylabel=None)\n\n\n\n\n\n\n\n\nFigura B.3: Proyección mediante PCA del problema de Breast Cancer Wisconsin.\n\n\n\n\n\n\n\nB.3.2 Iris\nUn conjunto clásico en problemas de clasificación es el problema del Iris descrito por Fisher (1936); este problema se descarga con la siguiente instrucción. La Figura B.4 muestra una visualización de estos datos mediante PCA.\n\nD, y = load_iris(return_X_y=True)\n\n\n\nCódigo\nD = StandardScaler().fit_transform(D)\npca = decomposition.PCA(n_components=2).fit(D)\nlow_dim = pca.transform(D)\n# reducer = umap.UMAP(n_neighbors=5)\n# low_dim = reducer.fit_transform(D)\ndf = pd.DataFrame(low_dim, columns=['x', 'y'])\ndf['Clase'] = y\nfig = sns.relplot(df, kind='scatter', \n                  legend='full', palette=PALETTE,\n                   x='x', y='y', hue='Clase')\nfig.tick_params(bottom=False, top=False, \n                left=False, right=False,\n                labelbottom=False, labelleft=False)\n_ = fig.set(xlabel=None, ylabel=None)\n\n\n\n\n\n\n\n\nFigura B.4: Proyección mediante PCA del problema del Iris.\n\n\n\n\n\n\n\nB.3.3 Dígitos\nEl conjunto de Dígitos (ver Xu, Krzyzak, y Suen (1992)) es un conjunto de clasificación donde se trata de identificar el número escrito en una imagen; este conjunto de datos se descarga utilizando la siguiente instrucción. La Figura B.5 muestra una proyección de estos datos utilizando UMAP con ocho vecinos.\n\nD, y = load_digits(return_X_y=True)\n\n\n\nCódigo\npal = mpl.cm.Paired\nreducer = umap.UMAP(n_neighbors=8)\nD = StandardScaler().fit_transform(D)\nlow_dim = reducer.fit_transform(D)\ndf = pd.DataFrame(low_dim, columns=['x', 'y'])\ndf['Clase'] = y\nfig = sns.relplot(df, kind='scatter', \n                  legend='full', palette=PALETTE,\n                   x='x', y='y', hue='Clase')\nfig.tick_params(bottom=False, top=False, \n                left=False, right=False,\n                labelbottom=False, labelleft=False)\n_ = fig.set(xlabel=None, ylabel=None)\n\n\n\n\n\n\n\n\nFigura B.5: Proyección mediante UMAP del problema de Dígitos con ocho vecinos.\n\n\n\n\n\n\n\nB.3.4 Vino\nEl conjunto de Vino se obtiene con la siguiente instrucción. La Figura B.6 muestra una proyección de estos datos utilizando PCA.\n\nD, y = load_wine(return_X_y=True)\n\n\n\nCódigo\npal = mpl.cm.Paired\nD = StandardScaler().fit_transform(D)\npca = decomposition.PCA(n_components=2).fit(D)\nlow_dim = pca.transform(D)\n# reducer = umap.UMAP(n_neighbors=5)\n# low_dim = reducer.fit_transform(D)\ndf = pd.DataFrame(low_dim, columns=['x', 'y'])\ndf['Clase'] = y\nfig = sns.relplot(df, kind='scatter', \n                  legend='full', palette=PALETTE,\n                   x='x', y='y', hue='Clase')\nfig.tick_params(bottom=False, top=False, \n                left=False, right=False,\n                labelbottom=False, labelleft=False)\n_ = fig.set(xlabel=None, ylabel=None)\n\n\n\n\n\n\n\n\nFigura B.6: Proyección mediante PCA del problema del Vino.",
    "crumbs": [
      "Apéndices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Conjunto de Datos</span>"
    ]
  },
  {
    "objectID": "capitulos/16ConjuntosDatos.html#problemas-de-regresión",
    "href": "capitulos/16ConjuntosDatos.html#problemas-de-regresión",
    "title": "Apéndice B — Conjunto de Datos",
    "section": "B.4 Problemas de Regresión",
    "text": "B.4 Problemas de Regresión\nEn esta sección se listan los problemas de regresión utilizados para ejemplificar los algoritmos y su rendimiento.\n\nB.4.1 Problema Sintético\nEl siguiente ejemplo es un problema de regresión sintético que se forma de la suma de dos funciones trascendentales como se muestra en el siguiente código.\n\nX = np.linspace(-5, 5, 100)\ny = np.sin(X) + 0.3 * np.cos(X * 3.)\n\nLa Figura B.7 muestra este problema sintético.\n\n\nCódigo\ndf = pd.DataFrame(dict(X=X, y=y))\ndf.set_index('X', inplace=True)\nfig = sns.relplot(df, kind='line')\n\n\n\n\n\n\n\n\nFigura B.7: Problema de Regresión\n\n\n\n\n\n\n\nB.4.2 Diabetes\nEl conjunto de datos Diabetes es un problema que se puederecuperar usando el siguiente código.\n\nD, y = load_diabetes(return_X_y=True)\n\n\n\n\n\n\n\nFisher, Ronald Aylmer. 1936. «The use of multiple measurements in taxonomic problems». Annals of Eugenics 7 (2): 179-88. https://doi.org/https://doi.org/10.1111/j.1469-1809.1936.tb02137.x.\n\n\nStreet, William Nick, William H. Wolberg, y Olvi L. Mangasarian. 1993. «Nuclear feature extraction for breast tumor diagnosis». En Electronic imaging. https://api.semanticscholar.org/CorpusID:14922543.\n\n\nXu, L., A. Krzyzak, y C. Y. Suen. 1992. «Methods of combining multiple classifiers and their applications to handwriting recognition». IEEE Transactions on Systems, Man, and Cybernetics 22 (3): 418-35. https://doi.org/10.1109/21.155943.",
    "crumbs": [
      "Apéndices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Conjunto de Datos</span>"
    ]
  }
]