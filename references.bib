@article{EvoMSA,
author = {Mario Graff and Sabino Miranda{-}Jim{\'{e}}nez
               and Eric Sadit Tellez and Daniela Moctezuma},
title     = {EvoMSA: {A} Multilingual Evolutionary Approach for Sentiment Analysis},
journal   = {Computational Intelligence Magazine},
volume    = {15},
issue     = {1},
year      = {2020},
pages     = {76 -- 88},
url       = {https://ieeexplore.ieee.org/document/8956106},
month     = {Feb.}
}

@article{microTC,
title = "An automated text categorization framework based on hyperparameter optimization",
journal = "Knowledge-Based Systems",
volume = "149",
pages = "110--123",
year = "2018",
issn = "0950-7051",
doi = "10.1016/j.knosys.2018.03.003",
url = "https://www.sciencedirect.com/science/article/pii/S0950705118301217",
author = "Eric S. Tellez and Daniela Moctezuma and Sabino Miranda-Jiménez and Mario Graff",
keywords = "Text classification",
keywords = "Hyperparameter optimization",
keywords = "Text modelling"
}

@article{B4MSA,
title = {A {Simple} {Approach} to {Multilingual} {Polarity} {Classification} in {Twitter}},
issn = {0167-8655},
url = {http://www.sciencedirect.com/science/article/pii/S0167865517301721},
doi = {10.1016/j.patrec.2017.05.024},
abstract = {Recently, sentiment analysis has received a lot of attention due to the interest in mining opinions of social media users. Sentiment analysis consists in determining the polarity of a given text, i.e., its degree of positiveness or negativeness. Traditionally, Sentiment Analysis algorithms have been tailored to a specific language given the complexity of having a number of lexical variations and errors introduced by the people generating content. In this contribution, our aim is to provide a simple to implement and easy to use multilingual framework, that can serve as a baseline for sentiment analysis contests, and as a starting point to build new sentiment analysis systems. We compare our approach in eight different languages, three of them correspond to important international contests, namely, SemEval (English), TASS (Spanish), and SENTIPOLC (Italian). Within the competitions, our approach reaches from medium to high positions in the rankings; whereas in the remaining languages our approach outperforms the reported results.},
urldate = {2017-05-24},
journal = {Pattern Recognition Letters},
author = {Tellez, Eric S. and Miranda-Jiménez, Sabino and Graff, Mario and Moctezuma, Daniela and Suárez, Ranyart R. and Siordia, Oscar S.},
keywords = {Error-robust text representations, Multilingual sentiment analysis, Opinion mining},
year = {2017}
}

@misc{UMAP,
      title={UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction}, 
      author={Leland McInnes and John Healy and James Melville},
      year={2020},
      eprint={1802.03426},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@book{Wasserman2004,
   abstract = {This book is for people who want to learn probability and statistics quickly. It brings together many of the main ideas in modern statistics in one place. The book is suitable for students and researchers in statistics, computer science, data mining and machine learning. This book covers a much wider range of topics than a typical introductory text on mathematical statistics. It includes modern topics like nonparametric curve estimation, bootstrapping and classification, topics that are usually relegated to follow-up courses. The reader is assumed to know calculus and a little linear algebra. No previous knowledge of probability and statistics is required. The text can be used at the advanced undergraduate and graduate level.},
   author = {Larry Wasserman},
   doi = {10.1007/978-0-387-21736-9},
   isbn = {0387402721},
   issn = {1441923225},
   pages = {461},
   publisher = {Springer},
   title = {All of Statistics : A Concise Course in Statistical Inference},
   url = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20&amp;path=ASIN/0387402721},
   year = {2004},
}

@article{Quinlan1986,
   abstract = {The technology for building knowledge-based systems by inductive inference from examples has been demonstrated successfully in several practical applications. This paper summarizes an approach to synthesizing decision trees that has been used in a variety of systems, and it describes one such system, ID3, in detail. Results from recent studies show ways in which the methodology can be modified to deal with information that is noisy and/or incomplete. A reported shortcoming of the basic algorithm is discussed and two means of overcoming it are compared. The paper concludes with illustrations of current research directions.},
   author = {J. R. Quinlan},
   doi = {10.1007/BF00116251},
   issn = {1573-0565},
   issue = {1},
   journal = {Machine Learning 1986 1:1},
   keywords = {Artificial Intelligence,Control,Mechatronics,Natural Language Processing (NLP),Robotics,Simulation and Modeling},
   month = {3},
   pages = {81-106},
   publisher = {Springer},
   title = {Induction of decision trees},
   volume = {1},
   url = {https://link.springer.com/article/10.1007/BF00116251},
   year = {1986},
}

@inproceedings{10.1145/2808194.2809449,
author = {Sebastiani, Fabrizio},
title = {An Axiomatically Derived Measure for the Evaluation of Classification Algorithms},
year = {2015},
isbn = {9781450338332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2808194.2809449},
doi = {10.1145/2808194.2809449},
abstract = {We address the general problem of finding suitable evaluation measures for classification systems. To this end, we adopt an axiomatic approach, i.e., we discuss a number of properties ("axioms") that an evaluation measure for classification should arguably satisfy. We start our analysis by addressing binary classification. We show that F1, nowadays considered a standard measure for the evaluation of binary classification systems, does not comply with a number of them, and should thus be considered unsatisfactory. We go on to discuss an alternative, simple evaluation measure for binary classification, that we call K, and show that it instead satisfies all the previously proposed axioms. We thus argue that researchers and practitioners should replace F1 with K in their everyday binary classification practice. We carry on our analysis by showing that K can be smoothly extended to deal with single-label multi-class classification, cost-sensitive classification, and ordinal classification.},
booktitle = {Proceedings of the 2015 International Conference on The Theory of Information Retrieval},
pages = {11–20},
numpages = {10},
keywords = {classification, evaluation measures, ordinal classification.},
location = {Northampton, Massachusetts, USA},
series = {ICTIR '15}
}

%%% Introduccion
@Article{Hannun2019,
author={Hannun, Awni Y.
and Rajpurkar, Pranav
and Haghpanahi, Masoumeh
and Tison, Geoffrey H.
and Bourn, Codie
and Turakhia, Mintu P.
and Ng, Andrew Y.},
title={Cardiologist-level arrhythmia detection and classification in ambulatory electrocardiograms using a deep neural network},
journal={Nature Medicine},
year={2019},
month={Jan},
day={01},
volume={25},
number={1},
pages={65-69},
abstract={Computerized electrocardiogram (ECG) interpretation plays a critical role in the clinical ECG workflow1. Widely available digital ECG data and the algorithmic paradigm of deep learning2 present an opportunity to substantially improve the accuracy and scalability of automated ECG analysis. However, a comprehensive evaluation of an end-to-end deep learning approach for ECG analysis across a wide variety of diagnostic classes has not been previously reported. Here, we develop a deep neural network (DNN) to classify 12 rhythm classes using 91,232 single-lead ECGs from 53,549 patients who used a single-lead ambulatory ECG monitoring device. When validated against an independent test dataset annotated by a consensus committee of board-certified practicing cardiologists, the DNN achieved an average area under the receiver operating characteristic curve (ROC) of 0.97. The average F1 score, which is the harmonic mean of the positive predictive value and sensitivity, for the DNN (0.837) exceeded that of average cardiologists (0.780). With specificity fixed at the average specificity achieved by cardiologists, the sensitivity of the DNN exceeded the average cardiologist sensitivity for all rhythm classes. These findings demonstrate that an end-to-end deep learning approach can classify a broad range of distinct arrhythmias from single-lead ECGs with high diagnostic performance similar to that of cardiologists. If confirmed in clinical settings, this approach could reduce the rate of misdiagnosed computerized ECG interpretations and improve the efficiency of expert human ECG interpretation by accurately triaging or prioritizing the most urgent conditions.},
issn={1546-170X},
doi={10.1038/s41591-018-0268-3},
url={https://doi.org/10.1038/s41591-018-0268-3}
}


@Article{Esteva2017,
author={Esteva, Andre
and Kuprel, Brett
and Novoa, Roberto A.
and Ko, Justin
and Swetter, Susan M.
and Blau, Helen M.
and Thrun, Sebastian},
title={Dermatologist-level classification of skin cancer with deep neural networks},
journal={Nature},
year={2017},
month={Feb},
day={01},
volume={542},
number={7639},
pages={115-118},
abstract={An artificial intelligence trained to classify images of skin lesions as benign lesions or malignant skin cancers achieves the accuracy of board-certified dermatologists.},
issn={1476-4687},
doi={10.1038/nature21056},
url={https://doi.org/10.1038/nature21056}
}

@Article{Silver2016,
author={Silver, David
and Huang, Aja
and Maddison, Chris J.
and Guez, Arthur
and Sifre, Laurent
and van den Driessche, George
and Schrittwieser, Julian
and Antonoglou, Ioannis
and Panneershelvam, Veda
and Lanctot, Marc
and Dieleman, Sander
and Grewe, Dominik
and Nham, John
and Kalchbrenner, Nal
and Sutskever, Ilya
and Lillicrap, Timothy
and Leach, Madeleine
and Kavukcuoglu, Koray
and Graepel, Thore
and Hassabis, Demis},
title={Mastering the game of Go with deep neural networks and tree search},
journal={Nature},
year={2016},
month={Jan},
day={01},
volume={529},
number={7587},
pages={484-489},
abstract={The game of Go has long been viewed as the most challenging of classic games for artificial intelligence owing to its enormous search space and the difficulty of evaluating board positions and moves. Here we introduce a new approach to computer Go that uses `value networks' to evaluate board positions and `policy networks' to select moves. These deep neural networks are trained by a novel combination of supervised learning from human expert games, and reinforcement learning from games of self-play. Without any lookahead search, the neural networks play Go at the level of state-of-the-art Monte Carlo tree search programs that simulate thousands of random games of self-play. We also introduce a new search algorithm that combines Monte Carlo simulation with value and policy networks. Using this search algorithm, our program AlphaGo achieved a 99.8{\%} winning rate against other Go programs, and defeated the human European Go champion by 5 games to 0. This is the first time that a computer program has defeated a human professional player in the full-sized game of Go, a feat previously thought to be at least a decade away.},
issn={1476-4687},
doi={10.1038/nature16961},
url={https://doi.org/10.1038/nature16961}
}


@Article{Silver2017,
author={Silver, David
and Schrittwieser, Julian
and Simonyan, Karen
and Antonoglou, Ioannis
and Huang, Aja
and Guez, Arthur
and Hubert, Thomas
and Baker, Lucas
and Lai, Matthew
and Bolton, Adrian
and Chen, Yutian
and Lillicrap, Timothy
and Hui, Fan
and Sifre, Laurent
and van den Driessche, George
and Graepel, Thore
and Hassabis, Demis},
title={Mastering the game of Go without human knowledge},
journal={Nature},
year={2017},
month={Oct},
day={01},
volume={550},
number={7676},
pages={354-359},
abstract={A long-standing goal of artificial intelligence is an algorithm that learns, tabula rasa, superhuman proficiency in challenging domains. Recently, AlphaGo became the first program to defeat a world champion in the game of Go. The tree search in AlphaGo evaluated positions and selected moves using deep neural networks. These neural networks were trained by supervised learning from human expert moves, and by reinforcement learning from self-play. Here we introduce an algorithm based solely on reinforcement learning, without human data, guidance or domain knowledge beyond game rules. AlphaGo becomes its own teacher: a neural network is trained to predict AlphaGo's own move selections and also the winner of AlphaGo's games. This neural network improves the strength of the tree search, resulting in higher quality move selection and stronger self-play in the next iteration. Starting tabula rasa, our new program AlphaGo Zero achieved superhuman performance, winning 100--0 against the previously published, champion-defeating AlphaGo.},
issn={1476-4687},
doi={10.1038/nature24270},
url={https://doi.org/10.1038/nature24270}
}

@article{breiman2001statistical,
  title={Statistical modeling: The two cultures},
  author={Breiman, Leo},
  journal={Statistical science},
  volume={16},
  number={3},
  pages={199--231},
  year={2001},
  publisher={Institute of Mathematical Statistics},
  url={https://doi.org/10.1214/ss/1009213726}
}

@article{breiman2001randomforest,
  title={Random Forests},
  author={Breiman, Leo},
  journal={Machine Learning},
  volume={45},
  number={},
  pages={5-32},
  year={2001},
  publisher={Springer Nature},
  url={https://doi.org/10.1214/ss/1009213726}
}

@article{langley1986machine,
  title={Machine learning: An editorial},
  author={Langley, Pat},
  journal={Maching Learning},
  volume={1},
  pages={5--10},
  year={1986},
  url={https://doi.org/10.1023/A:1022687019898}
}

%%% Comparación de Algoritmos

@InProceedings{10.1007/978-3-031-33783-3_9,
author="Nava-Mu{\~{n}}oz, Sergio
        and Graff Guerrero, Mario
        and Escalante, Hugo Jair",
editor="Rodr{\'i}guez-Gonz{\'a}lez, Ansel Yoan
        and P{\'e}rez-Espinosa, Humberto
        and Mart{\'i}nez-Trinidad, Jos{\'e} Francisco
        and Carrasco-Ochoa, Jes{\'u}s Ariel
        and Olvera-L{\'o}pez, Jos{\'e} Arturo",
title="Comparison of Classifiers in Challenge Scheme",
booktitle="Pattern Recognition",
doi="10.1007/978-3-031-33783-3_9",
year="2023",
publisher="Springer Nature Switzerland",
address="Cham",
pages="89--98",
isbn="978-3-031-33783-3"
}

@article{Nava2024,
   abstract = {Collaborative competitions have gained popularity in the scientific and technological fields. These competitions involve defining tasks, selecting evaluation scores, and devising result verification methods. In the standard scenario, participants receive a training set and are expected to provide a solution for a held-out dataset kept by organizers. An essential challenge for organizers arises when comparing algorithms’ performance, assessing multiple participants, and ranking them. Statistical tools are often used for this purpose; however, traditional statistical methods often fail to capture decisive differences between systems’ performance. This manuscript describes an evaluation methodology for statistically analyzing competition results and competition. The methodology is designed to be universally applicable; however, it is illustrated using eight natural language competitions as case studies involving classification and regression problems. The proposed methodology offers several advantages, including off-the-shell comparisons with correction mechanisms and the inclusion of confidence intervals. Furthermore, we introduce metrics that allow organizers to assess the difficulty of competitions. Our analysis shows the potential usefulness of our methodology for effectively evaluating competition results.},
   author = {Sergio Nava-Muñoz and Mario Graff and Hugo Jair Escalante},
   doi = {10.1016/J.PATREC.2024.03.010},
   issn = {0167-8655},
   journal = {Pattern Recognition Letters},
   keywords = {Bootstrap,Challenges,Performance},
   month = {3},
   publisher = {North-Holland},
   title = {Analysis of systems’ performance in natural language processing competitions},
   year = {2024},
}

%%% Conjunto de Datos

@article{iris,
author = {Fisher, Ronald Aylmer},
title = {The use of multiple measurements in taxonomic problems},
journal = {Annals of Eugenics},
volume = {7},
number = {2},
pages = {179-188},
doi = {https://doi.org/10.1111/j.1469-1809.1936.tb02137.x},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1469-1809.1936.tb02137.x},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1469-1809.1936.tb02137.x},
abstract = {The articles published by the Annals of Eugenics (1925–1954) have been made available online as an historical archive intended for scholarly use. The work of eugenicists was often pervaded by prejudice against racial, ethnic and disabled groups. The online publication of this material for scholarly research purposes is not an endorsement of those views nor a promotion of eugenics in any way.},
year = {1936}
}

@inproceedings{breast-cancer-wisconsin,
  title={Nuclear feature extraction for breast tumor diagnosis},
  author={Street, William Nick and Wolberg, William H. and Mangasarian, Olvi L.},
  booktitle={Electronic imaging},
  year={1993},
  url={https://api.semanticscholar.org/CorpusID:14922543}
}

@ARTICLE{digits,
  author={Xu, L. and Krzyzak, A. and Suen, C.Y.},
  journal={IEEE Transactions on Systems, Man, and Cybernetics}, 
  title={Methods of combining multiple classifiers and their applications to handwriting recognition}, 
  year={1992},
  volume={22},
  number={3},
  pages={418-435},
  doi={10.1109/21.155943}}