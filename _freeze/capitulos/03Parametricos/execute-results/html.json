{
  "hash": "bf0bbc1ae9e2586ff13bb39cd3c1c5ca",
  "result": {
    "engine": "jupyter",
    "markdown": "# Métodos Paramétricos {#sec-metodos-parametricos}\n\nEl **objetivo** de la unidad es conocer las características de los modelos paramétricos y aplicar máxima verosimilitud para estimar los parámetros del modelo paramétrico en problemas de regresión y clasificación.\n\n## Paquetes usados {.unnumbered}\n\n::: {#ed28b76d .cell execution_count=1}\n``` {.python .cell-code}\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets import load_breast_cancer,\\\n                             load_diabetes\nfrom scipy.stats import norm, multivariate_normal\nfrom scipy.special import logsumexp\nfrom matplotlib import pylab as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n```\n:::\n\n\n\n\n::: {.content-visible when-format=\"html\"}\n\n---\n\n\n\n\n\n\n\n{{< video https://www.youtube.com/embed/Tlwecs3dUPw width=\"560\" height=\"315\" >}}\n\n\n\n\n\n\n\n\n\n\n\n\n\n---\n\n:::\n\n## Introducción {#sec-intro-03}\n\nExisten diferentes tipos de algoritmos que se puede utilizar para resolver problemas de aprendizaje supervisado y no supervisado. En particular, esta unidad se enfoca en presentar las técnicas que se pueden caracterizar como métodos paramétricos. \n\nLos métodos paramétricos se identifican por asumir que los datos provienen de una distribución de la cual se desconocen los parámetros y el procedimiento es encontrar los parámetros de la distribución que mejor modelen los datos. Una vez obtenidos los parámetros se cuenta con todos los elementos para utilizar el modelo y predecir la característica para la cual fue entrenada. \n\n## Metodología {#sec-metodologia-met-parametricos}\n\nHasta el momento se han presentado ejemplos de los pasos 4 y 5 de la metodología general (ver @sec-metodologia-general); esto fue en la @sec-prediccion-normal y en la @sec-error-clasificacion. Esta sección complementa los ejemplos anteriores al utilizar todos pasos de la metodología general de aprendizaje supervisado (ver @sec-metodologia-general). En particular se enfoca al paso 3 que corresponde al diseño del algoritmo $f$ que modela el fenómeno de interés utilizando los datos $\\mathcal T \\subset \\mathcal D.$\n\nEl algoritmo $f$ corresponde a asumir que los datos $\\mathcal D$ provienen de \nuna distribución $F$ la cual tiene una serie de parámetros $\\theta$ que \nson identificados con $\\mathcal T.$\n\n## Estimación de Parámetros {#sec-estimacion-parametros-gnal}\n\nSe inicia la descripción de métodos paramétricos presentando el procedimiento general para estimar los parámetros de una distribución. Se cuenta con un conjunto $\\mathcal D$ donde los elementos $x \\in \\mathcal D$ son $x \\in \\mathbb R^d$. Los elementos $x \\in \\mathcal D$ tienen un distribución $F$, i.e., $x \\sim F$, son independientes y $F$ está definida por la función de densidad de probabilidad $f_{\\theta}$, que a su vez está definida por $\\theta$ parámetros. Utilizando $\\mathcal D$ el objetivo es identificar los parámetros $\\theta$ que hacen observar a $\\mathcal D$ lo más probable. \n\n### Verosimilitud {#sec-verosimilitud}\n\nUna solución para maximizar el observar $\\mathcal D$ es maximizando la verosimilitud. La verosimilitud es la función distribución conjunta de los elementos en $\\mathcal D$, i.e., $f_\\theta(x_1, x_2, \\ldots, x_N).$ Considerando que la muestras son independientes entonces $f_\\theta(x_1, x_2, \\ldots, x_N) = \\prod_{x \\in \\mathcal D} f_\\theta (x).$ La función de verosimilitud considera la ecuación anterior como una función de los parámetros $\\theta,$ es decir,\n\n$$\n\\mathcal L(\\theta) = \\prod_{x \\in \\mathcal D} f_\\theta (x),\n$$\n\nsiendo el logaritmo de la verosimilitud \n\n$$\n\\ell(\\theta) = \\log \\mathcal L(\\theta) = \\sum_{x \\in \\mathcal D} \\log f_\\theta (x).\n$$\n\n### Distribución de Bernoulli {#sec-distribucción-de-bernoulli}\n\nLa verosimilitud se ejemplifica con la identificación del parámetro $p$ de una distribución Bernoulli. Una distribución Bernoulli modela dos estados, por un lado se tiene la clase negativa identificada por $0$; identificando la clase positiva como $1$. Entonces, la probabilidad de observar $1$ es $\\mathbb P(X=1) = p$ y $\\mathbb P(X=0) = 1 - p$. Estas ecuaciones se pueden combinar para definir $f_\\theta(x) = p^x (1 - p)^{1-x}.$\n\nUtilizando el logaritmo de la verosimilitud se tiene:\n\n$$\n\\ell(p) = \\sum_{i=1}^N \\log p^{x_i} (1 - p)^{1-x_i} = \\sum_{i=1}^N x_i \\log p + (1-x_i) \\log (1 - p).\n$$\n\nRecordando que el máximo de $\\ell(\\mathcal p)$ se obtiene cuando $\\frac{d}{dp} \\ell(\\mathcal p) = 0$, entonces estimar $p$ corresponde a resolver lo siguiente:\n\n$$\n\\begin{split}\n\\frac{d}{dp} \\ell(\\mathcal p) &= 0 \\\\\n\\frac{d}{dp} [ \\sum_{i=1}^N x_i \\log p + (1-x_i) \\log (1 - p)] &= 0 \\\\ \n\\frac{d}{d p} [ \\sum_{i=1}^N x_i \\log p + \\log (1 - p) (N - \\sum_{i=1}^N x_i) ] &= 0\\\\\n\\sum_{i=1}^N x_i \\frac{d}{d p} \\log \\mathcal p + (N - \\sum_{i=1}^N x_i) \\frac{d}{d p} \\log (1 - \\mathcal p) &= 0\\\\ \n\\sum_{i=1}^N x_i \\frac{1}{p} + (N - \\sum_{i=1}^N x_i) \\frac{-1}{(1 - p)} &= 0\\\\ \n\\end{split}\n$$\n\nRealizando algunas operaciones algebraicas se obtiene:\n\n$$\n\\hat p = \\frac{1}{N}\\sum_{i=1}^N x_i.\n$$\n\n### Ejemplo: Distribución Gausiana {#sec-estimacion-distribucion-gausiana}\n\nEsta sección sigue un camino práctico, presentando el código para estimar los parámetros de una distribución Gausiana donde se conocen todos los parámetros. La distribución se usa para generar 1000 muestras y después de esta población se estiman los parámetros; de estas manera se tienen todos los elementos para comparar los parámetros reales $\\theta$ de los parámetros estimados $\\hat \\theta.$\n\nLa distribución que se usará se utilizó para generar un problema sintético (ver @sec-tres-normales) de tres clases. Los parámetros de la distribución son: $\\mathbf \\mu = [5, 5]^\\intercal$ y  $\\Sigma = \\begin{pmatrix} 4 & 0 \\\\ 0 & 2 \\\\ \\end{pmatrix}.$ La siguiente instrucción se puede utilizar para generar 1000 muestras de esa distribución. \n\n::: {#30e40263 .cell execution_count=3}\n``` {.python .cell-code}\nD = multivariate_normal(mean=[5, 5], \n                        cov=[[4, 0], \n                             [0, 2]]).rvs(size=1000)\n```\n:::\n\n\nLa media estimada de los datos en `D` se calcula usando la función `np.mean` de la siguiente manera\n\n::: {#1e559f84 .cell execution_count=4}\n``` {.python .cell-code}\nmu = np.mean(D, axis=0)\n```\n:::\n\n\n::: {#ae019f8f .cell execution_count=5}\n\n::: {.cell-output .cell-output-display .cell-output-markdown execution_count=5}\ndonde el eje de operación es el primero que corresponde al índice $0.$ La media estimada es: $\\hat \\mu = [5.0411, 5.0338]^\\intercal$ con un [error estándar](ver @sec-error-estandar-media) (`se`) de $[0.0644, 0.0467]^\\intercal$ que se calcula con el siguiente código.\n:::\n:::\n\n\n::: {#31ea596c .cell execution_count=6}\n``` {.python .cell-code}\nse = np.std(D, axis=0) / np.sqrt(1000)\n```\n:::\n\n\nHasta el momento se ha estimado $\\mu$, falta por estimar $\\Sigma$, que se puede realizar con la siguiente instrucción\n\n::: {#aca86415 .cell execution_count=7}\n``` {.python .cell-code}\ncov = np.cov(D, rowvar=False)\n```\n:::\n\n\n::: {#387bf1e6 .cell execution_count=8}\n\n::: {.cell-output .cell-output-display .cell-output-markdown execution_count=8}\ndonde el parámetro `rowvar` indica la forma en que están proporcionados los datos. La estimación da los siguientes valores $\\hat \\Sigma = \\begin{pmatrix} 4.1524&0.0465 \\\\ 0.0465&2.1854 \\\\ \\end{pmatrix};$ se puede observar que son similares al parámetro con que se simularon los datos.\n:::\n:::\n\n\nSiguiendo con la inercia de presentar el error estándar de cada estimación, en las siguientes instrucciones se presenta el error estándar de $\\hat \\Sigma$, el cual se calcula utilizando la técnica de bootstrap (ver @sec-bootstrap) implementada en el siguiente código. \n\n::: {#04f96548 .cell execution_count=9}\n``` {.python .cell-code}\nS = np.random.randint(D.shape[0],\n                      size=(500, D.shape[0]))\nB = [np.cov(D[s], rowvar=False) for s in S]\nse = np.std(B, axis=0)\n```\n:::\n\n\n::: {#dafa09f2 .cell execution_count=10}\n\n::: {.cell-output .cell-output-display .cell-output-markdown execution_count=10}\nSe puede observar que la función `np.cov` se ejecuta utilizando la muestra indicada en la variable `s`. El error estándar (`se`) de $\\hat \\Sigma$ corresponde a $\\begin{pmatrix} 0.1765&0.0910 \\\\ 0.0910&0.0955 \\\\ \\end{pmatrix}.$ Se observa que los elementos fuera de la diagonal tienen un error estándar tal que el cero se encuentra en el intervalo $\\hat \\Sigma \\pm se;$ lo cual indica que el cero es un valor factible. Lo anterior se puede verificar tomando en cuenta que se conoce $\\Sigma$ y que el parámetro real es $0$ para aquellos elementos fuera de la diagonal.\n:::\n:::\n\n\n## Metodología de Clasificación\n\nHabiendo descrito el proceso para estimar los parámetros de una distribución, por un lado se presentó de manera teórica con la distribución Bernoulli (ver @sec-distribucción-de-bernoulli) y de manera práctica con una distribución Gausiana (ver @sec-estimacion-distribucion-gausiana), se está en la posición de usar todos estos elementos para presentar el proceso completo de clasificación. La metodología general de aprendizaje supervisado (ver @sec-metodologia-general) está definida por cinco pasos, estos pasos se especializan para el problema de clasificación y regresión, utilizando modelos paramétricos, de la siguiente manera. \n\n1. Todo empieza con un conjunto de datos $\\mathcal D$ que tiene la información del fenómeno de interés.\n2. Se selecciona el conjunto $\\mathcal T \\subset \\mathcal D,$ el procedimiento se describe en la @sec-conjunto-entre-prueba. \n3. Se diseña un algoritmo, $f$, el cual se basa en un modelo (ver @sec-model-clasificacion) y la estimación de sus parámetros (ver @sec-estimacion-parametros) utilizando $\\mathcal T.$\n4. En la @sec-prediccion se describe el uso de $f$ para predecir.\n5. La @sec-rendimiento muestra el procedimiento para medir el rendimiento utilizando un conjunto de prueba (ver @sec-conjunto-entre-prueba).\n\nLa metodología de clasificación se ilustra utilizando el problema sintético (ver @sec-tres-normales) de tres clases que se presentó en el @sec-teoria-decision-bayesianas. \n\n\n::: {.callout-note}\n### Problema sintético  \n\n::: {#8c3a456b .cell execution_count=11}\n``` {.python .cell-code code-fold=\"true\"}\nseed = 0\np1 = multivariate_normal(mean=[5, 5],\n                         cov=[[4, 0], [0, 2]],\n                         seed=seed)\np2 = multivariate_normal(mean=[1.5, -1.5],\n                         cov=[[2, 1], [1, 3]],\n                         seed=seed)\np3 = multivariate_normal(mean=[12.5, -3.5], \n                         cov=[[2, 3], [3, 7]],\n                         seed=seed)\nX_1 = p1.rvs(size=1000)\nX_2 = p2.rvs(size=1000)\nX_3 = p3.rvs(size=1000)                         \n```\n:::\n\n\n:::\n\nEspecíficamente, las entradas que definían a cada clase están en la variables `X_1`, `X_2` y `X_3`. Entonces las clases se pueden colocar en la variable `y` tal como se indica a continuación. \n\n::: {#90fac46a .cell execution_count=12}\n``` {.python .cell-code}\nX = np.concatenate((X_1, X_2, X_3))\ny = np.array([1] * 1000 + [2] * 1000 + [3] * 1000)\n```\n:::\n\n\nLas variables `X` y `y` contiene la información del conjunto $\\mathcal D = (\\mathcal X, \\mathcal Y)$ donde cada renglón de `X` es una realización de la variable aleatoria $\\mathcal X$ y equivalentemente cada elemento en `y` es una realización de $\\mathcal Y.$\n\n## Conjunto de Entrenamiento y Prueba {#sec-conjunto-entre-prueba}\n\nEn la @sec-estimacion-distribucion-gausiana se había utilizado a $\\mathcal D$ en el procedimiento de maximizar la verosimilitud, esto porque el objetivo en ese procedimiento era estimar los parámetros de la distribución. Pero el objetivo en aprendizaje supervisado es diseñar un algoritmo (función en este caso) que modele la relación entre $\\mathcal X$ y $\\mathcal Y$. Para conocer esto es necesario medir el rendimiento del algoritmo en instancias que no han sido vistas en el entrenamiento.\n\nEn consecuencia, se requieren contar con datos para medir el rendimiento, a este conjunto de datos se le conoce como el conjunto de prueba, $\\mathcal G$. $\\mathcal G$ se crea a partir de $\\mathcal D$ de tal manera que $\\mathcal G \\cap \\mathcal T = \\emptyset$ y $\\mathcal D =  \\mathcal G \\cup \\mathcal T.$ La siguiente instrucción se puede utilizar para dividir la generación de estos conjuntos a partir de $\\mathcal D.$\n\n::: {#781854b4 .cell execution_count=13}\n``` {.python .cell-code}\nT, G, y_t, y_g = train_test_split(X, y,\n                                  test_size=0.2,\n                                  random_state=seed)\n```\n:::\n\n\nEl parámetro `test_size` indica la proporción del tamaño de conjunto $\\mathcal G$ en relación con el conjunto $\\mathcal D.$\n\n## Clasificador {#sec-model-clasificacion}\n\nEl inicio de métodos paramétricos es el Teorema de Bayes (@eq-teorema-bayes) $\\mathbb P(\\mathcal Y \\mid \\mathcal X) = \\frac{ \\mathbb P(\\mathcal X \\mid \\mathcal Y) \\mathbb P(\\mathcal Y)}{\\mathbb P(\\mathcal X)}$ donde se usa la verosimilitud $\\mathbb P(\\mathcal X \\mid \\mathcal Y)$ y el prior $\\mathbb P(\\mathcal Y)$ para definir la probabilidad a posteriori $\\mathbb P(\\mathcal Y \\mid \\mathcal X)$. En métodos paramétricos se asume que se puede modelar la verosimilitud con una distribución particular, que por lo generar es una distribución Gausiana multivariada. Es decir, la variable aleatoria $\\mathcal X$ dado $\\mathcal Y$ (i.e., $\\mathcal X_{\\mid \\mathcal Y}$) es $\\mathcal X_{\\mid \\mathcal Y} \\sim \\mathcal N(\\mu_{\\mathcal Y}, \\Sigma_{\\mathcal Y}),$ donde se observa que los parámetros de la distribución Gausiana dependen de la variable aleatoria $\\mathcal Y$ y estos pueden ser identificados cuando $\\mathcal Y$ tiene un valor específico. \n\n### Estimación de Parámetros {#sec-estimacion-parametros}\n\nDado que por definición del problema (ver @sec-tres-normales) se conoce que la verosimilitud para cada clase proviene de una Gausiana, i.e., $\\mathcal X_{\\mid \\mathcal Y} \\sim \\mathcal N(\\mu_{\\mathcal Y}, \\Sigma_{\\mathcal Y}),$ en esta sección se estimarán los parámetros utilizando este conocimiento. \n\nEl primer paso en la estimación de parámetros es calcular el prior $\\mathbb P(\\mathcal Y)$, el cual corresponde a clasificar el evento sin observar el valor de $\\mathcal X.$ Esto se puede modelar mediante una distribución Categórica con parámetros $p_i$ donde $\\sum_i^K p_i = 1$. Estos parámetros se pueden estimar utilizando la función `np.unique` de la siguiente manera\n\n::: {#fcf9908e .cell execution_count=14}\n``` {.python .cell-code}\nlabels, counts = np.unique(y_t, return_counts=True)\nprior = counts / counts.sum()\n```\n:::\n\n\nLa variable `prior` contiene en el primer elemento $\\mathbb P(\\mathcal Y=1) = 0.3179,$ en el segundo $\\mathbb P(\\mathcal Y=2) = 0.3387$ y en el tercero $\\mathbb P(\\mathcal Y=3) = 0.3433$ que es aproximadamente $\\frac{1}{3}$ el cual es el valor real del prior. \n\nSiguiendo los pasos en estimación de parámetros de una Gausiana (@sec-estimacion-distribucion-gausiana) se pueden estimar los parámetros para cada Gausiana dada la clase. Es decir, se tiene que estimar los parámetros $\\mu$ y $\\Sigma$ para la clase $1$, $2$ y $3.$ El algoritmo de clasificación que estima $\\mu$ y $\\Sigma$ para cada clase se le conoce como **Analizador Discriminante Cuadrático** implementando en la clase `QuadraticDiscriminantAnalysis`.\n\nUna implementación directa para la estimación de los parámetros se puede realizar iterando por las etiquetas contenidas en la variable `labels` y seleccionando los datos en `T` que corresponden a la clase analizada, ver el uso de la variable `mask` en el slice de la línea 4 y 5. Después se inicializa una instancia de la clase `multivariate_normal` para ser utilizada en el cómputo de la función de densidad de probabilidad. El paso final es guardar las instancias de las distribuciones en la lista `likelihood`.\n\n::: {#2f1d8bc9 .cell execution_count=15}\n``` {.python .cell-code}\nlikelihood = []\nfor k in labels:\n    mask = y_t == k\n    mu = np.mean(T[mask], axis=0)\n    cov = np.cov(T[mask], rowvar=False)\n    likelihood_k = multivariate_normal(mean=mu, cov=cov)\n    likelihood.append(likelihood_k)\n```\n:::\n\n\n::: {#1a1b2cce .cell execution_count=16}\n\n::: {.cell-output .cell-output-display .cell-output-markdown execution_count=16}\nLos valores estimados para la media, en cada clase son: $\\hat \\mu_1 = [5.0267, 4.9626]^\\intercal,$ $\\hat \\mu_2 = [1.5687, -1.4642]^\\intercal$ y $\\hat \\mu_3 = [12.5188, -3.4715]^\\intercal$. Para las matrices de covarianza, los valores estimados corresponden a $\\hat \\Sigma_1 = \\begin{pmatrix} 3.8108 & -0.0363\\\\-0.0363 & 1.9319 \\\\ \\end{pmatrix},$ $\\hat \\Sigma_2 = \\begin{pmatrix} 1.8221 & 0.8862\\\\0.8862 & 2.8153 \\\\ \\end{pmatrix}$ y $\\hat \\Sigma_3 = \\begin{pmatrix} 1.9043 & 2.8677\\\\2.8677 & 6.7392 \\\\ \\end{pmatrix}.$\n:::\n:::\n\n\nEstas estimaciones se pueden comparar con los parámetros reales (@sec-tres-normales). También se puede calcular su error estándar para identificar si el parámetro real, $\\theta$, se encuentra en el intervalo definido por $\\hat \\theta - 2\\hat{se} \\leq \\hat \\theta \\leq \\hat \\theta + 2 \\hat{se}$ que corresponde aproximadamente al 95% de confianza asumiendo que la distribución de la estimación del parámetro es Gausiana.\n\n\n::: {.callout-note}\n\nEl código anterior tiene el fin de explicar el procedimiento para estimar los parámetros, la clase `QuadraticDiscriminantAnalysis` implementa diferentes métodos de estimación y se puede utilizar con el siguiente código. \n\n::: {#61c6ea50 .cell execution_count=17}\n``` {.python .cell-code}\nqda = QuadraticDiscriminantAnalysis(store_covariance=True).fit(T, y_t)\n```\n:::\n\n\nLos parámetros $\\mu$ se encuentran en el siguiente atributo. Se puede observar que los valores estimados por el método explicado y el implementado en QDA es el mismo. \n\n::: {#640b3073 .cell execution_count=18}\n``` {.python .cell-code}\nqda.means_\n```\n\n::: {.cell-output .cell-output-display execution_count=18}\n```\narray([[ 5.0267,  4.9626],\n       [ 1.5687, -1.4642],\n       [12.5188, -3.4715]])\n```\n:::\n:::\n\n\nLos parámetros estimados para $\\Sigma_1$ se pueden obtener en el siguiente atributo\n\n::: {#4098b522 .cell execution_count=19}\n``` {.python .cell-code}\nqda.covariance_[0]\n```\n\n::: {.cell-output .cell-output-display execution_count=19}\n```\narray([[ 3.8108, -0.0363],\n       [-0.0363,  1.9319]])\n```\n:::\n:::\n\n\nSe observa que los valores son equivalentes entre los dos procedimientos, es importante mencionar que estos parámetros solamente están disponibles si la clase se inicializa con el parámetro `store_covariance` en verdadero.\n:::\n\n### Predicción {#sec-prediccion}\n\nUna vez que se tiene la función que modela los datos, se está en condiciones de utilizarla para predecir (ver @sec-prediccion-normal) nuevos datos. \n\nEn esta ocasión se organiza el procedimiento de predicción en diferentes funciones, la primera función recibe los datos a predecir `X` y los componentes del modelo, que son la verosimilitud (`likelihood`) y el `prior`. La función calcula $\\mathbb P(\\mathcal Y=y \\mid \\mathcal X=x)$ que es la probabilidad de cada clase dada la entrada $x$. Se puede observar en la primera línea que se usa la función de densidad de probabilidad (`pdf`) para cada clase y esta se multiplica por el `prior` y en la tercera línea se calcula la evidencia. Finalmente, se regresa el a posteriori.  \n\n::: {#bebcce5b .cell execution_count=20}\n``` {.python .cell-code}\ndef predict_prob(X, likelihood, prior):\n    likelihood = [m.pdf(X) for m in likelihood]\n    posterior = np.vstack(likelihood).T * prior\n    evidence = posterior.sum(axis=1)\n    return posterior / np.atleast_2d(evidence).T\n```\n:::\n\n\nLa función `predict_proba` se utiliza como base para predecir la clase, para la cual se requiere el mapa entre índices y clases que se encuentra en la variable `labels`. Se observa que se llama a la función `predict_proba` y después se calcula el argumento que tiene la máxima probabilidad regresando la etiqueta asociada. \n\n::: {#bae776e4 .cell execution_count=21}\n``` {.python .cell-code}\ndef predict(X, likelihood, prior, labels):\n    _ = predict_prob(X, likelihood, prior)\n    return labels[np.argmax(_, axis=1)]\n```\n:::\n\n\n::: {.callout-note}\n\nLa predicción en la clase `QuadraticDiscriminantAnalysis` se puede realizar invocando al siguiente método tal y como se muestra en la siguiente linea. \n\n::: {#10c75a54 .cell execution_count=22}\n``` {.python .cell-code}\nqda_hy = qda.predict(G)\n```\n:::\n\n\nLa probabilidad se puede obtener utilizando el método `predict_proba.` \n\n::: {#0acc0404 .cell execution_count=23}\n``` {.python .cell-code}\nqda_prob = qda.predict_proba(G)\n```\n:::\n\n\n:::\n\n\n### Rendimiento {#sec-rendimiento}\n\nEl rendimiento del algoritmo se mide en el conjunto de prueba `G`, utilizando como medida el error de clasificación (@sec-error-clasificacion). El primer paso es predecir las clases de los elementos en `G`, utilizando la función `predict` que fue diseñada anteriormente. Después se mide el error, con la instrucción de la segunda línea.  \n\n::: {#5dbb6669 .cell execution_count=24}\n``` {.python .cell-code}\nhy = predict(G, likelihood, prior, labels)\nerror = (y_g != hy).mean()\n```\n:::\n\n\nEl error que tiene el algoritmo en el conjunto de prueba es $0.0117$. \n\n::: {.callout-note}\nEl error utilizado `qda_hy` corresponde a $0.0117.$\n:::\n\n::: {.callout-tip collapse=\"true\"}\n#### Actividad\n\nUtilizando la probabilidad en el conjunto de prueba, que se tiene en la variable `qda_prob`, calcular la variación del número de elementos que son asociados a la acción nula cuando se varía el nivel de riesgo (ver @sec-seleccion-accion-nula), incluir en la figura o en una figura adicional, la dinámica del error en el conjunto de prueba para los elementos válidos. La @fig-actividad-riesgo-nulo-error muestra el resultado de este proceso. Se observa como van disminuyendo el número de elementos asociados a la acción nula cuando el riesgo se incrementa y al mismo tiempo como el error aumenta.\n\n::: {#cell-fig-actividad-riesgo-nulo-error .cell execution_count=25}\n\n::: {.cell-output .cell-output-display}\n![Variación del número de elementos que seleccionan la acción nula y el error en el conjunto de prueba respecto al riesgo](03Parametricos_files/figure-html/fig-actividad-riesgo-nulo-error-output-1.png){#fig-actividad-riesgo-nulo-error width=658 height=429}\n:::\n:::\n\n\n:::\n\n\nPara calcular el error estándar se utiliza el siguiente código \n\n::: {#c60d50f7 .cell execution_count=26}\n``` {.python .cell-code}\nse_formula = np.sqrt(error * (1 - error) / y_g.shape[0])\n```\n:::\n\n\ndando un valor de $0.0044.$\n\n\n\n::: {.callout-tip collapse=\"true\"}\n#### Actividad\n\nGenerar la distribución del error utilizando el método de Bootstrap (ver @sec-bootstrap), tal y como se muestra en la @fig-actividad-distribucion.\n\n::: {#cell-fig-actividad-distribucion .cell execution_count=27}\n\n::: {.cell-output .cell-output-display}\n![Distribución del error](03Parametricos_files/figure-html/fig-actividad-distribucion-output-1.png){#fig-actividad-distribucion width=471 height=470}\n:::\n:::\n\n\nEl error estándar calculado con los datos mostrados en la figura anterior es $0.0045$\n:::\n\n\n## Clasificador Bayesiano Ingenuo {#sec-cl-bayesiano-ingenuo}\n\nUno de los clasificadores mas utilizados, sencillo de implementar y competitivo, es el clasificador Bayesiano Ingenuo. En la @sec-model-clasificacion se asumió que la variable aleatoria $\\mathcal X = (\\mathcal X_1, \\mathcal X_2, \\ldots, \\mathcal X_d)$ dado $\\mathcal Y$ ($\\mathcal X_{\\mid \\mathcal Y}$) es $\\mathcal X_{\\mid \\mathcal Y} \\sim \\mathcal N(\\mu_{\\mathcal Y}, \\Sigma_{\\mathcal Y}),$ donde $\\mu_{\\mathcal Y} \\in \\mathbb R^d$, $\\Sigma_{\\mathcal Y} \\in \\mathbb R^{d \\times d}$ y $f(\\mathcal X_1, \\mathcal X_2, \\ldots, \\mathcal X_d)$ es la función de densidad de probabilidad conjunta.\n\nEn el clasificador Bayesiano Ingenuo se asume que las variables $\\mathcal X_i$ y $\\mathcal X_j$ para $i \\neq j$ son independientes, esto trae como consecuencia que $f(\\mathcal X_1, \\mathcal X_2, \\ldots, \\mathcal X_d) = \\prod_i^d f(\\mathcal X_i).$ Esto quiere decir que cada variable está definida como una Gausina donde se tiene que identificar $\\mu$ y $\\sigma^2.$\n\nLa estimación de los parámetros de estas distribuciones se puede realizar utilizando un código similar siendo la única diferencia que en se calcula $\\sigma^2$ de cada variable en lugar de la covarianza $\\Sigma$, esto se puede observar en la quinta línea donde se usa la función `np.var` en el primer eje. El resto del código es equivalente al usado en la @sec-estimacion-parametros.\n\n::: {#d59d15e5 .cell execution_count=28}\n``` {.python .cell-code}\nlikelihood = []\nfor k in labels:\n    mask = y_t == k\n    mu = np.mean(T[mask], axis=0)\n    var = np.var(T[mask], axis=0, ddof=1)\n    likelihood_k = multivariate_normal(mean=mu, cov=var)\n    likelihood.append(likelihood_k)\n```\n:::\n\n\n::: {#22750a4f .cell execution_count=29}\n\n::: {.cell-output .cell-output-display .cell-output-markdown execution_count=29}\nLos parámetros estimados en la versión ingenua son equivalentes con respecto a las medias, i.e., $\\hat \\mu_1 = [5.0267, 4.9626]^\\intercal$, $\\hat \\mu_2 = [1.5687, -1.4642] ^\\intercal$ y $\\hat \\mu_3 = [12.5188, -3.4715]^\\intercal$. La diferencia se puede observar en las varianzas, que a continuación se muestran como matrices de covarianza para resaltar la diferencia, i.e., $\\hat \\Sigma_1 = \\begin{pmatrix} 3.8108 & 0.0000\\\\0.0000 & 1.9319 \\\\ \\end{pmatrix}$, $\\hat \\Sigma_2 = \\begin{pmatrix} 1.8221 & 0.0000\\\\0.0000 & 2.8153 \\\\ \\end{pmatrix}$ y $\\hat \\Sigma_3 = \\begin{pmatrix} 1.9043 & 0.0000\\\\0.0000 & 6.7392 \\\\ \\end{pmatrix}$ se observa como los elementos fuera de la diagonal son ceros, lo cual indica la independencia entra las variables de entrada.\n:::\n:::\n\n\nFinalmente, el código para predecir se utiliza el código descrito en la @sec-prediccion dado que el modelo está dado en las variables `likelihood` y `prior`. \n\n::: {#bd876cb1 .cell execution_count=30}\n\n::: {.cell-output .cell-output-display .cell-output-markdown execution_count=30}\nEl `error` del clasificador Bayesiano Ingenuo, en el conjunto de prueba, es de $0.01$ y su error estándar (`se_formula`) es $0.0041.$\n:::\n:::\n\n\n::: {.callout-note}\n\nEl código anterior tiene la finalidad de explicar la estimación de parámetros del Clasificador Bayesiano Ingenuo. Este procedimiento se encuentra en la clase `GaussianNB`, en ese paquete se pueden encontrar implementaciones con otras distribuciones. \n\nEl siguiente código muestra su uso. \n\n::: {#9366bac9 .cell execution_count=31}\n``` {.python .cell-code}\nnaive = GaussianNB().fit(T, y_t)\n```\n:::\n\n\nLos parámetros $\\mu$ se encuentran se pueden consultar con la siguiente instrucción\n\n::: {#23bfd9b3 .cell execution_count=32}\n``` {.python .cell-code}\nnaive.theta_\n```\n\n::: {.cell-output .cell-output-display execution_count=32}\n```\narray([[ 5.0267,  4.9626],\n       [ 1.5687, -1.4642],\n       [12.5188, -3.4715]])\n```\n:::\n:::\n\n\ny $\\sigma^2$ en \n\n::: {#ad439c6e .cell execution_count=33}\n``` {.python .cell-code}\nnaive.var_\n```\n\n::: {.cell-output .cell-output-display execution_count=33}\n```\narray([[3.8058, 1.9293],\n       [1.8199, 2.8119],\n       [1.902 , 6.731 ]])\n```\n:::\n:::\n\n\n:::\n\n\n## Ejemplo: Breast Cancer Wisconsin {#sec-ejemplo-breast-cancer-wisconsin}\n\nEsta sección ilustra el uso del clasificador Bayesiano al generar dos modelos (Clasificador Bayesiano (mejor conocido como el algoritmo de Análisis Discriminante Cuadrático) y Bayesiano Ingenuo) del conjunto de datos de *Breast Cancer Wisconsin.* Estos datos se pueden obtener utilizando la función `load_breast_cancer` tal y como se muestra a continuación.\n\n::: {#87160b98 .cell execution_count=34}\n``` {.python .cell-code}\nX, y = load_breast_cancer(return_X_y=True)\n```\n:::\n\n\nEl primer paso es contar con los conjuntos de [entrenamiento y prueba](/AprendizajeComputacional/capitulos/03Parametricos/#conjunto-de-entrenamiento-y-prueba) para poder realizar de manera completa la evaluación del proceso de clasificación. Esto se realiza ejecutando la siguiente instrucción.\n\n::: {#dbc52157 .cell execution_count=35}\n``` {.python .cell-code}\nT, G, y_t, y_g = train_test_split(X, y, test_size=0.2,\n                                  random_state=seed)\n```\n:::\n\n\n### Entrenamiento\n\nLos dos modelos que se utilizarán será el clasificador de Análisis Discriminante Cuadrático y Bayesiano Ingenuo, utilizando las clases `QuadraticDiscriminantAnalysis` y `GaussianNB`. Las siguientes dos instrucciones inicializan estos dos clasificadores. \n\n::: {#d5ab28c1 .cell execution_count=36}\n``` {.python .cell-code}\nqda = QuadraticDiscriminantAnalysis().fit(T, y_t)\nnaive = GaussianNB().fit(T, y_t)\n```\n:::\n\n\n### Predicción\n\nHabiendo definido los dos clasificadores, las predicciones del conjunto de prueba se realiza de la siguiente manera. \n\n::: {#b2975fa5 .cell execution_count=37}\n``` {.python .cell-code}\nhy_qda = qda.predict(G)\nhy_naive = naive.predict(G)\n```\n:::\n\n\n### Rendimiento {#sec-gaussina-perf-breast_cancer}\n\nEl rendimiento de ambos clasificadores se calcula de la siguiente manera \n\n::: {#1b8fd1da .cell execution_count=38}\n``` {.python .cell-code}\nerror_qda = (y_g != hy_qda).mean()\nerror_naive = (y_g != hy_naive).mean()\n```\n:::\n\n\nEl clasificador Bayesiano Gausiano tiene un error de $0.0439$ y el error de Bayesiano Ingenuo es $0.0702.$ Se ha visto que el error es una variable aleatoria, entonces la pregunta es saber si esta diferencia en rendimiento es significativa o es una diferencia que proviene de la aleatoriedad de los datos. \n\n## Diferencias en Rendimiento \n\nUna manera de ver si existe una diferencia en rendimiento es calcular la diferencia entre los dos errores de clasificación, esto es \n\n::: {#3dde08c4 .cell execution_count=39}\n``` {.python .cell-code}\nnaive = (y_g != hy_naive).mean()\ncompleto = (y_g != hy_qda).mean()\nif naive > completo:\n    diff = naive - completo\nelse:\n    diff = completo - naive\n```\n:::\n\n\nque tiene un valor de $0.0263$. De la misma manera que se ha utilizado la técnica de bootstrap (@sec-bootstrap) para calcular el error estándar de la media, se puede usar para estimar el error estándar de la diferencia en rendimiento. El siguiente código muestra el procedimiento para estimar este error estándar. \n\n::: {#b4bf33e9 .cell execution_count=40}\n``` {.python .cell-code}\nS = np.random.randint(y_g.shape[0],\n                      size=(500, y_g.shape[0]))\nif naive > completo:\n    diff_f = lambda s: (y_g[s] != hy_naive[s]).mean() -\\\n                       (y_g[s] != hy_qda[s]).mean()\nelse:\n    diff_f = lambda s: (y_g[s] != hy_qda[s]).mean() -\\\n                       (y_g[s] != hy_naive[s]).mean()\nB = [diff_f(s) for s in S]\nse = np.std(B, axis=0)\n```\n:::\n\n\nEl error estándar de la diferencia de rendimiento es de $0.0190$, una procedimiento simple para saber si la diferencia observada es significativa, es dividir la diferencia entre su error estándar dando un valor de $1.3821$. En el caso que el valor absoluto fuera igual o superior a 2 se sabría que la diferencia es significativa con una confianza de al menos 95%, esto asumiendo que la diferencia se comporta como una distribución Gausiana. \n\nEl histograma de los datos que se tienen en la variable `B` se observa en la @fig-diff-cl-bayesianos. Se puede ver que la forma del histograma asemeja una distribución Gausiana y que el cero esta en el cuerpo de la Gausiana, tal y como lo confirmó el cociente que se calculado.\n\n::: {#cell-fig-diff-cl-bayesianos .cell execution_count=41}\n``` {.python .cell-code code-fold=\"true\"}\nsns.set_style('whitegrid')\nfig = sns.displot(B, kde=True)\n```\n\n::: {.cell-output .cell-output-display}\n![Diferencia entre Clasificadores Bayesianos](03Parametricos_files/figure-html/fig-diff-cl-bayesianos-output-1.png){#fig-diff-cl-bayesianos width=471 height=470}\n:::\n:::\n\n\nSe puede conocer la probabilidad de manera exacta calculando el área bajo la curva a la izquierda del cero, este sería el valor $p$, si este es menor a 0.05 quiere decir que se tiene una confianza mayor del 95% de que los rendimientos son diferentes. Para este ejemplo, el área se calcula con el siguiente código\n\n::: {#65328ab8 .cell execution_count=42}\n``` {.python .cell-code}\ndist = norm(loc=diff, scale=se)\np_value = dist.cdf(0)\n```\n:::\n\n\n\n\nteniendo el valor de $0.0835$, lo que significa que se tiene una confianza del $91$% de que los dos algoritmos son diferentes considerando el error de clasificación como medida de rendimiento. \n\n## Regresión {#sec-regresion-ols}\n\nHasta este momento se han revisado métodos paramétricos en clasificación, ahora es el turno de abordar el problema de regresión. La diferencia entre clasificación y regresión como se describió en la @sec-aprendizaje-supervisado es que en regresión $\\mathcal Y \\in \\mathbb R.$\n\nEl procedimiento de regresión que se describe en esta sección es regresión de **Mínimos Cuadrados Ordinaria** (OLS -*Ordinary Least Squares*-), en el cual se asume que $\\mathcal Y \\sim \\mathcal N(\\mathbf w \\cdot \\mathbf x + \\epsilon, \\sigma^2)$, de tal manera que $y = \\mathbb E[\\mathcal N(\\mathbf w \\cdot \\mathbf x + \\epsilon, \\sigma^2)].$\n\nTrabajando con $y = \\mathbb E[\\mathcal N(\\mathbf w \\cdot \\mathbf x + \\epsilon, \\sigma^2)],$ se considera lo siguiente $y = \\mathbb E[\\mathcal N(\\mathbf w \\cdot \\mathbf x, 0) + \\mathcal N(0, \\sigma^2)]$ que implica que el error $\\epsilon$ es independiente de $\\mathbf x$, lo cual se transforma en $y = \\mathbf w \\cdot \\mathbf x + \\mathbb E[\\epsilon],$ donde $\\mathbb E[\\epsilon]=0.$ Por lo tanto $y = \\mathbf w \\cdot \\mathbf x.$\n\nLa función de densidad de probabilidad de una Gausiana corresponde a\n\n$$\nf(\\alpha) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\exp{-\\frac{1}{2} (\\frac{\\alpha -  \\mu}{\\sigma})^2},\n$$\n\ndonde $\\alpha$, en el caso de regresión, corresponde a $\\mathbf w \\cdot \\mathbf x$ (i.e., $\\alpha = \\mathbf w \\cdot \\mathbf x$).\n\nUtilizando el método de verosimilitud el cual corresponde a maximizar \n\n$$\n\\begin{split}\n\\mathcal L(\\mathbf w, \\sigma) &= \\prod_{(\\mathbf x, y) \\in \\mathcal D} f(\\mathbf w \\cdot \\mathbf x) \\\\\n&= \\prod_{(\\mathbf x, y) \\in \\mathcal D} \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp{(-\\frac{1}{2} (\\frac{\\mathbf w \\cdot \\mathbf x -  y}{\\sigma})^2)} \\\\\n\\ell(\\mathbf w, \\sigma) &= \\sum_{(\\mathbf x, y) \\in \\mathcal D}\\log \\frac{1}{\\sigma \\sqrt{2\\pi}}  -\\frac{1}{2} (\\frac{\\mathbf w \\cdot \\mathbf x -  y}{\\sigma})^2 \\\\\n&= - \\frac{1}{2\\sigma^2}  \\sum_{(\\mathbf x, y) \\in \\mathcal D} (\\mathbf w \\cdot \\mathbf x -  y)^2 - N \\log \\frac{1}{\\sigma \\sqrt{2\\pi}}.\n\\end{split}\n$$\n\nEl valor de cada parámetro se obtiene al calcular la derivada parcial con respecto al parámetro de interés, entonces se resuelven $d$ derivadas parciales para cada uno de los coeficientes $\\mathbf w$. En este proceso se observar que el término $N \\log \\frac{1}{\\sigma \\sqrt{2\\pi}}$ no depende de $\\mathbf w$ entonces no afecta el máximo siendo una constante en el proceso de derivación y por lo tanto se desprecia. Lo mismo pasa para la constante $\\frac{1}{2\\sigma^2}$. Una vez obtenidos los parámetros $\\mathcal w$ se obtiene el valor $\\sigma.$ \n\nUna manera equivalente de plantear este problema es como un problema de algebra lineal, donde se tiene una matriz de observaciones $X$ que se construyen con las variables $\\mathbf x$ de $\\mathcal X,$ donde cada renglón de $X$ es una observación, y el vector dependiente $\\mathbf y$ donde cada elemento es la respuesta correspondiente a la observación.\n\nViéndolo como un problema de algebra lineal lo que se tiene es \n\n$$\nX \\mathbf w = \\mathbf y,\n$$\n\ndonde para identificar $\\mathbf w$ se pueden realizar lo siguiente\n\n$$\nX^\\intercal X \\mathbf w = X^\\intercal \\mathbf y.\n$$\n\nDespejando $\\mathbf w$ se tiene\n\n$$\n\\mathbf w = (X^\\intercal X)^{-1} X^\\intercal \\mathbf y.\n$$\n\nPreviamente se ha presentado el error estándar de cada parámetro que se ha estimado, en caso de la regresión el error estándar (@sec-error-estandar-ols) de $\\mathcal w_j$ es $\\sigma \\sqrt{(X^\\intercal X)^{-1}_{jj}}.$\n\n### Ejemplo: Diabetes {#sec-diabetes}\n\nEsta sección ilustra el proceso de resolver un problema de regresión utilizando OLS. El problema a resolver se obtiene mediante la función `load_diabetes` de la siguiente manera\n\n::: {#642437c7 .cell execution_count=44}\n``` {.python .cell-code}\nX, y = load_diabetes(return_X_y=True)\n```\n:::\n\n\nEl siguiente paso es generar los conjuntos de entrenamiento y prueba (@sec-conjunto-entre-prueba)\n\n::: {#021904c8 .cell execution_count=45}\n``` {.python .cell-code}\nT, G, y_t, y_g = train_test_split(X, y, test_size=0.2,\n                                  random_state=seed)\n```\n:::\n\n\nCon el conjunto de entrenamiento `T` y `y_t` se estiman los parámetros de la regresión lineal tal y como se muestra a continuación\n\n::: {#11818cc7 .cell execution_count=46}\n``` {.python .cell-code}\nm = LinearRegression().fit(T, y_t)\n```\n:::\n\n\n\n\nLos primeros tres coeficientes de la regresión lineal son $\\mathbf w=[-35.55, -243.17, 562.76, \\ldots]$ y $w_0=152.54$ lo cual se encuentran en las siguientes variables\n\n::: {#aa38dea4 .cell execution_count=48}\n``` {.python .cell-code}\nw = m.coef_\nw_0 = m.intercept_\n```\n:::\n\n\nLa pregunta es si estos coeficientes son estadísticamente diferentes de cero, esto se puede conocer calculando el error estándar de cada coeficiente. Para lo cual se requiere estimar $\\sigma$ que corresponde a la desviación estándar del error tal y como se muestra en las siguientes instrucciones.\n\n::: {#65927600 .cell execution_count=49}\n``` {.python .cell-code}\nerror = y_t - m.predict(T)\nstd_error = np.std(error)\n```\n:::\n\n\nEl error estándar de $\\mathbf w$ es \n\n::: {#3b861d56 .cell execution_count=50}\n``` {.python .cell-code}\ndiag = np.arange(T.shape[1])\n_ = np.sqrt((np.dot(T.T, T)**(-1))[diag, diag])\nse = std_error * _\n```\n:::\n\n\n\n\ny para saber si los coeficientes son significativamente diferente de cero se calcula el cociente `m.coef_` entre `se`; teniendo los siguientes valores $[-0.62, -4.17, 9.88, \\ldots]$, para las tres primeras componentes. Se observa que hay varios coeficientes con valor absoluto menor que 2, lo cual significa que esas variables tiene un coeficiente que estadísticamente no es diferente de cero. \n\nLa predicción del conjunto de prueba se puede realizar con la siguiente instrucción\n\n::: {#36f0c7ea .cell execution_count=52}\n``` {.python .cell-code}\nhy = m.predict(G)\n```\n:::\n\n\nFinalmente, la @fig-regresion-lineal-scatter muestra las predicciones contra las mediciones reales. También se incluye la línea que ilustra el modelo ideal. \n\n::: {#cell-fig-regresion-lineal-scatter .cell execution_count=53}\n``` {.python .cell-code code-fold=\"true\"}\nsns.scatterplot(x=hy, y=y_g)\n_min = min(y_g.min(), hy.min())\n_max = max(y_g.max(), hy.max())\nsns.set_style('whitegrid')\nfig = sns.lineplot(x=[_min, _max], y=[_min, _max])\n```\n\n::: {.cell-output .cell-output-display}\n![Regresión Lineal](03Parametricos_files/figure-html/fig-regresion-lineal-scatter-output-1.png){#fig-regresion-lineal-scatter width=572 height=410}\n:::\n:::\n\n\nComplementando el ejemplo anterior, se realiza un modelo que primero elimina las variables que no son estadísticamente diferentes de cero (primera línea) y después crea nuevas variables al incluir el cuadrado, ver las líneas dos y tres del siguiente código. \n\n::: {#1aaa066a .cell execution_count=54}\n``` {.python .cell-code}\nmask = np.fabs(m.coef_ / se) >= 2\nT = np.concatenate((T[:, mask], T[:, mask]**2), axis=1)\nG = np.concatenate((G[:, mask], G[:, mask]**2), axis=1)\n```\n:::\n\n\nSe observa que la identificación de los coeficientes $\\mathbf w$ sigue siendo lineal aun y cuando la representación ya no es lineal por incluir el cuadrado. Siguiendo los pasos descritos previamente, se inicializa el modelo y después se realiza la predicción.\n\n::: {#7c9bc3fe .cell execution_count=55}\n``` {.python .cell-code}\nm2 = LinearRegression().fit(T, y_t)\nhy2 = m2.predict(G)\n```\n:::\n\n\n\n\nEn este momento se compara si la diferencia entre el error cuadrático medio, del primer y segundo modelo, la diferencia es $8.9400$ indicando que el primer modelo es mejor. \n\n```python\ndiff = ((y_g - hy2)**2).mean() -  ((y_g - hy)**2).mean()\n```\n\nPara comprobar si esta diferencia es significativa se calcula el error estándar, utilizando bootstrap (@sec-bootstrap) tal y como se muestra a continuación. \n\n::: {#030e19c0 .cell execution_count=57}\n``` {.python .cell-code}\nS = np.random.randint(y_g.shape[0],\n                      size=(500, y_g.shape[0]))\nB = [((y_g[s] - hy2[s])**2).mean() -\n      ((y_g[s] - hy[s])**2).mean()\n     for s in S]\nse = np.std(B, axis=0)\n```\n:::\n\n\n\n\nFinalmente, se calcula el área bajo la curva a la izquierda del cero, teniendo un valor de $0.4999$ lo cual indica que los dos modelos son similares. En este caso se prefiere el modelo más simple porque se observar que incluir el cuadrado de las variables no contribuye a generar un mejor model. El área bajo la curva se calcula con el siguiente código. \n\n::: {#23336bac .cell execution_count=59}\n``` {.python .cell-code}\ndist = norm(loc=diff, scale=se)\np_value = dist.cdf(0)\n```\n:::\n\n\n",
    "supporting": [
      "03Parametricos_files/figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}