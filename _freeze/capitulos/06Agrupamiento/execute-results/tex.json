{
  "hash": "d162499129c09e993437ca90946c0933",
  "result": {
    "markdown": "# Agrupamiento\n\nEl **objetivo** de la unidad es conocer y aplicar el algoritmo de agrupamiento k-medias\n\n## Paquetes usados\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nfrom sklearn.cluster import KMeans\nfrom sklearn.datasets import load_iris\nfrom sklearn import decomposition\nfrom sklearn import metrics\nfrom scipy import linalg\nfrom itertools import permutations\nfrom matplotlib import pylab as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n```\n:::\n\n\n\n\n::: {.content-visible when-format=\"html\"}\n\n---\n\n\n{{< video https://www.youtube.com/embed/oS_U5XZLS8g width=\"560\" height=\"315\" >}}\n\n\n\n---\n\n:::\n\n## Introducción\n\nEsta unidad trata el problema de agrupamiento, el cual es un problema de aprendizaje no supervisado (@sec-aprendizaje-no-supervisado), en el cual se cuenta con un conjunto $\\mathcal D = \\{ x_i \\mid i=1, \\ldots, N\\}$ donde $x_i \\in \\mathbb R^d.$ El objetivo de agrupamiento es separar los elementos de $\\mathcal D$ en $K$ grupos. Es decir asociar a $x_i \\in \\mathcal D$ a un grupo $x_i \\in G_j$ donde $\\cup_j^K G_j = \\mathcal D$ y $G_j \\cap G_i = \\emptyset$ para todo $i \\neq j.$\n\nPor supuesto existen diferentes algoritmos que se han desarrollado para generar esta partición, en particular, todos de ellos encuentran la participación optimizando una función objetivo que se considera adecuada para el problema que se está analizando. En particular, esta unidad se enfoca a describir uno de los algoritmos de agrupamiento más utilizados que es K-medias. \n\n## K-medias {#sec-agrupamiento-k-medias}\n\nDe manera formal el objetivo de K-medias es encontrar la partición $G = \\{G_1, G_2, \\ldots, G_K \\}$ que corresponda al $\\min \\sum_{i=1}^K \\sum_{x \\in G_i} \\mid\\mid x - \\mu_i \\mid\\mid,$ donde $\\mu_i$ es la media de todos los elementos que pertenecen a $G_i.$\n\nPara comprender la función objetivo ($\\min \\sum_{i=1}^K \\sum_{x \\in G_i} \\mid\\mid x - \\mu_i \\mid\\mid$) de k-medias se explican los dos componentes principales que son las medias $\\mu_i$ y los grupos $G_i.$\n\nPara ilustrar tanto a $\\mu_i$ como a $G_i$ se utiliza el problema del iris (@sec-visualizacion-iris) cuyos datos se pueden obtener de la siguiente manera.\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nD, y = load_iris(return_X_y=True)\n```\n:::\n\n\n### $\\mu_i$\n\nComo se describió, $\\mu_i$ es la media de los elementos que corresponden al grupo $G_i$. Asumiendo que el grupo $1$ ($G_1$) tiene $10$ elementos seleccionados de manera aleatoria de $\\mathcal D$ como se muestra a continuación.\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nindex = np.arange(len(D))\nnp.random.shuffle(index)\nsel = index[:10]\nG_1 = D[sel]\n```\n:::\n\n\nLa variable `G_1` tiene los 10 elementos considerados como miembros de $G_1$ entonces $\\mu_1$ se calcula como la media de cada componente, lo cual se puede calcular con el siguiente código. \n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nmu_1 = G_1.mean(axis=0)\n```\n:::\n\n\nLa @fig-g1-centro muestra los elementos seleccionados ($x \\in G_1$) y la media ($\\mu_1$) del grupo. Los elementos se encuentran en $\\mathbb R^4$ y para visualizarlos se transformaron usando PCA descrito en la @sec-visualizacion-iris.\n\n::: {.cell execution_count=6}\n\n::: {.cell-output .cell-output-display}\n![Elementos del primer grupo y su centro](06Agrupamiento_files/figure-pdf/fig-g1-centro-output-1.pdf){#fig-g1-centro}\n:::\n:::\n\n\n### $G_i$\n\nEl complemento del procedimiento anterior es encontrar los elementos de $G_i$ dando la $\\mu_i$. El ejemplo consiste en generar dos medias, es decir, $K=2$ y encontrar los elementos que corresponden a las medias generadas. Se puede utilizar cualquier procedimiento para generar dos vectores de manera aleatoria, pero en este ejemplo se asume que estos vectores corresponden a dos elementos de $\\mathcal D.$ Estos elementos son los que se encuentran en los indices $50$ y $100$ tal y como se muestra en las siguientes instrucciones. \n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nmu_1 = D[50]\nmu_2 = D[100]\n```\n:::\n\n\nEl elemento $x$ pertenece al grupo $G_i$ si el valor $\\mid\\mid x - \\mu_i\\mid\\mid$ corresponde al $\\min_j \\mid\\mid x - \\mu_j\\mid\\mid.$ Entonces se requiere calcular $\\mid\\mid x - \\mu_i\\mid\\mid$ para cada elemento $x \\in \\mathcal D$ y para cada una de las medias $\\mu_i$. Esto se puede realizar con la siguiente instrucción\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\ndis = np.array([linalg.norm((D - np.atleast_2d(mu)),\n                            axis=1)\n                for mu in [mu_1, mu_2]]).T\n```\n:::\n\n\ndonde se puede observar que el ciclo itera por cada una de las medias, i.e., `mu_1` y `mu_2`. Después se calcula la norma utilizando la función `linalg.norm` y finalmente se regresa la transpuesta para tener una matriz de 150 renglones y dos columnas que corresponden al número de ejemplos en $\\mathcal D$ y a las dos medias. Los valores de `dis[50]` y `dis[100]` son array([0.    , 1.8439]) y array([1.8439, 0.    ]) respectivamente. Tal y como se espera porque $\\mu_1$ corresponde al índice 50 y $\\mu_2$ es el índice 100. Estos dos ejemplos, array([0.    , 1.8439]) y array([1.8439, 0.    ]), permiten observar que el argumento mínimo de `dis` identifica al grupo del elemento, haciendo la consideración que el índice 0 representa $G_1$ y el índice 1 es $G_2.$ La siguiente instrucción muestra como se realiza esta asignación. \n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nG = dis.argmin(axis=1)\n```\n:::\n\n\nLa @fig-k-means-g muestra los grupos formados, el primer grupo `G_1` se encuentra en azul y el segundo en naranja, también muestra los elementos que fueron usados como medias de cada grupo; estos elementos se observan en color verde. \n\n::: {.cell execution_count=10}\n\n::: {.cell-output .cell-output-display}\n![Proyección de los elementos del conjunto y sus centros](06Agrupamiento_files/figure-pdf/fig-k-means-g-output-1.pdf){#fig-k-means-g}\n:::\n:::\n\n\n### Algoritmo\n\nHabiendo explicado $\\mu_i$ y $G_i$ se procede a describir el procedimiento para calcular los grupos utilizado por k-medias. Este es un procedimiento iterativo que consta de los siguientes pasos. \n\n1. Se generar $K$ medias de manera aleatoria, donde $\\mu_i$ corresponde a $G_i.$\n2. Para cada media, $\\mu_i$, se seleccionan los elementos más cercanos, esto es, $x \\in G_i$ si $\\mid\\mid x - \\mu_i\\mid\\mid$ corresponde al $\\min_j \\mid\\mid x - \\mu_j\\mid\\mid.$\n3. Se actualizan las $\\mu_i$ con los elementos de $G_i.$\n4. Se regresa al paso 2. \n\nEl procedimiento termina cuando se llega a un número máximo de iteraciones o que la variación de los $\\mu_i$ es mínima, es decir, que los grupos no cambian. \n\n## Ejemplo: Iris\n\nEn el siguiente ejemplo se usará K-medias para encontrar 2 y 3 grupos en el conjunto del iris. La clase se inicializa primero con 2 grupos (primera línea). En la segunda instrucción se predice los grupos para todo el conjunto de datos. Las medias para cada grupo se encuentran en el atributo `cluster_centers_.`\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\nm = KMeans(n_clusters=2, n_init='auto').fit(D)\ncl = m.predict(D)\n```\n:::\n\n\nLa @fig-kmeans-2gr muestra el resultado del algoritmo k-means en el conjunto del Iris, se muestran los dos grupos $G_1$ y $G_2$ y en color verde $\\mu_1$ y $\\mu_2$. \n\n::: {.cell execution_count=12}\n\n::: {.cell-output .cell-output-display}\n![Proyección de k-means usando dos grupos](06Agrupamiento_files/figure-pdf/fig-kmeans-2gr-output-1.pdf){#fig-kmeans-2gr}\n:::\n:::\n\n\nUn procedimiento equivalente se puede realizar para generar \ntres grupos, el único cambio es el parámetro `n_clusters`\nen la clase `KMeans` de la siguiente manera.\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\nm = KMeans(n_clusters=3, n_init='auto').fit(D)\ncl = m.predict(D)\n```\n:::\n\n\nLa @fig-kmeans-3gr muestra los tres grupos y con sus tres respectivas medias en color rojo. \n\n::: {.cell execution_count=14}\n\n::: {.cell-output .cell-output-display}\n![Proyección de k-means usando tres grupos](06Agrupamiento_files/figure-pdf/fig-kmeans-3gr-output-1.pdf){#fig-kmeans-3gr}\n:::\n:::\n\n\n## Rendimiento\n\nRecordando que en aprendizaje no supervisado no se tiene una variable dependiente que predecir. En este caso particular se utilizó un problema de clasificación para ilustrar el procedimiento de k-medias, entonces se cuenta con una clase para cada elemento $x \\in \\mathcal D$. Además se sabe que el problema del iris tiene tres clases, entonces utilizando los tres grupos obtenidos previamente podemos medir que tanto se parecen estos tres grupos a las clases del iris. Es decir, se puede saber si el algoritmo de k-medias agrupa los elementos de tal manera que cada grupo corresponda a una clase del iris. \n\n\n\nLos grupos generados se encuentran en la lista `cl` y las clases se encuentran en `y`. La lista `y` tiene organizada las clases de la siguiente manera: los primeros 50 elementos son la clase $0$, los siguientes $50$ son clase $1$ y los últimos son la clase $2$. Dado que K-medias no conoce los clases y genera los grupos empezando de manera aleatoria, entonces es probable que los grupos sigan una numeración diferente al problema del iris. Los grupos en `cl` están organizados de la siguiente manera aproximadamente los $50$ primeros elementos son del grupo $1$, los siguientes son grupo $0$ y finalmente los últimos son grupo $2$. Entonces se puede hacer una transformación usando la variable `perm` con la siguiente información array([0, 1, 2]).\n\n\n\nUtilizando `perm` se calcula la exactitud (@sec-accuracy) utilizando la siguiente instrucción. Se obtiene una exactitud de $0.8867$ que significa que la mayoría de los datos se agrupan en un conjunto que corresponde a la clase del conjunto del iris. \n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\nacc = metrics.accuracy_score(y, perm[cl])\n```\n:::\n\n\nEn general en agrupamiento no se cuenta con la composición de los grupos, es más, se desconocen cuántos grupos modela el problema. Para estas ocasiones es imposible medir el accuracy o cualquier otra medida de agrupamiento que requiera la composición de real de los grupos. \n\nUna medida que no requiere conocer los grupos es el **Silhouette Coefficient**; el cual mide la calidad de los grupos, mientras mayor sea el valor significa una mejor calidad en los grupos. Este coeficiente se basa en la siguiente función:\n\n$$\ns = \\frac{b - a}{\\max(a, b)},\n$$\n\ndonde $a$ corresponde a la distancia media entre un elemento y todos las objetos del mismo grupo; y $b$ es la distancia media entre la muestra y todos los elementos del grupo más cercano.\n\n\n\nPor ejemplo, en el problema del Iris $s$ tiene un valor de $0.5512$ calculado con la siguiente instrucción. \n\n::: {.cell execution_count=19}\n``` {.python .cell-code}\nsil = metrics.silhouette_score(D, cl, metric='euclidean')\n```\n:::\n\n\nOtra medida de la calidad de los grupos es índice de **Calinski-Harabasz** que mide la dispersión entre grupos y dentro del grupo, al igual que Silhouette, mientras mayor sea la estadística mejor es el agrupamiento. Para el problema del Iris el índice de Calinski-Harabasz tiene un valor de $561.5937$ obtenido con la siguiente instrucción.\n\n```python\ncal_har = metrics.calinski_harabasz_score(D, cl)\n```\n\n## Número de Grupos\n\nUtilizando una medida de rendimiento de agrupamiento se analizar cual sería el número adecuado de grupos para un problema dado. El procedimiento es variar el número de grupos y medir el rendimiento para cada grupo y quedarse con aquel que da el mejor rendimiento considerando también el número de grupos. \n\nPor ejemplo, el siguiente instrucción calcula el coeficiente de Silhouette y el índice de Calinski-Harabasz en el problema del Iris. \n\n::: {.cell execution_count=20}\n``` {.python .cell-code}\nS1 = []\nS2 = []\nfor k in range(2, 11):\n    m = KMeans(n_clusters=k, n_init='auto').fit(D)\n    cl = m.predict(D)\n    _ = metrics.silhouette_score(D, cl, metric='euclidean')\n    S1.append(_)\n    _ = metrics.calinski_harabasz_score(D, cl)\n    S2.append(_)\n```\n:::\n\n\nEstas dos estadísticas se pueden observar en la @fig-k-means-performance-k. En color azul se observa el coeficiente de Silhouette; donde el mejor resultado es cuando $K=2$. En color naranja se muestra el índice Calinski-Harabasz done el mejor resultado se tiene cuando $K=3$. Considerando que se está trabajando con el problema del Iris se conoce que la mejor agrupación es para $K=3$ dado que son tres clases.\n\n::: {.cell execution_count=21}\n\n::: {.cell-output .cell-output-display}\n![Rendimiento variando el número de grupos](06Agrupamiento_files/figure-pdf/fig-k-means-performance-k-output-1.pdf){#fig-k-means-performance-k}\n:::\n:::\n\n\n",
    "supporting": [
      "06Agrupamiento_files/figure-pdf"
    ],
    "filters": []
  }
}